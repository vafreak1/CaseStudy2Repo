{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2442d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import pytorch_lightning as pl\n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb7d6fef",
   "metadata": {},
   "source": [
    "## First, we slice the train images into 31 x 31 pixels with the ground truth in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d52ff711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndigit(n, x):\n",
    "    x = str(x)\n",
    "    while(len(x) < n):\n",
    "        x = \"0\" + x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef62c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(res, files = 20):\n",
    "    j = 0\n",
    "    path = [\"train\", \"02\"]\n",
    "    res = int((res-1)/2)\n",
    "    \n",
    "    for p in path:\n",
    "        for f in range(files):\n",
    "            image = np.load(f\"images_{p}/images/image_{ndigit(3, f)}.npy\")\n",
    "            mask = np.load(f\"masks_{p}/masks/mask_{ndigit(3, f)}.npy\")\n",
    "            image = np.reshape(image, (1024,1024,10))\n",
    "            mask = np.reshape(mask, (1024,1024,1))\n",
    "            ground_truths_pos = np.array(np.where(mask != 0)).T\n",
    "\n",
    "            # Add padding to every image edge in case there are ground truths which are too close to an edge\n",
    "            padded_image = np.pad(image, ((res, res), (res, res), (0,0)), mode='constant') \n",
    "            \n",
    "            # Slice and save image\n",
    "            for i in ground_truths_pos: \n",
    "                patch = (padded_image[i[0]-res : i[0]+res+1, i[1]-res : i[1]+res+1, :], np.array(mask[i[0], i[1], 0]))\n",
    "                np.save(f\"patches/train/patch_{ndigit(5, j)}.npy\", np.array(patch, dtype=\"object\"))                                 \n",
    "                j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31235460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6624\n"
     ]
    }
   ],
   "source": [
    "# Check number of ground truths\n",
    "pos = 0\n",
    "for i in range(20):\n",
    "    mask = np.load(f\"masks_02/masks/mask_{ndigit(3, i)}.npy\")\n",
    "    ground_truths_pos = np.array(np.where(mask != 0)).T\n",
    "    pos = pos + len(ground_truths_pos)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5fce53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 15\n",
    "load_data(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "899b7cd4",
   "metadata": {},
   "source": [
    "## Then, we load the data and have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ca66217",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b0bff0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38194\n"
     ]
    }
   ],
   "source": [
    "directory = 'patches/train'\n",
    "file_paths = glob.glob(directory + '/*.npy')\n",
    "trainset0 = [np.load(file_path, allow_pickle=True) for file_path in file_paths]\n",
    "#delete every image that doesnt have the correct shape (!THIS MIGHT BE A REAL PROBLEM THAT NEEDS TO BE FIXED PROPERLY LATER!)\n",
    "trainset = []\n",
    "for pic in trainset0:\n",
    "    if pic[0].shape == (res,res,10):\n",
    "        trainset.append(pic)\n",
    "print(len(trainset)) # Anzahl patches = 38862, d. h. es haben \"nur\" 668 fehlerhafte Dimensionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed9c374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_channels(trainset, veggie, moisture):\n",
    "# structure of the data: \n",
    "#trainset[pic_no][0][Horizontal][VERTIKAL][CHANNEL] -> Intensity \n",
    "#trainset[pic_no][1]-> Ground truth \n",
    "    print(f\"Shape vorher: Liste mit ({res},{res},10) Bildern\")\n",
    "    counter = 0\n",
    "    trainset = trainset\n",
    "\n",
    "    if veggie:\n",
    "        pic_no = 0\n",
    "        for pic in trainset:\n",
    "            counter += 1\n",
    "            pixel_values = pic[:][:][0]\n",
    "            channel8 = pixel_values[6]\n",
    "            channel4 = pixel_values[2]\n",
    "            channels = pic[0].shape[2]\n",
    "            #print(\"Chanels:\", channels)\n",
    "            width = pic[0].shape[0]\n",
    "            height = pic[0].shape[1]\n",
    "            vegetation_array = np.divide((np.subtract(channel8, channel4)), np.add(channel8, channel4))\n",
    "            trainset_transformed = np.append(trainset[pic_no][0], vegetation_array)\n",
    "            trainset1_transformed = np.reshape(trainset_transformed, (width, height, channels + 1, ))\n",
    "            trainset[pic_no] = (trainset1_transformed, trainset[pic_no][1])\n",
    "            pic_no += 1\n",
    "\n",
    "        print(\"Added Vegetation (B8-B4)/(B8+B4)\")\n",
    "\n",
    "    if moisture:\n",
    "        pic_no = 0\n",
    "        for pic in trainset:\n",
    "            pixel_values = pic[:][:][0]\n",
    "            channel8a = pixel_values[7]\n",
    "            channel11 = pixel_values[8]\n",
    "            channels = pic[0].shape[2]\n",
    "            #print(\"Chanels:\", channels)\n",
    "\n",
    "            width = pic[0].shape[0]\n",
    "            height = pic[0].shape[1]\n",
    "            moisture_array = np.divide((np.subtract(channel8a, channel11)), np.add(channel8a, channel11))\n",
    "            trainset_transformed = np.append(trainset[pic_no][0], moisture_array)\n",
    "            trainset1_transformed = np.reshape(trainset_transformed, (width, height, channels + 1))\n",
    "            #print(trainset1_transformed.shape)\n",
    "            trainset[pic_no] = (trainset1_transformed, trainset[pic_no][1]) # append ground truth in tupel \n",
    "            pic_no += 1\n",
    "\n",
    "        print(\"Added Moisture (B8A-B11)/(B8A+B11)\")\n",
    "\n",
    "    return trainset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d4d8018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape vorher: Liste mit (15,15,10) Bildern\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2400 into shape (15,15,11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainset \u001b[39m=\u001b[39m enrich_channels(trainset, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[56], line 22\u001b[0m, in \u001b[0;36menrich_channels\u001b[1;34m(trainset, veggie, moisture)\u001b[0m\n\u001b[0;32m     20\u001b[0m vegetation_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdivide((np\u001b[39m.\u001b[39msubtract(channel8, channel4)), np\u001b[39m.\u001b[39madd(channel8, channel4))\n\u001b[0;32m     21\u001b[0m trainset_transformed \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(trainset[pic_no][\u001b[39m0\u001b[39m], vegetation_array)\n\u001b[1;32m---> 22\u001b[0m trainset1_transformed \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mreshape(trainset_transformed, (width, height, channels \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, ))\n\u001b[0;32m     23\u001b[0m trainset[pic_no] \u001b[39m=\u001b[39m (trainset1_transformed, trainset[pic_no][\u001b[39m1\u001b[39m])\n\u001b[0;32m     24\u001b[0m pic_no \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\damian.garrell\\AppData\\Local\\anaconda3\\envs\\venv_dl\\lib\\site-packages\\numpy\\core\\fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(a, newshape, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    200\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mreshape\u001b[39;49m\u001b[39m'\u001b[39;49m, newshape, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[1;32mc:\\Users\\damian.garrell\\AppData\\Local\\anaconda3\\envs\\venv_dl\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 2400 into shape (15,15,11)"
     ]
    }
   ],
   "source": [
    "trainset = enrich_channels(trainset, True, True)\n",
    "#trainset[pic_no][0][h][w][channel] -> pixel value\n",
    "#trainset[pic_no][1] -> Ground truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "541939c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 31, 31)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = trainset[0]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a187451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, trainset, transform):\n",
    "        self.trainset = trainset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trainset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data, target = self.trainset[index]\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data, target\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.ConvertImageDtype(torch.float),\n",
    "     transforms.Lambda(lambda x : x / 3000),\n",
    "     transforms.Lambda(lambda x : torch.where(x > 1, 1, x)), # clip images between 0 and 1\n",
    "     transforms.Normalize(mean=(0.5,)*12,\n",
    "                          std=(0.5,)*12)\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1ba42dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 12, 31])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the custom dataset\n",
    "custom_dataset = CustomDataset(trainset, transform=transform)\n",
    "\n",
    "custom_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8f4492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sizes of the training set and validation set\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "\n",
    "# Split trainset into trainset and valset\n",
    "trainset, valset = random_split(trainset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders for the training set and validation set\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "validloader = DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89572caf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      3\u001b[0m     X,y \u001b[38;5;241m=\u001b[39m trainset[i]\n\u001b[1;32m----> 4\u001b[0m     X,y \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m, y\n\u001b[0;32m      5\u001b[0m     axarr[i]\u001b[38;5;241m.\u001b[39mimshow(X)\n\u001b[0;32m      6\u001b[0m     axarr[i]\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# f, axarr = plt.subplots(1,10, figsize=(12, 12))\n",
    "# for i in range(10):\n",
    "#     X,y = trainset[i]\n",
    "#     X,y = X.transpose(0,-1).transpose(0,1) * 0.5 + 0.5, y\n",
    "#     axarr[i].imshow(X)\n",
    "#     axarr[i].axis('off')\n",
    "#     axarr[i].set_title(f'{y}', fontsize='small')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93ab30c0",
   "metadata": {},
   "source": [
    "## Next, we define the model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d6a1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNNModel(pl.LightningModule): # New! def init(self, layers, lr=0.01, classes=None): super().init() # <- Very important! self.lr = lr self.classes = classes ## Build model self.layers = nn.Sequential(layers) # Create a sequential model\n",
    "\n",
    "    def __init__(self, *layers, classes=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lr = 0.01  # Assign the learning rate here\n",
    "        self.classes = classes\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)  # Create a sequential model\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.layers(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            y_hat = self(X).argmax(1)\n",
    "        if self.classes is not None:\n",
    "            y_hat = [self.classes[i] for i in y_hat]\n",
    "        return y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx, log_prefix='train'): # New !\n",
    "        X, y = batch # Tuple with (X,y) in our case\n",
    "        y_hat = self(X)\n",
    "        loss = nn.MSELoss(y_hat, y)\n",
    "        self.log(f\"{log_prefix}_loss\", loss.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx): # New!\n",
    "        with torch.no_grad():\n",
    "            return self.training_step(batch, batch_idx, log_prefix='valid')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Adam with Weight Decay (Most commonly used)\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=0.01)\n",
    "\n",
    "        # Simplest scheduler is ReduceLROnPlateau. This scheduler reduces the learning rate by 0.1\n",
    "        # if the val_loss has not decreased within the last 10 epochs.\n",
    "        scheduler = {\n",
    "            # REQUIRED: The scheduler instance\n",
    "            \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10, verbose=True),\n",
    "            # The unit of the scheduler's step size, could also be 'step'.\n",
    "            # 'epoch' updates the scheduler on epoch end whereas 'step'\n",
    "            # updates it after a optimizer update.\n",
    "            \"interval\": \"epoch\",\n",
    "            # How many epochs/steps should pass between calls to\n",
    "            # `scheduler.step()`. 1 corresponds to updating the learning\n",
    "            # rate after every epoch/step.\n",
    "            \"frequency\": 1,\n",
    "            # Metric to to monitor for schedulers like `ReduceLROnPlateau`\n",
    "            \"monitor\": \"val_loss\",\n",
    "            # If set to `True`, will enforce that the value specified 'monitor'\n",
    "            # is available when the scheduler is updated, thus stopping\n",
    "            # training if not found. If set to `False`, it will only produce a warning\n",
    "            \"strict\": True,\n",
    "            # If using the `LearningRateMonitor` callback to monitor the\n",
    "            # learning rate progress, this keyword can be used to specify\n",
    "            # a custom logged name\n",
    "            \"name\": None,\n",
    "        }\n",
    "        return {\"optimizer\": optimizer, 'lr-scheduler': scheduler}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3dd9a9b5",
   "metadata": {},
   "source": [
    "## Implement model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "be94dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implements entry to SepConv2d, see Lang et al. (2019), p. 6\n",
    "class MyEntryLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.proj_out = nn.Conv2d(in_channels, out_channels[len(out_channels)-1], (1,1))\n",
    "\n",
    "        self.entry_blocks = nn.ModuleList()\n",
    "        for i in range(len(out_channels)):\n",
    "            self.entry_blocks.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels[i], (1, 1)),\n",
    "                nn.BatchNorm2d(out_channels[i]),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "            in_channels = out_channels[i]  # Update in_channels for next iteration\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_entry = x\n",
    "        for i in range(len(self.out_channels)):\n",
    "            x_entry = self.entry_blocks[i](x_entry)\n",
    "        x = self.proj_out(x)\n",
    "        return (x + x_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "61d1726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implements SepConv2D\n",
    "class MySepConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel, **kwargs):\n",
    "        super().__init__()\n",
    "        if in_channels == out_channels:\n",
    "            self.proj_out = nn.Identity()\n",
    "        else:\n",
    "            self.proj_out = nn.Conv2d(in_channels, out_channels, (1,1), **kwargs)\n",
    "\n",
    "        self.sep_conv_block = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, in_channels, kernel, groups=in_channels, **kwargs), # depthwise SepConv\n",
    "            nn.Conv2d(in_channels, out_channels, (1,1), **kwargs), # pointwise SepConv\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_sep_conv = self.sep_conv_block(x)\n",
    "        x_sep_conv_2 = self.sep_conv_block(x_sep_conv) # performs second SepConv, see Lang et al. (2019), p. 6\n",
    "        x = self.proj_out(x)\n",
    "        return (x + x_sep_conv_2) # adds original input and sep_conv_2 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "823bc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = MyCNNModel(\n",
    "    MyEntryLayer(12, [128, 256, 512]), # increase number of channels to 512\n",
    "    MySepConvLayer(512, 512, (3,3), padding='same'),\n",
    "    MySepConvLayer(512, 512, (3,3), padding='same'),\n",
    "    MySepConvLayer(512, 512, (3,3), padding='same'),\n",
    "    MySepConvLayer(512, 512, (3,3), padding='same'),\n",
    "    MySepConvLayer(512, 512, (3,3), padding='same'),\n",
    "    MySepConvLayer(512, 512, (3,3), padding='same'),\n",
    "    nn.AdaptiveMaxPool2d(1),\n",
    "    nn.Flatten(1),\n",
    "    nn.Linear(512, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "36dec192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# New, we need a trainer class\n",
    "from pytorch_lightning.callbacks import RichProgressBar, RichModelSummary\n",
    "trainer1 = pl.Trainer(devices=1, accelerator=\"cpu\", precision='64', max_epochs=1,\n",
    "                      callbacks=[RichProgressBar(refresh_rate=50),\n",
    "                                 RichModelSummary(3),\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "707927a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[ 0.0322]],\n",
      "\n",
      "         [[-0.1153]],\n",
      "\n",
      "         [[-0.0560]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0128]],\n",
      "\n",
      "         [[ 0.2286]],\n",
      "\n",
      "         [[ 0.0630]]],\n",
      "\n",
      "\n",
      "        [[[-0.2319]],\n",
      "\n",
      "         [[ 0.1190]],\n",
      "\n",
      "         [[ 0.2672]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0324]],\n",
      "\n",
      "         [[-0.0277]],\n",
      "\n",
      "         [[-0.0829]]],\n",
      "\n",
      "\n",
      "        [[[-0.1140]],\n",
      "\n",
      "         [[ 0.1899]],\n",
      "\n",
      "         [[-0.2257]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2231]],\n",
      "\n",
      "         [[ 0.0564]],\n",
      "\n",
      "         [[-0.2633]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2685]],\n",
      "\n",
      "         [[ 0.2390]],\n",
      "\n",
      "         [[ 0.2079]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1362]],\n",
      "\n",
      "         [[ 0.0020]],\n",
      "\n",
      "         [[-0.0088]]],\n",
      "\n",
      "\n",
      "        [[[-0.1312]],\n",
      "\n",
      "         [[ 0.2131]],\n",
      "\n",
      "         [[-0.0141]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0782]],\n",
      "\n",
      "         [[-0.2338]],\n",
      "\n",
      "         [[ 0.2205]]],\n",
      "\n",
      "\n",
      "        [[[-0.1661]],\n",
      "\n",
      "         [[ 0.0953]],\n",
      "\n",
      "         [[-0.0077]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1244]],\n",
      "\n",
      "         [[ 0.2518]],\n",
      "\n",
      "         [[-0.1572]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1291,  0.0132, -0.0956,  0.1839, -0.2724, -0.0710, -0.2215, -0.1559,\n",
      "        -0.0084, -0.2585,  0.0202, -0.2877,  0.1279,  0.0772, -0.2085, -0.0975,\n",
      "         0.1909, -0.2851, -0.1776, -0.2281,  0.1170, -0.2695,  0.2374, -0.0971,\n",
      "        -0.2486, -0.2138,  0.1482, -0.0748,  0.1370, -0.0516, -0.1878,  0.2823,\n",
      "         0.0156, -0.2014,  0.1558, -0.2374, -0.1614, -0.0242,  0.2569, -0.2191,\n",
      "        -0.1083, -0.2340,  0.0717, -0.0487, -0.2138,  0.2355,  0.1471,  0.0717,\n",
      "         0.2193,  0.2269, -0.1133,  0.0101, -0.0630,  0.0040,  0.1253,  0.2521,\n",
      "        -0.2080,  0.2643,  0.2284,  0.0930, -0.2809, -0.0860, -0.0127, -0.1473,\n",
      "         0.2226, -0.0252,  0.2358,  0.1365,  0.1374,  0.2258,  0.2453, -0.1329,\n",
      "         0.1550, -0.2248, -0.2277, -0.2801,  0.1217,  0.2183, -0.1368, -0.0855,\n",
      "         0.2480,  0.2053,  0.0477, -0.0254, -0.2144,  0.1727,  0.0078,  0.1553,\n",
      "        -0.2329,  0.0721,  0.0728, -0.1556, -0.1621,  0.1170, -0.1355, -0.1610,\n",
      "        -0.1458, -0.0800, -0.1007, -0.2309,  0.0424,  0.1319, -0.0602,  0.2586,\n",
      "         0.0869,  0.2202, -0.0407,  0.2505, -0.0746,  0.2436,  0.0015,  0.2256,\n",
      "         0.2526, -0.0305, -0.0697,  0.0360, -0.0202,  0.1104, -0.0184,  0.0401,\n",
      "         0.0619,  0.1940, -0.2842,  0.1063, -0.2506, -0.1195,  0.1364, -0.1713,\n",
      "         0.1968,  0.1682,  0.2884,  0.2136,  0.2724,  0.2091,  0.2755, -0.0214,\n",
      "         0.1836, -0.0113,  0.0781, -0.2210, -0.0292,  0.1462,  0.0406,  0.0168,\n",
      "         0.0057,  0.2758, -0.0439,  0.2182,  0.1833,  0.1873, -0.2168,  0.2383,\n",
      "         0.0360,  0.1583,  0.1098,  0.1920,  0.0360, -0.1451,  0.0093,  0.0906,\n",
      "        -0.2108, -0.1985,  0.0859,  0.1515, -0.0016, -0.1048,  0.1185,  0.1408,\n",
      "         0.1956,  0.1629, -0.2465, -0.2541,  0.0456, -0.1725, -0.0053, -0.0809,\n",
      "        -0.2566,  0.2710,  0.1068,  0.1254,  0.0323, -0.0361,  0.2471,  0.2561,\n",
      "         0.1790,  0.0322,  0.2443, -0.0521,  0.1726, -0.0029, -0.0128, -0.2805,\n",
      "        -0.0495,  0.0070,  0.2193,  0.2533,  0.2496, -0.2430,  0.2225, -0.0442,\n",
      "         0.1751, -0.2650, -0.1051,  0.0545,  0.1467,  0.2573, -0.1849,  0.2778,\n",
      "         0.0045,  0.2615, -0.0162,  0.0231, -0.1375, -0.0106,  0.1275,  0.0905,\n",
      "         0.1161, -0.0287,  0.1293, -0.0093, -0.1361,  0.2588, -0.2645,  0.2348,\n",
      "        -0.0436,  0.0308, -0.1083,  0.1608,  0.0358,  0.1324, -0.1019, -0.1199,\n",
      "         0.2752, -0.0872,  0.2107,  0.0844,  0.2256,  0.0958, -0.1562, -0.0610,\n",
      "        -0.2084,  0.1715, -0.0004,  0.2572,  0.2530,  0.0042,  0.0241,  0.0577,\n",
      "         0.1345,  0.0809,  0.1212,  0.2721, -0.0460,  0.1021, -0.0865, -0.2630,\n",
      "         0.0847,  0.1644,  0.0707,  0.2443,  0.0733, -0.0940,  0.1979, -0.2038,\n",
      "        -0.0030, -0.2067,  0.2510, -0.1678, -0.1751,  0.1783,  0.0539, -0.2410,\n",
      "         0.2135,  0.0742,  0.0157,  0.0677,  0.0847,  0.0467, -0.1709, -0.1403,\n",
      "         0.2814, -0.2624,  0.1994, -0.0638,  0.1834, -0.2216,  0.0975,  0.0411,\n",
      "         0.1419,  0.0189, -0.1222,  0.1347,  0.2095, -0.2194,  0.1724, -0.2281,\n",
      "        -0.1161, -0.0782, -0.0325,  0.0253, -0.2444,  0.2778,  0.2227, -0.1657,\n",
      "        -0.0265,  0.1386, -0.1012, -0.1570, -0.0080,  0.1303,  0.0429,  0.1054,\n",
      "        -0.0418,  0.2243, -0.0072, -0.2738, -0.2140, -0.2412,  0.2687, -0.0303,\n",
      "         0.0846, -0.1688,  0.1384,  0.0113, -0.0934, -0.0417, -0.1410, -0.1125,\n",
      "         0.1830, -0.0075, -0.1514, -0.1636, -0.0267, -0.0764, -0.2454, -0.2165,\n",
      "        -0.1057, -0.1136,  0.1212, -0.0722, -0.2880, -0.2096,  0.1004,  0.0666,\n",
      "        -0.0521, -0.1371, -0.2048,  0.1962, -0.2030, -0.1398,  0.1835,  0.1911,\n",
      "         0.2740,  0.1840,  0.0589, -0.1344,  0.1135,  0.2856, -0.0591, -0.0099,\n",
      "        -0.0088,  0.2644, -0.0422,  0.1701, -0.1726,  0.0254, -0.0948, -0.2682,\n",
      "        -0.0113, -0.0524,  0.0529,  0.0292, -0.1746,  0.2280, -0.2497,  0.2873,\n",
      "        -0.2593, -0.1476, -0.2796,  0.0745,  0.1426,  0.1516, -0.1948,  0.2200,\n",
      "        -0.1378,  0.0415, -0.1339,  0.0820,  0.1632,  0.1329,  0.0285,  0.0536,\n",
      "        -0.2020,  0.2637, -0.1753,  0.0254, -0.1091, -0.0124, -0.0430, -0.0790,\n",
      "         0.2702, -0.0026, -0.2234, -0.0524, -0.2628,  0.1876,  0.0575,  0.1450,\n",
      "        -0.1313, -0.2276,  0.1691,  0.0538,  0.2555, -0.1700,  0.2121,  0.1309,\n",
      "         0.0114,  0.2447, -0.1580,  0.1738, -0.2099, -0.2330,  0.0486, -0.0024,\n",
      "        -0.2266, -0.0049, -0.2877, -0.0802, -0.2322, -0.1534, -0.1688,  0.0255,\n",
      "        -0.1152,  0.0861,  0.0538,  0.0371,  0.1937,  0.1479,  0.2405,  0.2297,\n",
      "         0.0863, -0.0091,  0.2237,  0.1094,  0.1518, -0.2191, -0.2507,  0.2731,\n",
      "         0.1665, -0.2295, -0.1235,  0.0766, -0.0307,  0.1191,  0.0080, -0.0750,\n",
      "         0.2799,  0.1181, -0.1936,  0.1603, -0.2078, -0.0400, -0.1169,  0.0676,\n",
      "         0.1557,  0.2270, -0.1826,  0.2714, -0.1831, -0.2508, -0.1195,  0.2578,\n",
      "        -0.0804,  0.1687,  0.0671, -0.0420, -0.2509,  0.1673, -0.2411,  0.2688,\n",
      "         0.2552, -0.0939,  0.0795, -0.1506, -0.1052, -0.2222, -0.0349,  0.1512,\n",
      "        -0.1976, -0.2579, -0.2000,  0.0877,  0.2419,  0.2452, -0.2584,  0.0388,\n",
      "        -0.1290, -0.1338, -0.2549, -0.1158,  0.1792, -0.2076, -0.0655, -0.0607,\n",
      "        -0.2207,  0.1088, -0.1917, -0.2687, -0.0796, -0.0858, -0.0638, -0.1412],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.1798]],\n",
      "\n",
      "         [[-0.0210]],\n",
      "\n",
      "         [[ 0.0774]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2633]],\n",
      "\n",
      "         [[-0.0631]],\n",
      "\n",
      "         [[-0.1681]]],\n",
      "\n",
      "\n",
      "        [[[-0.1336]],\n",
      "\n",
      "         [[-0.2346]],\n",
      "\n",
      "         [[-0.1255]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0605]],\n",
      "\n",
      "         [[-0.1236]],\n",
      "\n",
      "         [[ 0.0534]]],\n",
      "\n",
      "\n",
      "        [[[-0.0204]],\n",
      "\n",
      "         [[-0.2541]],\n",
      "\n",
      "         [[ 0.2196]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2690]],\n",
      "\n",
      "         [[ 0.0759]],\n",
      "\n",
      "         [[-0.0564]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0968]],\n",
      "\n",
      "         [[ 0.2427]],\n",
      "\n",
      "         [[ 0.1090]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2745]],\n",
      "\n",
      "         [[ 0.2638]],\n",
      "\n",
      "         [[-0.0494]]],\n",
      "\n",
      "\n",
      "        [[[-0.2044]],\n",
      "\n",
      "         [[-0.0791]],\n",
      "\n",
      "         [[ 0.2780]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2555]],\n",
      "\n",
      "         [[-0.2363]],\n",
      "\n",
      "         [[-0.0254]]],\n",
      "\n",
      "\n",
      "        [[[-0.2359]],\n",
      "\n",
      "         [[-0.0472]],\n",
      "\n",
      "         [[-0.0120]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0066]],\n",
      "\n",
      "         [[ 0.1102]],\n",
      "\n",
      "         [[ 0.2079]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0287, -0.2431,  0.2619,  0.1597, -0.1107,  0.0998,  0.1338, -0.1141,\n",
      "         0.1469, -0.2094,  0.0806,  0.0500,  0.1483, -0.0548, -0.0160,  0.1586,\n",
      "        -0.1084, -0.2692, -0.1337,  0.1241,  0.1007, -0.2227, -0.1383,  0.2298,\n",
      "        -0.1861,  0.2258,  0.0586, -0.0691, -0.2873, -0.2298, -0.2259,  0.2576,\n",
      "         0.1114, -0.1543, -0.1218,  0.1495, -0.2249,  0.2015, -0.1250,  0.0422,\n",
      "        -0.1183, -0.0432, -0.0079,  0.1767,  0.1742, -0.2160,  0.0335, -0.2546,\n",
      "        -0.2309, -0.0886,  0.2795,  0.2870, -0.0227,  0.1283, -0.0276, -0.2191,\n",
      "         0.1657, -0.2146,  0.0584,  0.1511,  0.0737,  0.0423, -0.0724, -0.0576,\n",
      "        -0.2474, -0.2075,  0.0621,  0.2405,  0.2257, -0.2275,  0.2099, -0.1284,\n",
      "         0.0520,  0.0052, -0.2444,  0.0159,  0.1135,  0.1879,  0.1155,  0.1334,\n",
      "         0.0449,  0.1199, -0.1468,  0.2449, -0.2146,  0.1112,  0.2821,  0.1868,\n",
      "         0.0181,  0.2796, -0.0078,  0.1041,  0.2107,  0.0510, -0.1997, -0.1455,\n",
      "         0.2718,  0.2389,  0.0909,  0.0909, -0.1638, -0.2497,  0.2490, -0.0743,\n",
      "         0.0793, -0.1402, -0.0143, -0.0039,  0.0544,  0.0313, -0.2014,  0.0840,\n",
      "        -0.0793, -0.0488, -0.2082, -0.1476,  0.1531,  0.1603,  0.1431, -0.1115,\n",
      "        -0.1388,  0.0595, -0.1583, -0.1442,  0.2559,  0.1775, -0.1403,  0.0383],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.0710]],\n",
      "\n",
      "         [[ 0.0584]],\n",
      "\n",
      "         [[ 0.0692]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0724]],\n",
      "\n",
      "         [[ 0.0825]],\n",
      "\n",
      "         [[-0.0202]]],\n",
      "\n",
      "\n",
      "        [[[-0.0657]],\n",
      "\n",
      "         [[ 0.0346]],\n",
      "\n",
      "         [[ 0.0533]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0806]],\n",
      "\n",
      "         [[-0.0015]],\n",
      "\n",
      "         [[ 0.0457]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0240]],\n",
      "\n",
      "         [[-0.0069]],\n",
      "\n",
      "         [[-0.0532]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0663]],\n",
      "\n",
      "         [[ 0.0135]],\n",
      "\n",
      "         [[-0.0036]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0809]],\n",
      "\n",
      "         [[ 0.0781]],\n",
      "\n",
      "         [[-0.0703]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0040]],\n",
      "\n",
      "         [[-0.0621]],\n",
      "\n",
      "         [[ 0.0031]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0100]],\n",
      "\n",
      "         [[-0.0737]],\n",
      "\n",
      "         [[ 0.0493]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0469]],\n",
      "\n",
      "         [[-0.0844]],\n",
      "\n",
      "         [[ 0.0140]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0526]],\n",
      "\n",
      "         [[-0.0483]],\n",
      "\n",
      "         [[-0.0260]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0745]],\n",
      "\n",
      "         [[ 0.0221]],\n",
      "\n",
      "         [[ 0.0212]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-8.1627e-02,  7.5887e-02,  8.6472e-02,  9.6835e-04, -6.3080e-02,\n",
      "         3.0460e-02, -6.8491e-02,  1.7129e-02,  2.4074e-02,  8.4741e-02,\n",
      "        -2.3318e-02,  6.6992e-02,  6.0654e-02,  5.7461e-02,  4.5321e-02,\n",
      "         7.6646e-02,  3.8859e-02,  7.9271e-02,  6.4270e-02,  6.4331e-02,\n",
      "         4.9590e-02,  7.4828e-05, -3.9724e-03,  2.1807e-02,  8.2667e-02,\n",
      "         7.6792e-02, -6.2773e-02,  2.1479e-02, -5.7278e-02,  6.1052e-02,\n",
      "        -3.4935e-02, -1.3514e-03, -1.2204e-02,  7.2449e-02,  3.7728e-02,\n",
      "         5.1149e-02, -8.5864e-02, -8.7167e-02, -1.4554e-02, -8.2781e-02,\n",
      "         6.1579e-02,  2.5175e-02, -3.9581e-02, -1.4907e-02, -1.9981e-02,\n",
      "         5.2599e-02, -7.4818e-02,  8.1896e-02, -7.3647e-02,  6.2478e-02,\n",
      "         5.1281e-02, -5.3524e-02, -4.1378e-02,  9.6951e-05,  4.8625e-02,\n",
      "         1.0938e-02, -3.3451e-02, -2.6154e-02, -4.6364e-02,  7.9003e-02,\n",
      "        -8.0236e-02, -5.5880e-02,  8.7699e-02, -4.9390e-02,  5.8485e-02,\n",
      "         2.2811e-02,  1.4844e-02,  7.3932e-02,  2.5592e-02,  5.9261e-02,\n",
      "        -7.5244e-02, -4.7236e-03, -5.7650e-03,  5.7957e-02, -6.3675e-02,\n",
      "        -9.9863e-03, -5.8589e-02, -6.8642e-02,  7.8751e-02, -2.8132e-03,\n",
      "         7.5066e-02,  4.0550e-02, -2.1319e-02, -3.7712e-02,  3.9957e-02,\n",
      "         6.5168e-02, -4.5599e-02,  3.2922e-02,  2.5478e-02,  8.3385e-02,\n",
      "        -5.3567e-02,  5.8417e-02,  8.4464e-02,  4.1175e-03, -8.5122e-02,\n",
      "         1.4317e-02, -2.5201e-02,  8.6549e-02, -1.6288e-02,  8.2448e-02,\n",
      "         3.7538e-02, -3.0709e-02, -7.4383e-02, -1.6977e-02,  7.2787e-02,\n",
      "        -5.8169e-03, -6.4807e-02, -8.7940e-02,  2.5266e-02, -3.8062e-02,\n",
      "        -2.9946e-02, -5.3600e-02,  2.2576e-02,  2.9190e-02,  4.9778e-02,\n",
      "        -1.4351e-02, -3.3589e-02, -3.5359e-02,  3.5516e-02, -5.9580e-02,\n",
      "         7.9124e-02, -2.4658e-02, -3.1515e-02,  5.8710e-03, -8.4244e-02,\n",
      "         2.1586e-02, -3.5188e-03, -6.0342e-02,  3.1654e-02,  2.7940e-03,\n",
      "        -3.3237e-02, -8.4010e-02, -4.6213e-03,  6.8259e-03,  7.4052e-04,\n",
      "        -2.9980e-02, -5.1144e-02,  4.3429e-02, -4.1397e-02, -7.1548e-02,\n",
      "         4.0530e-02,  4.2476e-02, -7.5102e-02, -5.9244e-02, -1.9329e-02,\n",
      "        -3.4543e-02,  8.3596e-02,  4.0775e-02, -3.8697e-02, -8.7672e-02,\n",
      "         9.3800e-03, -5.8064e-02,  2.6690e-02,  7.6109e-02,  4.0548e-02,\n",
      "        -6.0509e-02, -3.3159e-02, -6.9458e-02, -7.3127e-02,  8.5198e-02,\n",
      "        -8.0188e-02,  3.5764e-02,  1.7007e-02,  3.0929e-02,  1.5296e-02,\n",
      "        -3.1810e-02, -6.7151e-03,  1.0192e-02,  3.1699e-02,  4.9164e-03,\n",
      "         7.6332e-02,  1.5814e-02,  2.4727e-02,  6.6767e-02,  8.7184e-02,\n",
      "        -5.8260e-02,  6.0705e-02,  7.1650e-02,  5.1273e-02,  2.7362e-02,\n",
      "         5.8265e-02, -8.4427e-02,  6.7578e-02,  6.3649e-02,  7.1997e-02,\n",
      "         7.5487e-02,  1.2443e-02,  2.1875e-02, -8.7444e-02, -2.1071e-02,\n",
      "        -5.5179e-02,  5.6672e-02,  5.0145e-02,  7.7142e-02, -6.9605e-02,\n",
      "         7.1778e-02, -6.1420e-02,  4.4473e-02,  7.6583e-02,  7.4968e-02,\n",
      "         8.3526e-02,  7.5520e-03,  4.3860e-02, -8.0424e-02, -7.0683e-03,\n",
      "         2.1383e-02, -2.2095e-02, -2.2039e-02,  1.1343e-02, -8.1478e-02,\n",
      "        -2.3378e-04,  2.4993e-02,  7.8963e-02, -2.1885e-02,  1.3150e-02,\n",
      "         8.2689e-02,  5.5387e-02, -1.3801e-02, -7.1381e-02, -1.0182e-02,\n",
      "         2.2432e-03,  4.1680e-02,  7.0722e-02,  5.3106e-02, -2.7104e-02,\n",
      "         7.1626e-02, -6.1462e-02, -2.3600e-02, -6.1081e-02, -6.0429e-02,\n",
      "         3.1223e-02,  9.1178e-03,  7.0221e-02,  1.4949e-02,  4.7991e-03,\n",
      "        -5.7615e-02,  2.8880e-02, -7.0995e-03,  7.9354e-02, -2.5433e-02,\n",
      "         2.8522e-02,  5.5741e-02,  3.4232e-02, -6.4429e-02,  5.1503e-02,\n",
      "         4.3854e-02, -2.0545e-02, -7.1791e-02,  6.8693e-02, -1.2579e-02,\n",
      "         3.2213e-02, -3.0251e-03,  7.3184e-02,  3.4198e-02,  5.2022e-02,\n",
      "         6.0288e-02], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 0.0315]],\n",
      "\n",
      "         [[ 0.0268]],\n",
      "\n",
      "         [[ 0.0456]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0424]],\n",
      "\n",
      "         [[-0.0291]],\n",
      "\n",
      "         [[-0.0495]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0307]],\n",
      "\n",
      "         [[ 0.0287]],\n",
      "\n",
      "         [[ 0.0572]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0620]],\n",
      "\n",
      "         [[-0.0552]],\n",
      "\n",
      "         [[ 0.0615]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0388]],\n",
      "\n",
      "         [[-0.0015]],\n",
      "\n",
      "         [[ 0.0623]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0499]],\n",
      "\n",
      "         [[ 0.0420]],\n",
      "\n",
      "         [[ 0.0162]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0008]],\n",
      "\n",
      "         [[ 0.0148]],\n",
      "\n",
      "         [[-0.0062]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0258]],\n",
      "\n",
      "         [[-0.0277]],\n",
      "\n",
      "         [[ 0.0427]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0196]],\n",
      "\n",
      "         [[ 0.0315]],\n",
      "\n",
      "         [[ 0.0272]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0298]],\n",
      "\n",
      "         [[-0.0293]],\n",
      "\n",
      "         [[ 0.0166]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0120]],\n",
      "\n",
      "         [[ 0.0049]],\n",
      "\n",
      "         [[-0.0320]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0517]],\n",
      "\n",
      "         [[-0.0396]],\n",
      "\n",
      "         [[ 0.0132]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0332, -0.0381, -0.0035,  0.0478, -0.0527,  0.0558, -0.0370, -0.0547,\n",
      "         0.0495,  0.0194,  0.0352, -0.0575,  0.0528,  0.0490,  0.0190,  0.0270,\n",
      "         0.0455,  0.0388,  0.0097,  0.0556,  0.0176,  0.0510, -0.0005, -0.0300,\n",
      "        -0.0569,  0.0397, -0.0438,  0.0424, -0.0286,  0.0241,  0.0031,  0.0495,\n",
      "         0.0443,  0.0492,  0.0376, -0.0256, -0.0180,  0.0597, -0.0128, -0.0183,\n",
      "        -0.0398, -0.0006,  0.0326,  0.0102,  0.0574, -0.0488, -0.0207, -0.0055,\n",
      "        -0.0272, -0.0243, -0.0243, -0.0211,  0.0420,  0.0340, -0.0353, -0.0324,\n",
      "        -0.0275,  0.0466,  0.0611,  0.0223,  0.0072,  0.0369, -0.0332, -0.0620,\n",
      "        -0.0579,  0.0086,  0.0184, -0.0568, -0.0007,  0.0186, -0.0556,  0.0545,\n",
      "         0.0184, -0.0612,  0.0045,  0.0297, -0.0488,  0.0557,  0.0007, -0.0078,\n",
      "        -0.0276, -0.0252, -0.0310,  0.0007,  0.0487, -0.0601, -0.0248, -0.0395,\n",
      "        -0.0504, -0.0156,  0.0450, -0.0338,  0.0124,  0.0252,  0.0204,  0.0005,\n",
      "        -0.0568, -0.0389, -0.0261,  0.0223, -0.0271,  0.0156,  0.0124, -0.0173,\n",
      "        -0.0402,  0.0513,  0.0356, -0.0458, -0.0372, -0.0418, -0.0484, -0.0262,\n",
      "         0.0194, -0.0435,  0.0530, -0.0021,  0.0279,  0.0376,  0.0357, -0.0374,\n",
      "        -0.0106,  0.0472, -0.0244, -0.0059,  0.0377, -0.0135, -0.0366,  0.0613,\n",
      "        -0.0463, -0.0113,  0.0501, -0.0305, -0.0323, -0.0394,  0.0494,  0.0135,\n",
      "        -0.0258, -0.0302, -0.0157, -0.0290,  0.0153,  0.0362, -0.0360, -0.0096,\n",
      "         0.0138, -0.0201, -0.0476,  0.0018, -0.0015,  0.0428,  0.0264,  0.0603,\n",
      "        -0.0388, -0.0296,  0.0122, -0.0595, -0.0265, -0.0613,  0.0498,  0.0582,\n",
      "         0.0205,  0.0494,  0.0608,  0.0468, -0.0315, -0.0442,  0.0056, -0.0251,\n",
      "        -0.0342, -0.0447, -0.0483, -0.0260, -0.0187, -0.0401,  0.0517, -0.0085,\n",
      "        -0.0097,  0.0258, -0.0377, -0.0426,  0.0459, -0.0346, -0.0123, -0.0131,\n",
      "         0.0246, -0.0395, -0.0137, -0.0583, -0.0613,  0.0526,  0.0588, -0.0461,\n",
      "         0.0312,  0.0288,  0.0264,  0.0187,  0.0159,  0.0603, -0.0033,  0.0036,\n",
      "         0.0192, -0.0095,  0.0415, -0.0120, -0.0147,  0.0171,  0.0183,  0.0381,\n",
      "         0.0379, -0.0337,  0.0304, -0.0064,  0.0390, -0.0180,  0.0528,  0.0173,\n",
      "         0.0310, -0.0410,  0.0597,  0.0621, -0.0364, -0.0204, -0.0090,  0.0604,\n",
      "         0.0294, -0.0199, -0.0277, -0.0041,  0.0248, -0.0213,  0.0447, -0.0572,\n",
      "         0.0565,  0.0047, -0.0357,  0.0025, -0.0517, -0.0228,  0.0089,  0.0618,\n",
      "        -0.0393, -0.0408, -0.0511,  0.0414, -0.0300, -0.0271,  0.0328, -0.0167,\n",
      "         0.0392, -0.0405, -0.0208,  0.0348,  0.0176, -0.0115, -0.0224,  0.0222,\n",
      "        -0.0041,  0.0164, -0.0340,  0.0208, -0.0348,  0.0288, -0.0335, -0.0624,\n",
      "         0.0448,  0.0614,  0.0127, -0.0033,  0.0504, -0.0466,  0.0314, -0.0201,\n",
      "        -0.0140,  0.0581, -0.0495,  0.0540, -0.0123, -0.0466,  0.0216, -0.0304,\n",
      "        -0.0201,  0.0085, -0.0452, -0.0462, -0.0510, -0.0305, -0.0128, -0.0410,\n",
      "         0.0601, -0.0530, -0.0204, -0.0582,  0.0276, -0.0522, -0.0189,  0.0566,\n",
      "        -0.0564,  0.0373, -0.0039,  0.0142,  0.0495,  0.0601, -0.0214,  0.0520,\n",
      "        -0.0119,  0.0610,  0.0371,  0.0476, -0.0151, -0.0106,  0.0499, -0.0479,\n",
      "        -0.0214,  0.0187, -0.0330,  0.0523, -0.0167, -0.0474,  0.0574, -0.0021,\n",
      "        -0.0125, -0.0296,  0.0252,  0.0091,  0.0372, -0.0187, -0.0463, -0.0057,\n",
      "        -0.0046, -0.0192,  0.0558,  0.0334, -0.0243,  0.0469, -0.0348, -0.0320,\n",
      "         0.0219, -0.0321,  0.0613,  0.0246, -0.0021, -0.0499,  0.0533, -0.0166,\n",
      "         0.0310,  0.0396, -0.0240,  0.0578, -0.0142, -0.0575, -0.0061,  0.0044,\n",
      "        -0.0506, -0.0559,  0.0071, -0.0429,  0.0120, -0.0013,  0.0161,  0.0410,\n",
      "         0.0552, -0.0394, -0.0567, -0.0565, -0.0351, -0.0252, -0.0510, -0.0352,\n",
      "        -0.0583,  0.0143, -0.0025, -0.0397, -0.0408, -0.0369, -0.0587, -0.0156,\n",
      "        -0.0077, -0.0537,  0.0108,  0.0463, -0.0153, -0.0348,  0.0283,  0.0409,\n",
      "         0.0191, -0.0137,  0.0481, -0.0621,  0.0593, -0.0409, -0.0185, -0.0425,\n",
      "         0.0615,  0.0349,  0.0212, -0.0384,  0.0523,  0.0107, -0.0276, -0.0472,\n",
      "         0.0530, -0.0357, -0.0405, -0.0467,  0.0057,  0.0554, -0.0315, -0.0428,\n",
      "         0.0377, -0.0377, -0.0193,  0.0226, -0.0199, -0.0107, -0.0615,  0.0111,\n",
      "         0.0169,  0.0256, -0.0552, -0.0300, -0.0548,  0.0499, -0.0107,  0.0142,\n",
      "         0.0515,  0.0576,  0.0329,  0.0376, -0.0565,  0.0379,  0.0539, -0.0393,\n",
      "        -0.0109, -0.0299, -0.0509, -0.0528, -0.0238, -0.0038,  0.0407, -0.0084,\n",
      "         0.0344,  0.0137,  0.0222,  0.0448,  0.0439,  0.0245, -0.0150,  0.0455,\n",
      "         0.0033, -0.0520,  0.0620,  0.0166, -0.0495,  0.0590, -0.0226,  0.0343,\n",
      "        -0.0410, -0.0171, -0.0119,  0.0072,  0.0492,  0.0338,  0.0376, -0.0332,\n",
      "        -0.0041, -0.0361, -0.0524,  0.0117, -0.0054, -0.0449, -0.0330, -0.0446,\n",
      "        -0.0179, -0.0528, -0.0224, -0.0168,  0.0122, -0.0057,  0.0148, -0.0203,\n",
      "        -0.0578,  0.0108, -0.0362,  0.0223,  0.0281, -0.0498, -0.0026,  0.0158,\n",
      "        -0.0011, -0.0613,  0.0454, -0.0531, -0.0617, -0.0453,  0.0270,  0.0178,\n",
      "         0.0447, -0.0462, -0.0430,  0.0180,  0.0239, -0.0449,  0.0523,  0.0099,\n",
      "         0.0554, -0.0235,  0.0337, -0.0314,  0.0555,  0.0510, -0.0249, -0.0187],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 0.0844, -0.0980, -0.0981],\n",
      "          [ 0.2121,  0.2126,  0.0079],\n",
      "          [ 0.2632, -0.2880, -0.1980]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2326, -0.2701, -0.3303],\n",
      "          [-0.1808, -0.3125,  0.3187],\n",
      "          [ 0.2125,  0.2387, -0.2062]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1627, -0.2174,  0.1993],\n",
      "          [ 0.1407, -0.1791,  0.0186],\n",
      "          [ 0.1682, -0.3230,  0.1456]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2840,  0.1823, -0.3250],\n",
      "          [ 0.2679,  0.1318, -0.3228],\n",
      "          [ 0.3034, -0.0017,  0.0553]]],\n",
      "\n",
      "\n",
      "        [[[-0.0936, -0.2189, -0.1250],\n",
      "          [-0.2578,  0.3253, -0.0485],\n",
      "          [-0.2077, -0.3097, -0.1346]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1681,  0.0707,  0.1790],\n",
      "          [-0.3326,  0.1774, -0.1456],\n",
      "          [-0.0661, -0.3243, -0.1168]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0262, -0.2323, -0.3198,  0.0582, -0.0891, -0.2015, -0.2017,  0.3240,\n",
      "        -0.0788,  0.2817, -0.2448,  0.2678, -0.0844,  0.1249, -0.2739, -0.2993,\n",
      "        -0.0348,  0.1010,  0.0684,  0.0724, -0.0774,  0.1576, -0.2673, -0.1646,\n",
      "         0.1968, -0.0718, -0.2509, -0.1592,  0.3077,  0.0973,  0.1787,  0.2058,\n",
      "         0.1493, -0.1915,  0.2718,  0.1323,  0.1610,  0.1170,  0.2542, -0.1907,\n",
      "         0.2773, -0.0575, -0.0950, -0.1186,  0.2572, -0.0614, -0.3244, -0.0268,\n",
      "         0.0920, -0.1054,  0.2021, -0.1057, -0.0664, -0.2977, -0.2337, -0.0184,\n",
      "        -0.2752, -0.1988,  0.0192, -0.1834, -0.2975,  0.0809, -0.1295,  0.1137,\n",
      "         0.3270,  0.1384, -0.0755,  0.2550, -0.2304,  0.1281, -0.1510,  0.1958,\n",
      "         0.0195,  0.1330, -0.2642, -0.2329,  0.3294, -0.2601,  0.1899,  0.2674,\n",
      "         0.2807, -0.1644, -0.1226,  0.0315, -0.2445,  0.1698,  0.0315,  0.3329,\n",
      "        -0.1006, -0.2239, -0.2221, -0.2262, -0.2612,  0.3310,  0.0280, -0.0563,\n",
      "         0.1548, -0.3224, -0.1241, -0.2875, -0.0707, -0.1814, -0.0939,  0.2767,\n",
      "         0.0988, -0.1811,  0.2497, -0.0909, -0.3019, -0.0835,  0.0058,  0.3084,\n",
      "         0.2911, -0.1862,  0.2688,  0.0475, -0.2308, -0.0698,  0.1689,  0.2075,\n",
      "         0.0534, -0.0938, -0.0467, -0.2111, -0.1917, -0.3059, -0.2225,  0.0315,\n",
      "         0.0691,  0.0545, -0.2794,  0.2577, -0.1089,  0.2333,  0.2240,  0.1812,\n",
      "         0.0080,  0.2144,  0.0322, -0.3045,  0.0042,  0.2357,  0.2395, -0.0885,\n",
      "        -0.2417, -0.3320,  0.1352, -0.2610,  0.1918,  0.0287,  0.2315,  0.2854,\n",
      "         0.1710, -0.2604, -0.1685, -0.0516, -0.3044,  0.2029,  0.0457,  0.2826,\n",
      "         0.1589, -0.2925,  0.2002,  0.2471, -0.0204,  0.3143, -0.2969,  0.0903,\n",
      "         0.2874, -0.0338, -0.1367,  0.2902,  0.0215, -0.0636,  0.2614,  0.1458,\n",
      "         0.1603,  0.0235, -0.2266,  0.3291, -0.0503,  0.2744,  0.0719,  0.0779,\n",
      "        -0.1586, -0.2814, -0.1405,  0.1698,  0.0239, -0.2158, -0.2618, -0.0087,\n",
      "        -0.2253, -0.2383, -0.1189, -0.2378, -0.0573,  0.0352, -0.0783,  0.2681,\n",
      "        -0.1675, -0.2974,  0.2293,  0.0493, -0.1467,  0.2265,  0.2736,  0.3241,\n",
      "         0.1642, -0.0669,  0.1575, -0.1114,  0.1000,  0.1997,  0.3231,  0.1877,\n",
      "        -0.1975, -0.0174,  0.0863, -0.0628, -0.2208, -0.2284,  0.1034, -0.2249,\n",
      "         0.1527, -0.0378, -0.0635,  0.3142, -0.1530, -0.1952,  0.2563,  0.0252,\n",
      "        -0.2199, -0.0328,  0.3289, -0.1561, -0.1607,  0.1681, -0.2966,  0.0224,\n",
      "         0.2942, -0.1225,  0.1145, -0.0997, -0.1418, -0.2584,  0.2784,  0.2947,\n",
      "        -0.1199,  0.1576, -0.2206,  0.2341,  0.1574,  0.2819, -0.1584, -0.0972,\n",
      "        -0.1856, -0.0889, -0.2559,  0.0091,  0.3330, -0.0927, -0.2462,  0.2018,\n",
      "         0.1629,  0.2428,  0.1341, -0.0039, -0.2027, -0.2259,  0.2069,  0.3127,\n",
      "        -0.0423,  0.2291, -0.3259,  0.3304,  0.0556,  0.1406, -0.1612,  0.3198,\n",
      "         0.1658, -0.2617,  0.2101, -0.2489, -0.1247, -0.2340, -0.0743, -0.0413,\n",
      "        -0.0759, -0.1203,  0.2928,  0.3205, -0.1486, -0.0248,  0.2212,  0.0772,\n",
      "         0.0533, -0.0606,  0.2311, -0.1121,  0.1771, -0.2908, -0.2594, -0.0479,\n",
      "         0.3042, -0.2670, -0.2874, -0.3222,  0.2295,  0.0561, -0.0733,  0.2284,\n",
      "         0.2573,  0.0954,  0.0958,  0.0083, -0.0055,  0.3187, -0.0171,  0.0173,\n",
      "        -0.0492, -0.0265, -0.2880, -0.3281,  0.3058,  0.1182, -0.0071, -0.2582,\n",
      "         0.0870, -0.0360, -0.2681, -0.2690,  0.2786, -0.2836,  0.3053,  0.2671,\n",
      "        -0.0138, -0.0457,  0.2127, -0.1053, -0.1655, -0.2419,  0.0306,  0.2867,\n",
      "        -0.2059,  0.2454, -0.0600,  0.1326,  0.1584,  0.3113, -0.2718,  0.2553,\n",
      "         0.1174,  0.3046,  0.3147, -0.1357, -0.1814, -0.2963,  0.2855, -0.3027,\n",
      "         0.2549, -0.2807,  0.1380, -0.0474,  0.3202, -0.0541,  0.0780, -0.1917,\n",
      "         0.1094, -0.2636,  0.1255,  0.1823, -0.1730,  0.2907, -0.2310, -0.2145,\n",
      "        -0.1764,  0.0425,  0.1938,  0.0892,  0.1825,  0.0616,  0.0696, -0.1998,\n",
      "        -0.2899,  0.3290,  0.2257,  0.1251, -0.1862,  0.1124,  0.2514, -0.0219,\n",
      "        -0.3152,  0.1364,  0.2708,  0.1322, -0.1116, -0.2689, -0.1592,  0.2500,\n",
      "        -0.0213,  0.1949, -0.2845,  0.0345,  0.0218,  0.2470, -0.0790,  0.2461,\n",
      "         0.1462,  0.0767, -0.0100,  0.2655, -0.0654,  0.1674,  0.1473, -0.0129,\n",
      "        -0.0280, -0.1090,  0.3260, -0.0332, -0.3160,  0.2374, -0.1255, -0.1098,\n",
      "         0.2409,  0.2555,  0.2830, -0.2567,  0.1464,  0.2251,  0.0705, -0.1515,\n",
      "        -0.0505, -0.1410,  0.1497, -0.0314, -0.1868, -0.1873,  0.2617, -0.1936,\n",
      "        -0.1302,  0.2868, -0.1655, -0.3328, -0.0741, -0.1039,  0.0283, -0.2787,\n",
      "        -0.1278,  0.1178, -0.0627, -0.2793, -0.1940,  0.2860, -0.2064, -0.2124,\n",
      "         0.2302, -0.1066,  0.0376,  0.3017,  0.1375,  0.3216, -0.3067,  0.3152,\n",
      "         0.1367,  0.3014, -0.0044,  0.1972, -0.1906, -0.2376,  0.2989, -0.0357,\n",
      "        -0.1014, -0.0465,  0.3208,  0.0702, -0.1703, -0.3134,  0.0055,  0.2074,\n",
      "         0.1073,  0.0283,  0.2175, -0.1019,  0.0013,  0.1027,  0.1548,  0.0847,\n",
      "         0.1413,  0.0468, -0.0236, -0.0066, -0.1571, -0.1702,  0.3313,  0.2070,\n",
      "        -0.1558, -0.0632,  0.0754, -0.0716,  0.0287,  0.0689,  0.0405, -0.1214,\n",
      "        -0.1997,  0.1148, -0.1248,  0.2705, -0.0740, -0.1778, -0.2477,  0.1381],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.0241]],\n",
      "\n",
      "         [[-0.0049]],\n",
      "\n",
      "         [[ 0.0155]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0312]],\n",
      "\n",
      "         [[-0.0386]],\n",
      "\n",
      "         [[ 0.0270]]],\n",
      "\n",
      "\n",
      "        [[[-0.0240]],\n",
      "\n",
      "         [[-0.0098]],\n",
      "\n",
      "         [[ 0.0372]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0066]],\n",
      "\n",
      "         [[ 0.0140]],\n",
      "\n",
      "         [[ 0.0360]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0152]],\n",
      "\n",
      "         [[ 0.0178]],\n",
      "\n",
      "         [[-0.0339]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0078]],\n",
      "\n",
      "         [[-0.0209]],\n",
      "\n",
      "         [[ 0.0354]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0112]],\n",
      "\n",
      "         [[ 0.0353]],\n",
      "\n",
      "         [[-0.0099]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0068]],\n",
      "\n",
      "         [[-0.0295]],\n",
      "\n",
      "         [[-0.0100]]],\n",
      "\n",
      "\n",
      "        [[[-0.0374]],\n",
      "\n",
      "         [[ 0.0359]],\n",
      "\n",
      "         [[ 0.0085]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0398]],\n",
      "\n",
      "         [[ 0.0115]],\n",
      "\n",
      "         [[ 0.0067]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0438]],\n",
      "\n",
      "         [[ 0.0094]],\n",
      "\n",
      "         [[ 0.0386]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0030]],\n",
      "\n",
      "         [[ 0.0040]],\n",
      "\n",
      "         [[ 0.0377]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-1.0165e-02, -3.8223e-02,  3.9210e-02, -2.7257e-02,  4.0136e-02,\n",
      "        -3.0667e-02, -3.0061e-02, -3.9892e-02,  3.1112e-02, -1.0277e-02,\n",
      "        -3.9759e-02,  4.1619e-02,  2.9909e-02,  1.3692e-02, -4.3049e-03,\n",
      "        -4.1683e-02, -3.6092e-02,  2.6227e-02, -1.8278e-02,  7.8501e-03,\n",
      "        -1.4424e-02,  4.4197e-03,  1.0195e-02, -3.7260e-02, -2.0822e-02,\n",
      "         2.8481e-02, -3.8174e-02,  3.7644e-02,  4.1266e-02,  6.9523e-03,\n",
      "         3.4486e-02, -1.8456e-02,  2.5017e-02, -2.9206e-02,  1.2722e-03,\n",
      "         4.0992e-02,  3.9757e-02,  3.7096e-02,  1.6708e-02, -3.8474e-02,\n",
      "        -2.5310e-02, -3.0959e-02, -1.1022e-02,  3.3727e-02,  4.1129e-02,\n",
      "        -2.6321e-03,  4.3020e-02, -4.0449e-02,  2.4136e-02,  4.6205e-03,\n",
      "        -3.9351e-02, -4.0122e-02,  2.7510e-02,  3.7804e-02,  1.0965e-02,\n",
      "         2.2478e-02,  5.7074e-04, -4.2646e-02,  2.1029e-02, -9.6922e-03,\n",
      "         3.7123e-02, -3.6392e-02,  3.2686e-02, -2.4817e-02, -4.3167e-02,\n",
      "         3.6474e-02,  3.5038e-02,  1.4213e-02,  3.0213e-02,  1.8752e-02,\n",
      "         2.6204e-02, -8.3703e-03, -4.1729e-02, -2.0250e-02,  3.7249e-02,\n",
      "         4.2898e-03,  1.4101e-02,  5.6582e-03,  6.0380e-03, -2.4272e-02,\n",
      "         4.0667e-02, -2.0613e-02, -4.7958e-03, -2.8275e-03, -3.7951e-03,\n",
      "         1.3327e-02,  2.9486e-02, -1.3477e-02,  4.2090e-03,  3.6400e-02,\n",
      "        -4.2888e-02,  2.1163e-02,  2.1924e-02,  2.9332e-02,  1.1093e-02,\n",
      "        -3.8798e-02, -2.5112e-02,  8.3883e-03,  1.8877e-02, -1.4904e-03,\n",
      "        -2.4633e-02, -4.3396e-02, -2.5406e-02, -1.5480e-02,  1.2833e-03,\n",
      "         1.6612e-02, -3.9736e-02, -1.0241e-02,  4.2016e-02,  2.4283e-02,\n",
      "        -7.2871e-03, -8.4478e-03, -1.7465e-02,  1.6172e-02,  2.8776e-02,\n",
      "        -3.9468e-02, -2.1292e-02, -2.8015e-02,  3.6002e-02, -2.6510e-02,\n",
      "         4.3449e-02, -2.5060e-02,  1.5849e-02, -3.9612e-02, -1.4743e-02,\n",
      "         3.2576e-02, -1.7118e-02,  4.1494e-04,  4.6757e-03,  3.4960e-02,\n",
      "        -8.1478e-03, -1.2167e-02, -3.5277e-02,  1.8447e-02,  1.2687e-02,\n",
      "        -2.2910e-02,  2.5256e-02, -2.7720e-02,  3.1271e-02,  3.6289e-02,\n",
      "         7.8975e-03,  1.0624e-02, -3.0273e-02,  3.6908e-02,  1.1312e-03,\n",
      "         3.3862e-03,  7.8807e-04, -1.0835e-02, -2.2555e-03, -1.4662e-02,\n",
      "         7.7145e-03, -4.5974e-03, -2.9992e-03, -2.5818e-02, -4.2616e-02,\n",
      "         7.5757e-03,  2.4308e-02,  2.8695e-02,  2.4377e-03, -3.9869e-02,\n",
      "         1.9427e-02, -3.2465e-02, -4.1819e-02,  7.2860e-03, -3.9494e-02,\n",
      "        -2.0109e-02, -1.8626e-02, -3.3304e-02, -3.9041e-02, -2.6922e-02,\n",
      "        -3.1411e-02, -3.8621e-02,  3.7931e-02,  3.8829e-04,  2.5490e-03,\n",
      "        -2.5920e-02, -1.0521e-03, -2.2188e-02,  1.6318e-02,  2.5411e-02,\n",
      "        -5.3096e-03,  3.1070e-02,  2.0438e-02, -3.3817e-03, -5.1971e-03,\n",
      "         1.4202e-02,  1.5086e-02, -1.1266e-02,  1.9715e-02,  5.4850e-03,\n",
      "         1.8226e-02,  2.9117e-02, -3.7711e-02,  9.6261e-03,  9.4174e-03,\n",
      "        -3.2368e-02, -2.8546e-02, -4.3624e-02,  3.1992e-03, -3.7469e-02,\n",
      "         3.1925e-02,  3.0404e-02, -1.4916e-02, -3.6796e-03, -3.9845e-02,\n",
      "         3.4629e-02,  3.5829e-02, -1.9649e-02, -1.9763e-02, -6.7426e-03,\n",
      "         2.1102e-02,  4.6245e-03,  3.7330e-02, -1.7951e-02, -6.8142e-03,\n",
      "        -2.8520e-02,  6.4148e-04, -3.7640e-03, -3.2594e-02,  3.1467e-02,\n",
      "        -1.3546e-02, -1.2620e-02, -2.8958e-02,  2.0247e-02,  4.3158e-03,\n",
      "         2.6727e-03, -2.7376e-02, -2.1553e-02, -3.8723e-02, -1.3387e-02,\n",
      "        -9.7666e-03,  1.5292e-03, -1.3633e-02,  3.6908e-02, -3.9245e-02,\n",
      "         3.3889e-02,  2.0357e-02, -2.3134e-02,  2.7245e-02, -3.2928e-02,\n",
      "        -1.3810e-02,  1.2831e-02, -3.6297e-02, -1.1261e-02,  1.1435e-02,\n",
      "         4.1272e-02,  9.7795e-03,  1.3299e-02, -3.5341e-02, -4.3582e-02,\n",
      "        -4.2426e-02, -4.3720e-02,  5.0818e-03,  1.8078e-03,  2.1027e-02,\n",
      "         8.2507e-03,  4.3191e-02,  3.5492e-02,  2.8050e-02,  6.6304e-04,\n",
      "         2.7621e-02, -1.2917e-02, -1.5460e-02,  2.5612e-02,  3.9605e-02,\n",
      "         3.3547e-02,  2.7165e-02, -4.2173e-02,  7.5408e-03, -6.2786e-03,\n",
      "         1.5600e-02,  3.2139e-02, -2.2070e-02,  3.6521e-02,  2.8038e-02,\n",
      "        -3.9797e-02,  5.9171e-03, -2.0297e-02, -3.0783e-04, -2.5598e-02,\n",
      "         2.2188e-02,  3.5731e-02, -2.5531e-02, -1.4475e-02, -2.6031e-02,\n",
      "        -3.3538e-02, -1.9417e-02, -1.6578e-03,  3.0130e-02,  1.2475e-02,\n",
      "        -7.0678e-03,  3.4978e-02, -1.5275e-03, -2.0520e-02,  1.7007e-02,\n",
      "         9.7746e-03, -7.9114e-03,  4.6028e-03,  4.3832e-02, -2.0250e-03,\n",
      "        -3.4611e-02, -4.0259e-02,  3.5872e-02, -2.4389e-02,  2.9702e-02,\n",
      "         5.2054e-03, -1.6791e-02, -1.5980e-02,  4.0352e-02,  4.0654e-02,\n",
      "         3.2946e-02, -3.9914e-02,  2.1965e-02,  2.5654e-02, -2.1739e-02,\n",
      "        -1.0339e-02, -1.3185e-02, -2.6429e-02,  2.9906e-02,  2.9439e-02,\n",
      "         1.4505e-02, -3.1812e-02, -3.3865e-02, -4.3127e-02, -9.3715e-03,\n",
      "         1.8196e-02,  3.1581e-02,  2.4001e-03,  2.0185e-02, -3.8286e-02,\n",
      "        -1.2578e-02, -8.9052e-03, -2.1070e-02,  7.8520e-03, -3.2825e-02,\n",
      "         5.5964e-03,  2.9398e-02, -1.0844e-02,  3.1353e-02, -3.7209e-02,\n",
      "        -1.6522e-02,  4.1949e-03, -3.0401e-02,  5.6371e-03, -3.9168e-02,\n",
      "         4.1666e-03,  3.0535e-02,  2.5882e-02, -1.0058e-02, -3.0641e-02,\n",
      "         3.9976e-02, -1.3068e-02, -3.9592e-02, -2.3013e-02, -1.7407e-02,\n",
      "         2.3760e-02,  2.0051e-02,  3.2882e-02, -2.4916e-02,  1.2344e-02,\n",
      "        -9.2132e-03, -1.1255e-02, -2.6397e-02, -1.1730e-04,  3.5911e-02,\n",
      "        -3.5203e-02, -4.5595e-03, -3.8088e-02, -1.3586e-02,  4.5014e-03,\n",
      "         1.0693e-02, -2.9806e-02,  3.3998e-02, -4.1053e-02, -3.8896e-02,\n",
      "        -2.3986e-02,  4.9083e-03,  3.4234e-02, -1.2657e-02,  1.2656e-02,\n",
      "         2.9558e-02,  3.1157e-02,  4.0169e-02, -2.9399e-02, -5.2560e-03,\n",
      "         2.7841e-02,  6.6333e-03, -2.0955e-02,  5.0708e-03,  3.4993e-02,\n",
      "        -2.6190e-02, -1.9570e-02,  2.9117e-02, -2.6131e-02,  8.8359e-03,\n",
      "        -2.8501e-02, -3.5265e-03, -3.8346e-02,  2.1455e-02,  2.4657e-02,\n",
      "         1.1583e-02,  1.2122e-02, -1.0759e-02,  3.4338e-03,  2.6542e-02,\n",
      "         1.5560e-02,  1.9828e-02, -1.7443e-02, -2.9378e-03,  2.4673e-02,\n",
      "        -3.8318e-02,  3.5462e-02,  2.4242e-02,  1.4140e-02, -2.2868e-03,\n",
      "        -4.3407e-02,  3.4736e-04, -3.9004e-02, -3.1554e-02,  3.4979e-02,\n",
      "        -1.1140e-02, -1.9443e-02, -3.7753e-02, -2.6609e-02, -1.9407e-02,\n",
      "         1.0045e-02,  1.4991e-02,  3.0236e-03, -2.1781e-02, -3.4287e-02,\n",
      "         1.4238e-02, -2.6188e-02, -8.4104e-03, -3.0016e-02,  2.1106e-03,\n",
      "         9.5773e-03,  2.8824e-02,  6.8758e-03,  3.3653e-02, -1.7866e-02,\n",
      "        -1.5835e-02,  1.1401e-02,  5.2777e-03,  5.1503e-03, -2.7807e-02,\n",
      "         3.7455e-04, -1.5242e-02,  2.3363e-03, -2.6083e-03,  4.1720e-02,\n",
      "         9.0833e-03,  8.0530e-05, -2.0267e-02, -3.4866e-02,  3.8276e-02,\n",
      "        -4.1683e-02,  1.0068e-02,  1.6429e-02,  5.8500e-03,  2.0901e-02,\n",
      "         4.2769e-02, -1.0964e-02, -4.0258e-02,  3.5851e-02, -9.8690e-03,\n",
      "         3.4939e-03,  2.3720e-02,  2.2692e-02, -2.4607e-02,  4.3463e-02,\n",
      "         6.1401e-03, -2.5421e-02,  2.0051e-02,  3.8219e-02, -3.7769e-03,\n",
      "        -2.9111e-02, -4.2480e-02,  5.1698e-03,  4.8200e-03,  3.6386e-02,\n",
      "        -6.0409e-03, -3.4236e-02, -9.0383e-03,  4.2420e-02, -1.1635e-02,\n",
      "        -3.4725e-02, -5.7833e-03,  2.2163e-02,  3.3593e-02, -3.3727e-02,\n",
      "         2.3483e-02, -3.0659e-03, -2.7566e-02, -3.7295e-02, -3.4622e-02,\n",
      "        -2.2718e-02,  3.8736e-02, -1.6733e-02, -3.1822e-02, -2.9141e-02,\n",
      "         3.6050e-02,  2.0169e-02,  1.5558e-02, -9.0649e-03,  3.2723e-02,\n",
      "        -1.3263e-02,  3.4288e-03, -3.5521e-02, -1.1512e-02, -2.9093e-02,\n",
      "         2.0853e-02, -4.3765e-02], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.1156,  0.1610, -0.0611],\n",
      "          [ 0.1177, -0.2342, -0.0282],\n",
      "          [-0.2272, -0.1169, -0.2473]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0157, -0.2562,  0.1764],\n",
      "          [-0.1810, -0.1749,  0.0849],\n",
      "          [ 0.1655,  0.2285, -0.3040]]],\n",
      "\n",
      "\n",
      "        [[[-0.0135, -0.1484, -0.0197],\n",
      "          [ 0.0600, -0.0880,  0.0851],\n",
      "          [ 0.1381, -0.3244,  0.1254]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1996, -0.0381,  0.1612],\n",
      "          [ 0.1431, -0.1567, -0.2515],\n",
      "          [-0.0183, -0.3181, -0.2692]]],\n",
      "\n",
      "\n",
      "        [[[-0.3107,  0.2261,  0.0753],\n",
      "          [ 0.2497, -0.0874,  0.2666],\n",
      "          [ 0.2931, -0.1026, -0.2141]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1579,  0.0323,  0.1303],\n",
      "          [ 0.1517, -0.1057, -0.0807],\n",
      "          [-0.0463,  0.1752,  0.2765]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.2038,  0.1270,  0.3026, -0.3091,  0.2482, -0.2184, -0.1815, -0.1723,\n",
      "        -0.1405, -0.3295,  0.2885, -0.2988,  0.2047, -0.0496,  0.2643, -0.0726,\n",
      "         0.0735, -0.2492,  0.1044, -0.2260,  0.1015, -0.0446,  0.2026,  0.1428,\n",
      "        -0.0961,  0.0010,  0.1396,  0.1845, -0.2036,  0.1359, -0.0312, -0.0697,\n",
      "        -0.1851,  0.2094, -0.1047, -0.2678, -0.3118,  0.0208, -0.2794, -0.2031,\n",
      "         0.1954,  0.2350, -0.2919, -0.3322,  0.0990, -0.2163,  0.0301,  0.0968,\n",
      "        -0.3153, -0.1755, -0.1048, -0.0417, -0.2678, -0.1704, -0.2209,  0.2099,\n",
      "         0.1106,  0.0428, -0.0171,  0.2857, -0.3171, -0.1022,  0.3179, -0.2956,\n",
      "        -0.1269, -0.2116, -0.0200,  0.3104, -0.0809, -0.0876,  0.1741,  0.1634,\n",
      "        -0.2376,  0.1852,  0.2248, -0.1112,  0.3333, -0.1385, -0.0476, -0.1499,\n",
      "        -0.0234, -0.2994,  0.0576, -0.1435, -0.1466,  0.0186,  0.0409, -0.1257,\n",
      "         0.2224, -0.1461, -0.3156,  0.3004,  0.1209, -0.1063,  0.0404,  0.0524,\n",
      "         0.0535, -0.2315, -0.1105,  0.1816, -0.0266,  0.1298,  0.0575, -0.2328,\n",
      "        -0.0152,  0.1232,  0.1373, -0.0524, -0.2220, -0.0088,  0.0929,  0.0339,\n",
      "        -0.2285, -0.2596,  0.1333,  0.1776, -0.2225,  0.1538, -0.2157, -0.1360,\n",
      "        -0.0216, -0.1710, -0.2906, -0.1065, -0.3147,  0.1228, -0.3278, -0.2611,\n",
      "         0.3109,  0.1165, -0.2131,  0.1377, -0.0150,  0.2369,  0.2806,  0.2806,\n",
      "         0.2607, -0.0623, -0.2149, -0.2893, -0.0703,  0.0863, -0.3005,  0.0888,\n",
      "         0.1781, -0.0500, -0.1994,  0.2013, -0.0237, -0.2668,  0.0421,  0.1723,\n",
      "        -0.2996,  0.3226,  0.3043,  0.3292, -0.0999,  0.1555, -0.1498,  0.1330,\n",
      "        -0.0434,  0.0756,  0.0726, -0.1602, -0.1328, -0.0791,  0.1629,  0.2507,\n",
      "         0.2776, -0.1497,  0.3195,  0.2389,  0.0657,  0.1494,  0.1754, -0.0415,\n",
      "         0.1298, -0.1114, -0.0551, -0.2429, -0.2023,  0.1841,  0.1162,  0.0658,\n",
      "        -0.2082, -0.2361,  0.3158, -0.2594,  0.3061,  0.1064,  0.0337,  0.2692,\n",
      "        -0.2807,  0.1108,  0.0476, -0.3088, -0.0628,  0.0587, -0.3305,  0.2141,\n",
      "        -0.1425,  0.2123,  0.1392,  0.1836, -0.2333,  0.0762,  0.0112,  0.3066,\n",
      "         0.0359,  0.1148,  0.1829,  0.0691,  0.2583,  0.0131,  0.3033, -0.1973,\n",
      "        -0.2380, -0.2803,  0.2493, -0.1095, -0.0388, -0.0870, -0.0325, -0.2505,\n",
      "         0.0262,  0.2922, -0.1221, -0.0634, -0.0908, -0.1624,  0.0948,  0.1925,\n",
      "        -0.1413,  0.2048,  0.1400, -0.2103,  0.2713, -0.1218,  0.1506,  0.2957,\n",
      "         0.2179, -0.1074, -0.0584, -0.2862, -0.2984, -0.2235, -0.2145,  0.1883,\n",
      "         0.1412,  0.3089,  0.2586,  0.0244,  0.0574,  0.1962,  0.2040, -0.0652,\n",
      "        -0.2629, -0.3079,  0.2825,  0.2376,  0.0473,  0.0081, -0.0054, -0.0305,\n",
      "         0.3170,  0.0716, -0.1399, -0.1371, -0.1862, -0.2345, -0.2775,  0.1697,\n",
      "         0.0028,  0.1521,  0.0883, -0.0959,  0.2465,  0.2257,  0.2159, -0.2740,\n",
      "        -0.1117,  0.0918,  0.2930, -0.2693, -0.1485, -0.0080,  0.2872, -0.1856,\n",
      "        -0.0826, -0.1457,  0.0165, -0.0322, -0.0529, -0.2528,  0.1842, -0.0599,\n",
      "         0.0024, -0.0464, -0.0654,  0.3159, -0.2524,  0.2671,  0.0874,  0.1342,\n",
      "        -0.0159,  0.2260,  0.1643,  0.2692,  0.1842, -0.0500, -0.1985, -0.1706,\n",
      "        -0.2857, -0.1216, -0.1953,  0.0423, -0.2934,  0.2941, -0.2294,  0.3241,\n",
      "        -0.0204,  0.3104,  0.1423,  0.1708, -0.2412,  0.1120,  0.0855,  0.1126,\n",
      "         0.2617, -0.2304,  0.1455,  0.1498,  0.1104,  0.0304,  0.1236,  0.1504,\n",
      "        -0.0426,  0.1524, -0.2444, -0.0981, -0.1210, -0.2805, -0.3270,  0.0677,\n",
      "        -0.2093, -0.2976,  0.1341, -0.1788, -0.1287, -0.1163,  0.2746,  0.2321,\n",
      "        -0.2040, -0.1538, -0.2527, -0.2285,  0.0735, -0.3254, -0.1025,  0.0578,\n",
      "         0.2837,  0.1841,  0.2918,  0.1640,  0.2761,  0.0561,  0.3005, -0.3163,\n",
      "        -0.0663,  0.1331, -0.0763,  0.2892,  0.1370,  0.1856,  0.1331,  0.2550,\n",
      "         0.1158, -0.0381,  0.2564, -0.3044,  0.3237,  0.2405,  0.0137, -0.1109,\n",
      "         0.0434, -0.0261, -0.2558, -0.1415,  0.0037, -0.0291,  0.1775,  0.0803,\n",
      "         0.3177, -0.1629,  0.2595,  0.2398,  0.0785, -0.1660, -0.1858, -0.0950,\n",
      "        -0.2518, -0.2792,  0.2752,  0.1668,  0.3182, -0.2799,  0.0520, -0.1286,\n",
      "        -0.3234, -0.0181,  0.2012, -0.0447,  0.1647,  0.1278,  0.0111,  0.0517,\n",
      "         0.1996, -0.1542, -0.1269, -0.1840,  0.3286,  0.1096,  0.0938,  0.0457,\n",
      "        -0.1655, -0.1445,  0.1613, -0.0816,  0.2634, -0.2639, -0.3086,  0.2750,\n",
      "        -0.2489, -0.1714,  0.0687,  0.2545,  0.2335,  0.2919, -0.0451,  0.2775,\n",
      "         0.1128,  0.2324, -0.2425,  0.0280,  0.2326, -0.2688,  0.2202,  0.2897,\n",
      "        -0.0833, -0.0754, -0.2470,  0.2588,  0.2829,  0.0421,  0.0986,  0.1932,\n",
      "        -0.1984, -0.3023,  0.1269, -0.0727,  0.2862,  0.1818,  0.0707, -0.2535,\n",
      "        -0.2189, -0.2825,  0.0188, -0.2509,  0.2784, -0.0159, -0.1452, -0.0587,\n",
      "         0.1630,  0.0583,  0.2238,  0.1791,  0.1559,  0.2081, -0.1858, -0.2362,\n",
      "         0.1011,  0.0772, -0.2288,  0.0202,  0.1420,  0.0941, -0.1041,  0.0915,\n",
      "         0.2314, -0.0621, -0.2662,  0.0537, -0.2726, -0.1998,  0.1288,  0.1662,\n",
      "        -0.0994, -0.1547, -0.3193, -0.0536,  0.1632, -0.2313, -0.2859, -0.3296,\n",
      "        -0.0420,  0.2952, -0.0256,  0.2363, -0.1505, -0.2134, -0.2325,  0.1649],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.0417]],\n",
      "\n",
      "         [[-0.0022]],\n",
      "\n",
      "         [[ 0.0026]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0417]],\n",
      "\n",
      "         [[-0.0222]],\n",
      "\n",
      "         [[-0.0403]]],\n",
      "\n",
      "\n",
      "        [[[-0.0073]],\n",
      "\n",
      "         [[ 0.0263]],\n",
      "\n",
      "         [[-0.0419]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0078]],\n",
      "\n",
      "         [[ 0.0082]],\n",
      "\n",
      "         [[-0.0219]]],\n",
      "\n",
      "\n",
      "        [[[-0.0122]],\n",
      "\n",
      "         [[ 0.0028]],\n",
      "\n",
      "         [[ 0.0396]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0024]],\n",
      "\n",
      "         [[ 0.0438]],\n",
      "\n",
      "         [[ 0.0245]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0289]],\n",
      "\n",
      "         [[ 0.0036]],\n",
      "\n",
      "         [[ 0.0227]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0042]],\n",
      "\n",
      "         [[-0.0116]],\n",
      "\n",
      "         [[ 0.0321]]],\n",
      "\n",
      "\n",
      "        [[[-0.0192]],\n",
      "\n",
      "         [[-0.0202]],\n",
      "\n",
      "         [[-0.0049]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0046]],\n",
      "\n",
      "         [[ 0.0359]],\n",
      "\n",
      "         [[ 0.0349]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0307]],\n",
      "\n",
      "         [[ 0.0302]],\n",
      "\n",
      "         [[-0.0097]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0027]],\n",
      "\n",
      "         [[ 0.0244]],\n",
      "\n",
      "         [[-0.0305]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 2.6168e-03, -2.4612e-02, -1.0364e-03, -3.6776e-02, -8.3364e-03,\n",
      "        -3.7345e-02, -3.9352e-02,  3.7751e-02, -9.7114e-03, -1.7257e-02,\n",
      "        -2.3959e-02, -1.0888e-02,  6.0931e-03, -1.4198e-02,  9.0146e-05,\n",
      "        -1.8936e-02, -7.6252e-03,  2.3274e-02, -4.0361e-02,  2.2470e-02,\n",
      "        -3.7851e-02,  1.2069e-02,  3.2911e-02,  1.7955e-02, -1.8781e-03,\n",
      "         4.0537e-02, -4.2481e-02, -2.9156e-03,  4.3174e-03, -3.8183e-02,\n",
      "        -1.8273e-02, -3.9164e-02, -1.5098e-02,  8.9800e-03,  3.0463e-02,\n",
      "        -8.5591e-03, -3.8093e-02,  2.2119e-02,  2.7052e-02, -3.5909e-02,\n",
      "         2.3265e-02,  2.6554e-02, -3.8022e-02,  4.8201e-03, -1.4053e-03,\n",
      "         3.7851e-02, -7.5169e-03, -6.0923e-03, -4.2490e-02,  3.9617e-02,\n",
      "         4.2578e-02,  2.5466e-02, -2.2162e-02, -2.7606e-02, -3.1943e-03,\n",
      "         2.0634e-02, -3.9686e-02, -2.4972e-02,  1.3912e-02, -3.3061e-02,\n",
      "        -3.9759e-02,  3.1587e-02, -1.3620e-02, -1.4247e-02, -3.6348e-04,\n",
      "         1.7253e-02,  1.8660e-02, -2.5899e-02, -1.1768e-02, -3.2452e-02,\n",
      "         4.1446e-02, -3.7721e-02, -1.8099e-02,  4.2410e-02,  2.7351e-02,\n",
      "         4.1574e-02, -3.2769e-02,  3.5995e-02,  4.0357e-02, -1.7161e-02,\n",
      "        -3.8672e-02,  2.8324e-02,  3.7205e-02, -1.1273e-02,  1.7921e-03,\n",
      "        -2.3074e-02, -2.5887e-02,  6.8764e-03,  3.8677e-02,  2.7366e-02,\n",
      "         2.0783e-03, -3.4403e-02, -3.1761e-02, -1.1041e-03, -1.0387e-02,\n",
      "         1.6527e-02, -2.5109e-02, -2.2367e-02, -4.2969e-02, -9.9040e-03,\n",
      "        -1.3310e-02, -3.5844e-02,  7.4530e-03, -9.9075e-03, -1.5713e-02,\n",
      "         1.8595e-02,  2.7794e-02,  4.3702e-02, -1.0472e-02,  2.2146e-02,\n",
      "         2.0108e-02,  3.9731e-02, -1.9743e-02,  8.3971e-03,  2.8753e-02,\n",
      "        -1.5411e-02, -4.1337e-04, -9.9964e-03,  2.4468e-02,  6.0860e-03,\n",
      "        -1.0178e-02,  3.8866e-02, -4.2143e-02,  3.9716e-02,  1.8115e-02,\n",
      "         1.6723e-02, -7.8887e-03, -2.7388e-02, -4.1238e-02, -6.9678e-03,\n",
      "        -4.3215e-02,  2.0424e-02, -2.6768e-02,  3.3546e-02,  1.0052e-02,\n",
      "        -3.9449e-02,  3.3264e-02, -5.8097e-03, -1.6902e-02,  1.1091e-02,\n",
      "         7.6929e-03,  5.6869e-03, -4.1172e-02,  2.2883e-02, -1.6533e-03,\n",
      "         6.6267e-03,  1.6574e-02, -1.0737e-02,  2.9564e-02, -1.3448e-02,\n",
      "         1.6881e-02,  2.8358e-02, -3.7249e-02,  3.4052e-02,  1.6225e-02,\n",
      "         7.8993e-03, -1.9327e-03,  3.0462e-02, -3.7805e-02, -3.3734e-02,\n",
      "         1.5477e-02,  3.6564e-02,  1.5342e-02, -7.3140e-03, -2.5444e-02,\n",
      "         2.5055e-02,  5.8824e-03, -1.1675e-02,  2.7383e-02, -3.3940e-02,\n",
      "        -1.1312e-02,  8.9052e-03, -8.8225e-03, -4.2565e-02,  4.2487e-02,\n",
      "        -3.5105e-02,  4.3883e-03,  1.0888e-02,  3.2280e-04, -1.6595e-02,\n",
      "         7.1208e-03, -2.0986e-02,  2.4089e-02,  1.6937e-02, -3.4131e-02,\n",
      "         3.4505e-02,  2.6007e-02,  2.8962e-02,  1.5831e-02, -2.9045e-02,\n",
      "        -2.5593e-02, -2.8219e-02,  2.9580e-02, -7.0690e-03, -6.2863e-03,\n",
      "         1.8350e-03, -3.5196e-02, -3.5091e-02,  5.0324e-03,  1.4600e-02,\n",
      "        -4.4783e-03, -2.5719e-02, -3.2079e-02, -2.9468e-02,  4.2905e-02,\n",
      "        -3.8319e-02,  2.2723e-02,  1.2874e-02,  2.0940e-02,  9.5115e-03,\n",
      "         3.2996e-02,  1.3757e-02,  1.2348e-02,  3.6731e-02, -4.7987e-03,\n",
      "         3.5407e-02, -3.7552e-02, -2.8952e-03, -1.8006e-02, -1.7647e-02,\n",
      "         1.2376e-02, -2.4740e-02, -3.3229e-02,  1.7705e-02, -1.0625e-02,\n",
      "         2.8079e-02,  4.1676e-02,  4.1301e-02, -2.0643e-02, -1.4556e-02,\n",
      "        -3.0518e-02,  9.6811e-03, -3.1908e-02, -1.8216e-02, -3.1102e-02,\n",
      "         3.8518e-02,  2.6571e-02, -3.8168e-02,  4.3185e-02,  3.5330e-02,\n",
      "        -3.3911e-02,  6.5330e-03,  3.4470e-02,  1.7159e-02, -1.6844e-02,\n",
      "        -2.2626e-02,  2.1862e-02,  2.9493e-02, -4.4827e-03,  2.3709e-02,\n",
      "        -8.2880e-03, -2.9074e-02, -3.9638e-02,  3.0786e-02, -7.7617e-04,\n",
      "        -8.9556e-03,  9.1354e-05,  1.8888e-02,  4.2704e-02, -2.4172e-03,\n",
      "        -1.4491e-02,  4.3567e-02, -5.4616e-03,  2.3764e-02, -3.3552e-02,\n",
      "         2.1777e-02,  2.6201e-02,  2.4667e-02, -3.3227e-02,  7.6340e-04,\n",
      "         3.5435e-02, -1.5260e-02,  2.7237e-02, -8.3800e-03, -6.1152e-03,\n",
      "        -4.5759e-03, -1.8788e-02, -1.3069e-02,  2.0218e-02,  2.6539e-02,\n",
      "        -4.9373e-03,  4.0137e-02,  1.3308e-02, -3.6936e-02, -1.9419e-02,\n",
      "        -4.0391e-02,  3.8726e-02,  1.7727e-02, -3.3715e-02,  3.9477e-02,\n",
      "        -1.8869e-02,  1.9876e-02, -2.0835e-02,  4.3035e-02,  3.0034e-02,\n",
      "         3.3912e-02, -6.9214e-03,  7.0887e-03,  3.3563e-02, -1.9250e-02,\n",
      "         2.3526e-02, -3.7841e-02, -1.7968e-02, -1.4815e-02,  1.0238e-02,\n",
      "         1.6825e-02, -2.5808e-02, -1.9102e-02,  1.3456e-02, -1.6291e-02,\n",
      "        -1.4040e-03,  1.7487e-02, -3.6018e-02, -7.2576e-03, -4.0512e-02,\n",
      "        -9.1199e-03, -2.0468e-02,  7.6767e-03,  1.3122e-02, -1.6996e-02,\n",
      "         3.0491e-03, -3.5524e-02,  1.1484e-02,  1.1055e-02,  1.3705e-02,\n",
      "         1.6428e-02, -1.3570e-02, -2.4837e-02,  4.1299e-03, -3.9158e-03,\n",
      "         1.8806e-02,  1.4930e-02, -1.3928e-02,  2.7471e-02, -4.3966e-02,\n",
      "         1.5969e-02,  3.4666e-02,  2.5204e-02, -1.8274e-02, -1.1403e-02,\n",
      "        -3.4878e-02, -4.3044e-03,  3.6104e-02,  2.6604e-02,  1.9730e-02,\n",
      "        -3.9576e-02, -5.0026e-03, -1.9609e-03,  9.4069e-03, -4.3547e-02,\n",
      "        -3.1436e-02, -1.3938e-02, -3.2633e-02,  2.2824e-02, -2.2868e-02,\n",
      "        -3.0687e-02,  3.3513e-02,  3.3101e-02, -1.6945e-02,  3.8079e-02,\n",
      "        -3.5296e-02, -3.0363e-02,  3.1938e-02, -7.8892e-04, -3.5840e-02,\n",
      "         2.7809e-02,  2.4050e-02, -2.0448e-02,  2.1973e-02,  5.5258e-04,\n",
      "        -1.4267e-02, -3.6555e-02,  3.9919e-02, -2.0428e-02, -1.2396e-02,\n",
      "        -3.8948e-02,  9.0732e-03, -1.1540e-03, -2.1741e-02, -1.4914e-02,\n",
      "        -1.4262e-02, -2.9294e-02,  7.7256e-03,  1.7424e-02,  2.8783e-02,\n",
      "         2.8753e-02, -1.1619e-02, -5.3573e-03,  8.4102e-03, -3.3961e-02,\n",
      "         2.5317e-02,  4.0724e-02,  3.3491e-02, -2.1345e-02,  2.0195e-02,\n",
      "         2.6919e-02,  1.9540e-02,  2.7887e-02, -1.7146e-02, -2.3412e-02,\n",
      "        -2.9696e-02,  4.2240e-02, -2.6451e-02, -4.1485e-02,  4.4151e-02,\n",
      "        -3.1220e-02,  6.9449e-03, -3.9078e-02, -2.9591e-02,  8.6056e-03,\n",
      "        -3.2075e-02, -8.5547e-03, -3.2555e-02, -1.6329e-02, -3.9004e-04,\n",
      "         3.2457e-02,  7.3811e-03, -4.0339e-02,  1.1492e-02, -7.8988e-03,\n",
      "         1.5500e-02, -2.3056e-02, -3.8226e-02, -2.9411e-02,  3.3598e-02,\n",
      "         2.4426e-02,  1.3425e-02,  7.0012e-03, -4.8561e-03,  3.9868e-02,\n",
      "        -3.5206e-02,  3.0863e-02,  2.0406e-02,  1.7130e-02, -1.8819e-02,\n",
      "        -1.1758e-02, -5.5665e-03, -1.4315e-02, -2.6050e-02,  4.2906e-02,\n",
      "        -3.9119e-02,  3.4867e-02,  7.6403e-03, -1.0725e-02,  6.5638e-03,\n",
      "        -1.1382e-03, -7.3199e-03, -4.4018e-03, -3.6939e-02,  1.6890e-02,\n",
      "        -1.3958e-02, -3.3056e-02,  3.2475e-02,  8.8391e-04, -7.6714e-03,\n",
      "         3.6456e-02,  4.0050e-03, -2.6109e-02,  2.4002e-02, -4.1629e-02,\n",
      "         9.6903e-03, -3.3120e-02, -3.2763e-02,  3.9755e-03,  1.4921e-02,\n",
      "        -1.2897e-02, -2.1056e-02,  2.8003e-03, -1.0130e-02,  2.5692e-02,\n",
      "        -3.4322e-02,  2.1681e-02,  4.3924e-03, -2.7845e-02, -2.7036e-02,\n",
      "         4.3766e-02, -3.5775e-03,  3.6624e-02, -1.5222e-02,  2.0649e-02,\n",
      "         4.4094e-02,  6.3147e-03,  3.4489e-02,  4.0737e-02, -1.8047e-02,\n",
      "        -3.3950e-02, -1.7290e-02,  1.6736e-02,  8.6823e-03,  8.0045e-03,\n",
      "         4.3820e-02,  1.1669e-02, -3.2419e-02,  2.9003e-02,  1.7870e-02,\n",
      "        -2.1590e-02,  3.3377e-02, -3.5294e-02, -7.4365e-03, -1.5253e-02,\n",
      "        -7.8718e-03,  2.0496e-02,  1.6832e-02, -3.7135e-02, -2.8473e-02,\n",
      "        -1.4209e-02, -3.2605e-02,  3.2722e-02,  2.2046e-02,  1.6662e-02,\n",
      "        -2.9239e-03, -4.1341e-03], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 0.3103,  0.1550, -0.2315],\n",
      "          [-0.0435, -0.3215,  0.2194],\n",
      "          [-0.2159, -0.1707,  0.1250]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2833, -0.0387,  0.2170],\n",
      "          [ 0.0924, -0.0976,  0.1691],\n",
      "          [ 0.2699,  0.1532, -0.3158]]],\n",
      "\n",
      "\n",
      "        [[[-0.1403, -0.0508,  0.3277],\n",
      "          [ 0.0607,  0.0480,  0.1480],\n",
      "          [ 0.1532, -0.1582,  0.0584]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2299,  0.0586, -0.0278],\n",
      "          [ 0.3253,  0.2045,  0.2316],\n",
      "          [ 0.0957, -0.0705,  0.1474]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3232, -0.1792,  0.3269],\n",
      "          [ 0.1162, -0.1300, -0.0487],\n",
      "          [-0.2247, -0.1822,  0.1963]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1446, -0.1223, -0.1785],\n",
      "          [-0.0034,  0.0588,  0.0782],\n",
      "          [ 0.1886, -0.2446,  0.2751]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-9.9880e-02, -1.6344e-01,  9.2195e-02,  1.3374e-01, -1.3960e-01,\n",
      "         3.0434e-02,  1.9804e-01, -3.3234e-01, -1.4036e-02,  4.2593e-02,\n",
      "         2.3655e-01, -2.2139e-01,  2.8901e-01,  1.6208e-01,  6.3232e-02,\n",
      "        -2.3159e-01,  3.1059e-01,  2.3544e-01,  1.5747e-02, -2.4275e-01,\n",
      "        -2.2337e-01, -8.1015e-02, -1.9780e-01,  1.9333e-02,  2.7105e-01,\n",
      "         1.8952e-01,  2.2686e-01, -2.9381e-01, -2.9462e-01,  2.7941e-02,\n",
      "         2.7113e-01,  3.2181e-01, -1.5050e-01,  2.0780e-01,  7.2082e-02,\n",
      "        -5.9243e-02,  7.8477e-02,  2.7116e-01, -2.6728e-02, -9.1470e-02,\n",
      "         1.0067e-01,  1.8444e-01,  2.0111e-01,  1.4348e-01,  2.1867e-02,\n",
      "        -1.8791e-01, -2.5268e-01, -1.6486e-01, -2.3119e-01,  1.1186e-01,\n",
      "        -3.1380e-01,  2.8704e-02,  2.5072e-01,  4.9486e-02,  2.2994e-01,\n",
      "        -1.8935e-01, -2.5172e-02,  1.6984e-01,  3.2852e-01,  1.5467e-01,\n",
      "        -4.3718e-02, -3.3029e-01,  1.9720e-01, -8.1928e-02, -4.7686e-02,\n",
      "        -3.5659e-02,  7.1523e-02,  7.0106e-02,  2.0735e-01, -1.0336e-01,\n",
      "         3.0464e-01,  2.1923e-01,  2.1962e-01, -6.2779e-02,  8.5219e-02,\n",
      "        -1.9261e-01,  5.7601e-02, -1.7941e-01,  1.1021e-01, -2.4890e-01,\n",
      "        -8.8819e-02,  1.8469e-01, -5.5773e-02, -9.1933e-02,  2.2616e-01,\n",
      "         2.6617e-01,  5.5954e-02, -3.0410e-01, -3.2670e-02,  2.4585e-01,\n",
      "         1.9548e-01, -2.1237e-01, -2.9750e-01, -2.6645e-01,  1.2032e-01,\n",
      "        -4.3605e-03,  6.8719e-02, -4.2093e-02,  1.3477e-01, -2.5608e-01,\n",
      "        -2.8728e-01, -1.1173e-01,  3.2329e-01, -1.1264e-01, -6.0350e-02,\n",
      "         1.0179e-02, -3.2601e-01,  1.2684e-01, -2.0972e-01, -2.6959e-01,\n",
      "         1.7970e-01,  2.1773e-01,  8.4611e-02,  3.2753e-01, -3.0053e-01,\n",
      "        -2.8767e-01, -1.3943e-01,  2.4861e-01, -2.4007e-02,  2.8805e-01,\n",
      "         2.2209e-01,  7.7760e-02,  3.0278e-01, -2.1867e-01,  2.7765e-01,\n",
      "        -2.5134e-01,  3.6401e-02,  7.4018e-02,  2.2127e-01,  1.1757e-01,\n",
      "        -1.9655e-01,  4.2743e-02, -2.1839e-01,  1.8052e-01, -3.2228e-01,\n",
      "        -2.7574e-01,  2.7312e-01,  3.0695e-01, -2.1586e-02,  3.3195e-01,\n",
      "         1.1274e-01, -1.0742e-01,  1.6062e-01, -1.2886e-02, -1.8571e-01,\n",
      "         7.5765e-02,  2.0433e-01,  8.7395e-02, -3.2624e-01, -3.0753e-01,\n",
      "         2.0554e-02, -2.0828e-01,  3.1255e-01,  2.8632e-01, -2.8913e-02,\n",
      "        -1.3989e-01, -1.8385e-02,  2.5768e-01, -8.8050e-02, -7.9124e-02,\n",
      "         8.1309e-02, -2.8991e-01, -2.5406e-01, -9.3475e-02, -2.6836e-01,\n",
      "        -2.3788e-01,  1.2507e-01,  1.8546e-01,  2.4988e-01, -1.0893e-02,\n",
      "        -2.8751e-01,  1.9972e-01, -7.6851e-02,  5.1233e-02,  1.8123e-01,\n",
      "         2.6776e-01,  2.1279e-01, -2.6144e-01,  8.5906e-03,  2.2215e-01,\n",
      "        -2.3570e-01,  3.2818e-01, -2.1508e-01, -1.7180e-01,  2.2588e-01,\n",
      "        -2.2038e-01, -2.8696e-01, -2.0420e-01,  1.8893e-01,  1.5468e-01,\n",
      "        -2.6562e-01, -1.1663e-01, -4.2191e-02,  5.4305e-02,  3.0105e-01,\n",
      "         1.7237e-01,  2.3704e-01,  1.0400e-01, -2.4023e-01,  1.0271e-01,\n",
      "        -3.2678e-01,  2.1428e-01, -2.6410e-01,  1.1486e-01,  2.5036e-02,\n",
      "         1.1233e-01, -8.4876e-02,  2.7018e-01, -7.9530e-02,  1.3702e-01,\n",
      "         3.1772e-01,  2.8079e-01, -1.4350e-01,  1.4535e-01, -2.8936e-01,\n",
      "         1.1607e-01,  1.3052e-01,  1.8621e-01, -2.8701e-01, -2.6217e-01,\n",
      "         1.5208e-01,  2.4377e-01,  2.9419e-01, -4.3973e-02, -1.8879e-01,\n",
      "         2.5013e-01,  1.0475e-01, -2.2543e-01, -6.7733e-02, -2.7129e-01,\n",
      "        -7.6897e-02,  2.6240e-01,  2.6662e-01, -7.3147e-02,  4.8096e-02,\n",
      "        -1.4344e-01,  4.8103e-02, -1.0287e-01, -2.5727e-01, -1.8463e-01,\n",
      "         2.8780e-01, -8.8833e-02,  1.3314e-01,  1.4618e-01,  2.2963e-01,\n",
      "        -1.2600e-01,  3.0210e-02, -2.8262e-01, -2.7284e-01, -2.7485e-01,\n",
      "        -2.0080e-01,  2.8325e-01,  2.4894e-01,  1.0782e-01, -1.4531e-01,\n",
      "         1.0747e-01,  2.3697e-01,  1.1414e-01, -1.8600e-01, -2.3661e-02,\n",
      "         8.7497e-02, -1.9929e-01, -1.7216e-01,  1.3125e-01, -1.8491e-01,\n",
      "         2.8522e-01,  2.2395e-01, -2.7842e-01,  8.7477e-02, -2.4249e-01,\n",
      "        -2.2737e-02, -5.9536e-02, -1.8952e-01,  5.0754e-02, -1.7293e-01,\n",
      "        -6.5205e-02, -1.9299e-01,  2.6207e-01, -2.1910e-01, -2.2393e-01,\n",
      "        -2.2619e-01,  5.1313e-02,  2.1271e-01, -1.9285e-02, -8.0904e-02,\n",
      "        -8.1008e-02,  1.6333e-01, -5.2517e-02,  3.2827e-02,  5.6332e-02,\n",
      "         1.0064e-01,  1.7444e-01,  1.8087e-01,  1.2096e-01,  1.6209e-01,\n",
      "         2.6584e-01, -1.8513e-01, -3.2727e-01,  2.8520e-01, -2.6121e-01,\n",
      "         9.4826e-02,  1.4955e-01,  1.2170e-01, -2.8930e-01,  4.7551e-02,\n",
      "         2.7612e-01,  1.8435e-01,  2.4787e-01,  6.4497e-03, -9.0488e-02,\n",
      "        -5.1910e-02, -4.1841e-02,  2.7849e-01,  2.1283e-01,  1.9679e-01,\n",
      "         3.2310e-01, -2.3851e-01,  7.6403e-02, -1.8799e-01, -1.1460e-01,\n",
      "        -3.3149e-01,  2.6231e-01,  6.7202e-02, -2.6279e-02,  3.3961e-03,\n",
      "        -5.8729e-02,  3.2007e-01, -8.5074e-02,  1.8185e-01, -2.6071e-01,\n",
      "         1.3069e-01,  7.7898e-02,  1.6109e-01,  1.6420e-01,  2.1465e-02,\n",
      "        -1.5499e-01, -2.8991e-01, -2.8108e-02,  2.3267e-01, -2.8225e-01,\n",
      "        -2.7330e-01, -1.9278e-01,  3.1018e-01,  2.9207e-01, -1.8993e-01,\n",
      "        -2.9792e-01, -2.0430e-01,  2.6500e-01, -1.1078e-01, -2.1658e-01,\n",
      "         7.7660e-02, -2.7543e-01,  1.6859e-01,  1.2478e-01,  1.9209e-01,\n",
      "        -4.3056e-03,  3.3210e-01, -2.3060e-01, -6.0894e-02, -3.8105e-02,\n",
      "        -2.4490e-01,  2.2171e-01, -8.0166e-02,  8.0495e-02, -2.6635e-01,\n",
      "        -2.3098e-01, -2.6946e-01,  3.2504e-01,  1.4165e-01,  2.4369e-02,\n",
      "         1.6668e-01, -2.7590e-01,  1.5348e-01,  2.8838e-01,  3.4275e-02,\n",
      "         2.8726e-01,  2.3098e-01,  1.2170e-01, -8.2810e-02,  2.0080e-01,\n",
      "        -2.0662e-01,  1.3617e-01,  1.9436e-02,  1.5647e-01,  7.1244e-03,\n",
      "         2.4270e-01, -2.3822e-01,  5.6242e-02,  2.8841e-01,  1.9070e-01,\n",
      "        -2.5541e-02, -2.7688e-01, -2.9831e-01, -8.8197e-02,  2.9828e-01,\n",
      "        -2.4921e-01, -4.6624e-02, -1.3635e-01,  2.5686e-01, -1.2658e-01,\n",
      "         3.0374e-01, -1.5380e-02, -2.3742e-01,  2.6284e-01, -8.1176e-02,\n",
      "        -2.4302e-01, -1.6395e-01, -3.0626e-01,  1.7164e-01, -2.7154e-01,\n",
      "        -1.2517e-01, -3.1964e-01,  1.7065e-01,  2.4656e-01, -1.1118e-01,\n",
      "        -2.7672e-01, -3.2864e-01,  2.2640e-01, -1.0610e-01,  2.1843e-01,\n",
      "         8.5204e-02,  2.7719e-01, -2.2346e-01,  1.1785e-01,  2.5494e-02,\n",
      "         3.2575e-01,  1.9779e-01,  1.0649e-01, -1.0814e-01,  3.2524e-01,\n",
      "        -2.9033e-01,  2.8511e-01, -2.6942e-01, -3.2456e-01, -3.1671e-04,\n",
      "        -1.7151e-01,  2.6095e-01,  6.4447e-02, -6.0897e-02,  9.2792e-02,\n",
      "        -2.1341e-01,  1.3994e-01,  6.8379e-02, -3.0790e-01,  1.5567e-02,\n",
      "        -2.7181e-01, -2.2856e-02,  1.8820e-01, -2.1627e-02,  2.8385e-01,\n",
      "        -8.5608e-02,  1.0802e-01,  2.8220e-01, -4.1235e-02, -1.4554e-01,\n",
      "        -1.7169e-01, -8.9741e-02, -2.9912e-01,  2.2254e-01, -5.7414e-02,\n",
      "         3.0674e-02,  1.4079e-01,  2.5509e-01,  2.3987e-01,  7.6661e-02,\n",
      "         5.6169e-02,  2.1548e-01, -3.1683e-01,  1.4021e-01,  2.2935e-01,\n",
      "         3.1592e-01, -2.7051e-01,  1.0782e-01,  1.5911e-01,  9.4991e-02,\n",
      "        -2.6233e-01, -2.9104e-01,  2.4827e-01, -3.0496e-01,  1.8180e-01,\n",
      "        -7.9598e-02, -3.3068e-01,  2.9484e-01,  1.9366e-01,  2.0895e-01,\n",
      "        -1.1510e-01, -7.1730e-02, -3.2713e-01, -1.6066e-01, -4.4810e-02,\n",
      "        -1.3269e-01,  2.3218e-02, -2.3694e-01, -4.9775e-02,  1.2542e-01,\n",
      "         2.7806e-01,  1.6248e-01,  4.9799e-02,  1.2911e-01,  4.7567e-03,\n",
      "        -3.0405e-02,  2.9595e-01, -2.2848e-01,  1.9159e-01,  3.1775e-03,\n",
      "         2.9760e-01,  3.5091e-02, -1.2971e-01,  3.1494e-01,  2.3439e-01,\n",
      "         8.6951e-02, -1.2447e-02], requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 0.0378]],\n",
      "\n",
      "         [[ 0.0284]],\n",
      "\n",
      "         [[ 0.0179]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0303]],\n",
      "\n",
      "         [[ 0.0308]],\n",
      "\n",
      "         [[-0.0033]]],\n",
      "\n",
      "\n",
      "        [[[-0.0324]],\n",
      "\n",
      "         [[ 0.0320]],\n",
      "\n",
      "         [[-0.0211]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0378]],\n",
      "\n",
      "         [[ 0.0301]],\n",
      "\n",
      "         [[-0.0322]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0069]],\n",
      "\n",
      "         [[ 0.0381]],\n",
      "\n",
      "         [[ 0.0208]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0091]],\n",
      "\n",
      "         [[ 0.0143]],\n",
      "\n",
      "         [[-0.0163]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0284]],\n",
      "\n",
      "         [[ 0.0368]],\n",
      "\n",
      "         [[ 0.0202]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0130]],\n",
      "\n",
      "         [[ 0.0367]],\n",
      "\n",
      "         [[-0.0114]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0437]],\n",
      "\n",
      "         [[-0.0198]],\n",
      "\n",
      "         [[-0.0354]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0412]],\n",
      "\n",
      "         [[-0.0046]],\n",
      "\n",
      "         [[ 0.0092]]],\n",
      "\n",
      "\n",
      "        [[[-0.0041]],\n",
      "\n",
      "         [[ 0.0041]],\n",
      "\n",
      "         [[ 0.0421]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0135]],\n",
      "\n",
      "         [[-0.0336]],\n",
      "\n",
      "         [[ 0.0104]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 3.2608e-02,  4.0889e-02,  8.9738e-03, -3.5594e-02, -8.9181e-03,\n",
      "        -2.8541e-02, -3.7890e-02, -2.9687e-02, -3.3264e-02, -1.8955e-02,\n",
      "         1.6987e-02, -3.3205e-02, -3.1301e-02, -3.7293e-02,  2.5000e-02,\n",
      "         9.7998e-03, -3.8328e-02,  4.3097e-03, -4.3062e-02,  3.2189e-03,\n",
      "        -2.9565e-02,  3.7432e-02,  2.7761e-02, -1.2916e-02, -1.5350e-02,\n",
      "         3.6862e-02,  4.0566e-02,  4.6199e-03, -2.0330e-03,  2.1389e-02,\n",
      "        -3.8812e-02,  1.0063e-02, -3.6624e-02, -2.6547e-02, -2.5559e-02,\n",
      "         3.7684e-02, -3.3292e-02, -2.9825e-02, -3.1175e-02,  1.6768e-02,\n",
      "         3.6558e-03, -2.9670e-02,  4.6656e-03, -3.0086e-03, -2.1151e-03,\n",
      "        -3.6751e-02, -1.4825e-02, -2.4991e-03,  6.2899e-05,  2.7140e-02,\n",
      "         3.2172e-02, -2.5621e-02,  2.2939e-02, -1.7647e-02,  2.5340e-03,\n",
      "        -3.5065e-02,  4.1435e-02,  1.2483e-02,  1.9932e-02, -4.2209e-02,\n",
      "        -1.9394e-02,  3.2766e-02,  1.1633e-02,  2.9822e-02, -1.3565e-03,\n",
      "         3.9725e-02, -5.3320e-03,  4.0589e-02,  2.0830e-03,  2.1901e-03,\n",
      "         1.1936e-02,  5.3118e-03, -4.2244e-02,  1.0162e-02, -1.9428e-02,\n",
      "         3.3201e-02, -2.0756e-02, -1.5799e-02,  2.3113e-02,  3.1565e-02,\n",
      "         2.9338e-02,  3.8037e-02,  3.8446e-02, -3.1598e-02, -3.6381e-02,\n",
      "         5.2126e-04, -1.4333e-02, -6.1290e-03,  6.3475e-03,  2.0292e-02,\n",
      "        -2.3718e-02,  2.8489e-03, -3.8330e-02, -2.9544e-02, -1.9201e-02,\n",
      "        -2.7535e-02, -9.4770e-03,  2.6762e-02, -3.3265e-02, -3.8660e-02,\n",
      "        -1.7532e-02, -3.6828e-02, -2.4606e-02,  3.4123e-02, -1.9178e-02,\n",
      "        -3.5877e-02, -4.2469e-02,  2.7751e-03,  1.6108e-02, -3.2105e-02,\n",
      "         3.1160e-02,  3.3746e-02, -2.6288e-02, -3.8751e-02, -1.5915e-02,\n",
      "        -1.0219e-03,  3.3599e-02, -2.3223e-02, -2.3787e-03, -1.7775e-02,\n",
      "         1.5239e-02,  5.0140e-03,  3.4303e-02, -4.0788e-02,  1.1109e-03,\n",
      "        -1.9078e-02,  1.1329e-02,  2.1170e-02, -7.2185e-03, -1.0045e-02,\n",
      "         1.6412e-02, -3.6961e-03,  1.5762e-02, -3.0159e-03,  3.2104e-02,\n",
      "        -1.5176e-02,  4.1517e-02,  4.2848e-02,  2.8173e-02,  1.8094e-02,\n",
      "         2.4522e-03,  2.2971e-02, -1.4257e-02, -2.0793e-02, -1.7680e-02,\n",
      "         2.9624e-02,  7.6981e-04, -3.1527e-02,  3.1139e-02, -3.8311e-02,\n",
      "         6.4750e-03, -2.8709e-02,  1.6849e-02, -1.5301e-02,  3.7891e-02,\n",
      "        -1.4062e-02, -3.0280e-02,  4.4141e-02, -1.9725e-03,  4.3912e-02,\n",
      "        -1.2845e-02, -6.6734e-03,  6.8379e-03, -7.6894e-04,  3.9919e-02,\n",
      "        -1.0380e-02,  7.0397e-03,  9.8125e-04, -2.9563e-02, -1.9355e-02,\n",
      "         2.5023e-02,  1.6487e-02, -3.8895e-02,  1.2003e-02, -2.9308e-02,\n",
      "         2.7323e-02, -3.1793e-02,  4.1134e-03,  2.5745e-02, -2.6339e-02,\n",
      "        -1.2189e-02,  2.2765e-02,  3.3642e-02,  4.3888e-03, -2.2725e-03,\n",
      "        -3.7683e-02, -1.7301e-02, -1.3245e-02,  2.2692e-02, -4.1484e-02,\n",
      "         2.2281e-02, -3.1279e-03, -3.9291e-04,  1.9414e-02,  2.1734e-02,\n",
      "         2.0918e-02,  1.9048e-02,  1.0031e-02,  1.7761e-02,  3.1117e-02,\n",
      "        -1.1219e-03, -2.1569e-02,  1.0955e-02,  5.9155e-03,  3.4263e-02,\n",
      "        -2.4441e-02, -1.1606e-02, -1.2605e-02, -1.2729e-02, -1.0603e-02,\n",
      "         5.5768e-03, -3.7598e-02,  2.8091e-02,  1.1502e-02, -2.3436e-02,\n",
      "         4.2894e-02, -4.0937e-02, -3.2354e-02, -3.2631e-02,  9.0222e-03,\n",
      "        -2.8636e-02, -1.6790e-02, -3.1362e-02,  2.9369e-02,  7.2193e-03,\n",
      "        -3.6000e-02, -1.8899e-02, -3.8804e-02, -3.7577e-02,  4.1721e-02,\n",
      "         8.7648e-03,  1.0181e-02,  3.7228e-02, -3.8004e-03,  2.5435e-02,\n",
      "        -4.3297e-02, -8.1439e-03, -4.2099e-02,  7.6901e-03,  4.4131e-02,\n",
      "        -3.5383e-02,  2.1265e-04,  3.9358e-03, -4.8873e-03, -3.0212e-02,\n",
      "        -2.4442e-02, -2.2218e-02,  3.7876e-02,  1.6188e-02,  1.8555e-02,\n",
      "         7.9434e-03,  2.3157e-02,  3.5236e-02, -1.5043e-03,  1.7259e-02,\n",
      "        -4.3210e-02,  1.0716e-02, -3.7404e-02,  1.4954e-02, -6.7945e-03,\n",
      "         1.8417e-02,  5.9726e-04, -1.5838e-02,  1.1609e-02,  3.5047e-02,\n",
      "        -2.5749e-02,  1.2514e-02,  8.8462e-03,  1.6764e-02,  4.1083e-02,\n",
      "        -2.2324e-02, -1.7156e-02, -2.7651e-02,  1.0878e-02,  2.4307e-02,\n",
      "         2.6822e-02, -2.6379e-02, -3.1588e-02, -3.6934e-02, -4.0531e-02,\n",
      "         3.4295e-02,  4.3704e-03, -3.2333e-02, -1.1023e-02, -2.2617e-02,\n",
      "         4.1740e-02,  3.8887e-02,  1.6261e-02, -3.7339e-02,  2.9405e-03,\n",
      "         2.5197e-02, -3.3468e-03,  2.3487e-04, -2.2708e-02,  1.7173e-02,\n",
      "        -1.4952e-02, -1.6378e-02, -1.0588e-02,  3.1210e-02,  4.0085e-02,\n",
      "         1.6330e-02,  3.7381e-02,  3.1128e-02,  6.9281e-04, -2.3242e-02,\n",
      "        -1.2977e-02, -2.6605e-02,  2.0131e-02,  2.0735e-02, -2.9507e-02,\n",
      "        -2.7814e-02, -2.8938e-02, -4.4856e-03,  4.7587e-03,  4.4174e-02,\n",
      "        -2.5785e-02,  4.1625e-02,  1.9752e-02, -1.7816e-02, -1.7950e-02,\n",
      "         3.5071e-02, -7.3111e-03, -1.6441e-02, -1.3259e-02, -2.5118e-02,\n",
      "         1.6242e-02, -4.0830e-02,  3.5346e-02, -4.0304e-02,  4.1963e-02,\n",
      "        -1.7524e-02, -3.1648e-03, -2.3117e-02, -8.7044e-03,  4.0677e-02,\n",
      "         4.1514e-02, -2.9771e-03, -6.8902e-03, -8.7094e-04,  1.7611e-04,\n",
      "         3.5406e-02,  2.0379e-02,  2.2141e-02, -2.0527e-02,  4.2125e-02,\n",
      "         1.0285e-02, -1.4930e-02, -2.9140e-02, -1.7763e-03, -9.9329e-03,\n",
      "         3.9919e-02,  1.1659e-02, -1.7311e-02, -3.8629e-02, -1.1554e-02,\n",
      "        -2.1645e-02, -4.1341e-02, -1.3690e-02,  1.0942e-02, -1.7032e-02,\n",
      "        -7.2921e-03,  2.1404e-02,  3.0027e-02,  3.5136e-02,  1.4216e-02,\n",
      "        -3.2471e-02,  1.1379e-02,  3.4799e-02, -1.4051e-02,  3.5999e-02,\n",
      "         2.8487e-02, -3.0714e-02,  3.6391e-02,  1.8893e-02,  2.7220e-02,\n",
      "        -2.1287e-02,  3.3296e-02,  3.6676e-02,  2.7829e-02,  1.4635e-02,\n",
      "         9.9107e-03,  1.4628e-02,  5.2271e-03, -8.6846e-03, -3.7643e-02,\n",
      "         1.6310e-02,  1.2576e-02, -2.2085e-02,  2.8450e-03,  2.9090e-02,\n",
      "        -4.1149e-02,  2.0695e-03,  3.4328e-02, -8.6001e-03, -1.4861e-02,\n",
      "         4.4173e-03,  4.1668e-02, -1.9135e-02, -3.3115e-02, -1.5674e-02,\n",
      "         1.7135e-02, -2.4571e-02, -1.8016e-03, -3.6188e-02,  2.4010e-02,\n",
      "        -2.1938e-02, -2.6042e-02, -3.1496e-02,  9.9184e-03,  3.3649e-02,\n",
      "         1.0461e-02, -4.1861e-02,  2.7128e-03, -2.7642e-02, -1.9219e-02,\n",
      "         3.7925e-02,  3.8978e-02, -2.4730e-02,  8.4501e-03, -4.2357e-02,\n",
      "        -2.0946e-02, -3.4309e-02,  2.4342e-02, -4.2374e-02,  2.3294e-02,\n",
      "         9.4403e-03, -2.5460e-02, -4.3641e-02, -9.2229e-03,  3.7323e-02,\n",
      "         2.4688e-03,  3.6435e-02, -5.4678e-03, -2.4202e-02, -1.8368e-02,\n",
      "         2.2924e-02, -2.8881e-02, -1.8333e-02,  3.1499e-02, -9.9680e-03,\n",
      "        -2.9507e-02,  3.1012e-02,  4.4053e-02, -3.6694e-03, -3.9728e-02,\n",
      "         1.4465e-02,  2.4678e-02, -2.7394e-02,  8.4738e-03, -1.3815e-02,\n",
      "        -2.0059e-02,  2.9456e-02,  3.1793e-02, -3.5828e-02, -2.8042e-02,\n",
      "        -3.5215e-02, -1.6995e-03,  4.4171e-04,  3.9012e-02, -1.1933e-02,\n",
      "         2.9567e-03, -3.5197e-02, -3.0814e-02,  5.9577e-03, -2.2039e-02,\n",
      "         5.4218e-03, -1.7377e-04,  1.2769e-02, -6.9266e-03,  3.3271e-02,\n",
      "         2.4225e-02, -3.2425e-02,  1.9405e-02,  3.2140e-02,  3.0877e-02,\n",
      "        -2.5072e-02,  3.2492e-02, -2.6614e-02,  1.0175e-02,  3.9327e-03,\n",
      "         1.0879e-02, -1.2022e-02, -8.2781e-03, -3.1541e-02, -7.7969e-03,\n",
      "         6.8908e-04,  2.2601e-02,  4.1809e-02, -2.6320e-02,  9.2531e-03,\n",
      "         2.0079e-02, -2.6357e-03,  3.8380e-02, -2.9054e-02, -4.4151e-02,\n",
      "         2.7652e-02, -1.0356e-02, -4.3298e-03, -4.7951e-03,  2.3792e-02,\n",
      "        -1.1918e-02, -4.6696e-03,  1.5606e-02,  3.9728e-02, -3.4053e-02,\n",
      "         2.3753e-02, -1.4168e-02,  1.1623e-02, -1.6020e-02, -3.4072e-02,\n",
      "         1.7741e-02, -7.8982e-04], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.2860, -0.2503, -0.0711],\n",
      "          [-0.2069,  0.2447,  0.2058],\n",
      "          [-0.0475,  0.3263, -0.2400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1762, -0.1100, -0.0884],\n",
      "          [-0.0400,  0.2954, -0.0693],\n",
      "          [-0.0090,  0.1359, -0.0677]]],\n",
      "\n",
      "\n",
      "        [[[-0.2152,  0.1835,  0.3289],\n",
      "          [ 0.2716,  0.2489,  0.2271],\n",
      "          [-0.3146, -0.3214,  0.1316]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1975, -0.2399, -0.2368],\n",
      "          [-0.2281, -0.1724,  0.0259],\n",
      "          [ 0.2322,  0.2968, -0.1560]]],\n",
      "\n",
      "\n",
      "        [[[-0.2710, -0.1949,  0.0849],\n",
      "          [-0.2151,  0.2952,  0.1461],\n",
      "          [-0.2208, -0.3146, -0.2971]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3303, -0.0919, -0.1798],\n",
      "          [ 0.1524, -0.0768,  0.2071],\n",
      "          [ 0.2365, -0.2684,  0.1489]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1137,  0.1051, -0.0769, -0.1234, -0.1946,  0.1922,  0.1049,  0.0869,\n",
      "        -0.2721, -0.3116, -0.0665,  0.0487,  0.1029, -0.2892, -0.0567, -0.1716,\n",
      "         0.2670,  0.3293,  0.0515,  0.0904,  0.2217, -0.2782,  0.0691,  0.2408,\n",
      "        -0.2644, -0.2015, -0.0828, -0.1888,  0.2665, -0.2146, -0.2927, -0.0800,\n",
      "         0.1573,  0.1905, -0.3040,  0.1847, -0.1797, -0.3113, -0.1037,  0.0784,\n",
      "        -0.3064,  0.2287,  0.1221,  0.0413, -0.0726, -0.3120, -0.0027, -0.1927,\n",
      "        -0.2443,  0.0744, -0.2513, -0.3320,  0.1486,  0.1606,  0.0690,  0.1852,\n",
      "         0.2355,  0.3246,  0.0994,  0.2897, -0.2273, -0.0134,  0.2227,  0.0486,\n",
      "        -0.3200,  0.2464,  0.0465,  0.0606,  0.1297, -0.1286, -0.3244, -0.0611,\n",
      "        -0.1282,  0.1015,  0.1742, -0.1640,  0.1614, -0.0049,  0.1859,  0.0498,\n",
      "        -0.0234,  0.3023,  0.1568,  0.2950,  0.1024,  0.2219,  0.2737, -0.0283,\n",
      "        -0.1375, -0.2150, -0.0385, -0.2828,  0.3330,  0.3129,  0.1949,  0.1467,\n",
      "         0.2532, -0.2359, -0.0843, -0.3042, -0.3075, -0.0726, -0.1813,  0.0956,\n",
      "        -0.2598, -0.2073, -0.3041, -0.1492, -0.1341,  0.2583, -0.2387,  0.1518,\n",
      "        -0.1056,  0.2835, -0.3102,  0.2327,  0.1757,  0.2320,  0.2171,  0.0614,\n",
      "         0.3078, -0.2072, -0.0510, -0.0084,  0.2578, -0.1262,  0.2398, -0.1939,\n",
      "         0.0945,  0.1659,  0.0377,  0.1580, -0.1946, -0.1472, -0.1802, -0.1669,\n",
      "        -0.0611, -0.0774,  0.0151,  0.1276,  0.2745,  0.0345,  0.2273,  0.1625,\n",
      "         0.1244,  0.0030, -0.2110,  0.2679, -0.2548, -0.2195, -0.2350, -0.0615,\n",
      "         0.3308,  0.2757, -0.2906, -0.0357,  0.0787,  0.2364, -0.2324, -0.2856,\n",
      "        -0.0537,  0.1942,  0.2770,  0.1982,  0.1374,  0.2085, -0.2332,  0.2736,\n",
      "         0.2336, -0.1207, -0.2699, -0.1574,  0.3166,  0.1211,  0.1130,  0.2571,\n",
      "         0.1454, -0.2205, -0.0866, -0.1677, -0.1587, -0.0332, -0.1056, -0.0798,\n",
      "        -0.1469, -0.1442,  0.1314,  0.0845,  0.0533,  0.2256, -0.1888, -0.2964,\n",
      "        -0.1317,  0.0905,  0.0689, -0.2169, -0.0153,  0.0558, -0.0429,  0.0125,\n",
      "        -0.0989,  0.0997, -0.0953,  0.3073,  0.1449,  0.2640,  0.2205,  0.2367,\n",
      "         0.2893, -0.1847,  0.1693, -0.1585, -0.0767, -0.1450,  0.2654,  0.2907,\n",
      "         0.2623, -0.0926, -0.0147,  0.1212,  0.1929, -0.2725,  0.0944, -0.2575,\n",
      "        -0.2861, -0.0834, -0.2022, -0.2434,  0.2072, -0.2160,  0.1970, -0.0618,\n",
      "        -0.2420, -0.1010,  0.1161,  0.1336, -0.2321,  0.1422,  0.1799, -0.0473,\n",
      "         0.1168,  0.1618,  0.3194,  0.2066,  0.0691, -0.2920, -0.0155, -0.1952,\n",
      "         0.3294, -0.2594, -0.0792, -0.0218, -0.1427,  0.2862,  0.3320,  0.2514,\n",
      "         0.3230, -0.2619,  0.0414, -0.0685,  0.1913,  0.2620, -0.0560,  0.1720,\n",
      "         0.2539,  0.2842,  0.1537, -0.2285, -0.2431,  0.0221, -0.2307, -0.1530,\n",
      "         0.1602, -0.2870, -0.1043,  0.3104, -0.1249, -0.2593,  0.2933, -0.0471,\n",
      "         0.1905,  0.2138, -0.2215, -0.1887, -0.1028, -0.0260, -0.2479,  0.0189,\n",
      "         0.1881,  0.2256,  0.2704,  0.3103,  0.2722,  0.1591, -0.0627, -0.0297,\n",
      "         0.2910, -0.0119,  0.0645,  0.1166,  0.2505, -0.1686,  0.2262,  0.3090,\n",
      "         0.1661,  0.1277,  0.0823, -0.1344,  0.3026, -0.2450, -0.0482, -0.2959,\n",
      "         0.1990, -0.1928,  0.1744,  0.0476,  0.1669, -0.2156, -0.2349,  0.0177,\n",
      "         0.2532,  0.1710, -0.1989,  0.3206,  0.0375, -0.1816,  0.0305, -0.1766,\n",
      "        -0.0044,  0.2868,  0.0148, -0.1692, -0.1655,  0.1998, -0.0789, -0.2511,\n",
      "         0.1054, -0.1114, -0.1478,  0.0314, -0.3130,  0.1579,  0.0258,  0.3257,\n",
      "        -0.2043,  0.0501,  0.1696, -0.2240, -0.0423,  0.0261, -0.1211, -0.3246,\n",
      "        -0.0999, -0.3155, -0.2086, -0.3038, -0.0775, -0.0024, -0.2845, -0.3306,\n",
      "        -0.2881,  0.0086,  0.0170, -0.2503, -0.0177, -0.0900, -0.1381,  0.0756,\n",
      "         0.0149,  0.2192, -0.1156,  0.0559, -0.3209,  0.0690,  0.0414,  0.3316,\n",
      "        -0.1986, -0.3097,  0.3028,  0.3161, -0.2568, -0.2139,  0.2531, -0.0606,\n",
      "        -0.1016, -0.2929, -0.2906,  0.3274,  0.3271,  0.2802,  0.1819,  0.1518,\n",
      "        -0.1630,  0.0650,  0.0356,  0.2568,  0.1929,  0.1468, -0.1028,  0.2154,\n",
      "         0.1207, -0.0703,  0.0533, -0.3089,  0.1363, -0.1484, -0.2021,  0.0425,\n",
      "        -0.2109, -0.0764, -0.0770,  0.3261, -0.2508, -0.0493, -0.0676,  0.1716,\n",
      "         0.1184,  0.2096, -0.0463, -0.0547, -0.3128,  0.2988, -0.1989, -0.0278,\n",
      "        -0.0477,  0.1170,  0.0643, -0.2763,  0.1119, -0.0643,  0.3131,  0.1561,\n",
      "         0.3152,  0.1042,  0.1177,  0.0242, -0.0228, -0.0271, -0.0669, -0.1293,\n",
      "        -0.0016, -0.3082, -0.0620,  0.2530,  0.0049,  0.2676, -0.2660, -0.2740,\n",
      "         0.1373, -0.3282, -0.3274, -0.0306, -0.1072,  0.2159, -0.2844,  0.1020,\n",
      "        -0.0393,  0.2498, -0.1864,  0.3092,  0.0217, -0.0236,  0.2805, -0.2868,\n",
      "         0.1955, -0.2905, -0.0383, -0.3004,  0.0281,  0.2822,  0.0110,  0.2632,\n",
      "         0.1763, -0.1324, -0.2688,  0.2596,  0.2611,  0.0285, -0.2737, -0.1112,\n",
      "        -0.0196,  0.1262, -0.2538, -0.2026,  0.2240,  0.2665,  0.1318,  0.1358,\n",
      "        -0.3099,  0.0941,  0.0130, -0.0258, -0.2823, -0.1408, -0.1927,  0.0808,\n",
      "         0.1333,  0.3229, -0.0525,  0.1615, -0.1491, -0.0025, -0.0850,  0.0357,\n",
      "        -0.1326, -0.0737, -0.1359,  0.1816, -0.0073,  0.0863,  0.0029, -0.3285],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 3.5782e-02]],\n",
      "\n",
      "         [[-3.4514e-02]],\n",
      "\n",
      "         [[-1.8806e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.9063e-02]],\n",
      "\n",
      "         [[-4.5154e-03]],\n",
      "\n",
      "         [[-6.5234e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4581e-03]],\n",
      "\n",
      "         [[-2.7960e-02]],\n",
      "\n",
      "         [[-8.5091e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8694e-02]],\n",
      "\n",
      "         [[ 4.5799e-03]],\n",
      "\n",
      "         [[-3.6114e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3932e-02]],\n",
      "\n",
      "         [[-7.3027e-03]],\n",
      "\n",
      "         [[ 2.3822e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4247e-02]],\n",
      "\n",
      "         [[-3.0623e-05]],\n",
      "\n",
      "         [[ 3.5619e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.2960e-02]],\n",
      "\n",
      "         [[ 2.8669e-02]],\n",
      "\n",
      "         [[ 2.8724e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9366e-02]],\n",
      "\n",
      "         [[ 3.4373e-02]],\n",
      "\n",
      "         [[ 7.4187e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.1986e-03]],\n",
      "\n",
      "         [[ 2.9789e-03]],\n",
      "\n",
      "         [[-2.4071e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2732e-03]],\n",
      "\n",
      "         [[-3.3420e-02]],\n",
      "\n",
      "         [[-3.3776e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4753e-02]],\n",
      "\n",
      "         [[-1.0796e-02]],\n",
      "\n",
      "         [[ 1.4570e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.6867e-03]],\n",
      "\n",
      "         [[-3.1158e-02]],\n",
      "\n",
      "         [[-1.1880e-02]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0238,  0.0113, -0.0126, -0.0225,  0.0022,  0.0102,  0.0425,  0.0422,\n",
      "         0.0263, -0.0306,  0.0046,  0.0257, -0.0380, -0.0047, -0.0150,  0.0387,\n",
      "         0.0197,  0.0356, -0.0037, -0.0436,  0.0380, -0.0412, -0.0040,  0.0402,\n",
      "        -0.0065,  0.0111, -0.0110, -0.0054, -0.0056, -0.0296, -0.0340, -0.0430,\n",
      "        -0.0345, -0.0210,  0.0008, -0.0083, -0.0015, -0.0121, -0.0181, -0.0363,\n",
      "         0.0086,  0.0354, -0.0122, -0.0223, -0.0281,  0.0237,  0.0403,  0.0046,\n",
      "        -0.0026, -0.0428, -0.0405,  0.0010, -0.0090,  0.0426, -0.0225,  0.0307,\n",
      "         0.0305, -0.0267,  0.0281, -0.0240, -0.0328, -0.0192, -0.0419, -0.0198,\n",
      "         0.0059,  0.0232,  0.0428,  0.0279,  0.0276,  0.0088, -0.0435,  0.0028,\n",
      "         0.0054, -0.0060,  0.0283,  0.0353,  0.0091,  0.0006, -0.0249, -0.0188,\n",
      "        -0.0306, -0.0286, -0.0406,  0.0323, -0.0149,  0.0206,  0.0170,  0.0008,\n",
      "        -0.0091, -0.0393,  0.0288,  0.0125, -0.0194,  0.0151, -0.0398,  0.0402,\n",
      "         0.0347, -0.0184,  0.0045,  0.0412,  0.0141, -0.0139,  0.0223,  0.0117,\n",
      "         0.0375, -0.0241, -0.0407,  0.0247, -0.0066,  0.0123, -0.0105, -0.0149,\n",
      "         0.0348,  0.0258,  0.0015, -0.0196,  0.0341,  0.0087, -0.0437, -0.0206,\n",
      "        -0.0375,  0.0025, -0.0117,  0.0031, -0.0195,  0.0019,  0.0234,  0.0071,\n",
      "         0.0208, -0.0172,  0.0197, -0.0398,  0.0231,  0.0395, -0.0165,  0.0277,\n",
      "         0.0010,  0.0366,  0.0042,  0.0207,  0.0249, -0.0006,  0.0425, -0.0043,\n",
      "         0.0278, -0.0313, -0.0434, -0.0329,  0.0286,  0.0441, -0.0259, -0.0032,\n",
      "        -0.0090,  0.0345, -0.0037,  0.0060,  0.0296,  0.0108,  0.0350,  0.0404,\n",
      "        -0.0376,  0.0422,  0.0155, -0.0429,  0.0300,  0.0422, -0.0351,  0.0239,\n",
      "         0.0375,  0.0257, -0.0261,  0.0029, -0.0136, -0.0203, -0.0298, -0.0223,\n",
      "         0.0287,  0.0329, -0.0206, -0.0201,  0.0363, -0.0102,  0.0071,  0.0334,\n",
      "         0.0148,  0.0375,  0.0335, -0.0201, -0.0015,  0.0282, -0.0243,  0.0063,\n",
      "        -0.0205, -0.0324, -0.0378, -0.0033, -0.0224, -0.0044,  0.0171, -0.0347,\n",
      "         0.0062,  0.0072,  0.0096,  0.0365,  0.0186,  0.0388, -0.0315,  0.0019,\n",
      "         0.0227,  0.0171,  0.0308,  0.0407,  0.0314, -0.0283, -0.0162, -0.0421,\n",
      "         0.0013, -0.0275, -0.0323,  0.0390, -0.0440,  0.0016, -0.0329, -0.0213,\n",
      "         0.0090, -0.0421, -0.0275, -0.0173, -0.0057,  0.0087,  0.0109, -0.0246,\n",
      "         0.0260, -0.0288,  0.0216, -0.0066,  0.0038, -0.0073,  0.0322, -0.0016,\n",
      "        -0.0260,  0.0166, -0.0261,  0.0286, -0.0420,  0.0101,  0.0064, -0.0328,\n",
      "        -0.0100,  0.0349,  0.0171,  0.0317,  0.0424,  0.0030,  0.0255,  0.0067,\n",
      "         0.0362, -0.0016,  0.0295,  0.0265, -0.0188,  0.0290, -0.0324, -0.0060,\n",
      "        -0.0034,  0.0059,  0.0330,  0.0239, -0.0220,  0.0161, -0.0287,  0.0251,\n",
      "         0.0176, -0.0025, -0.0090, -0.0119, -0.0282,  0.0151, -0.0334,  0.0032,\n",
      "        -0.0442, -0.0186, -0.0219,  0.0148,  0.0396, -0.0081, -0.0375,  0.0379,\n",
      "         0.0354, -0.0019, -0.0359, -0.0351, -0.0184, -0.0066, -0.0065,  0.0006,\n",
      "         0.0370, -0.0367,  0.0046, -0.0350, -0.0416, -0.0127,  0.0085,  0.0111,\n",
      "         0.0305,  0.0182, -0.0411, -0.0211,  0.0191, -0.0404,  0.0082, -0.0321,\n",
      "         0.0053, -0.0317, -0.0251,  0.0267,  0.0301, -0.0253,  0.0213, -0.0372,\n",
      "        -0.0420,  0.0158, -0.0080,  0.0141, -0.0255, -0.0005,  0.0107, -0.0026,\n",
      "        -0.0236,  0.0434, -0.0371,  0.0361,  0.0181,  0.0061, -0.0268, -0.0413,\n",
      "        -0.0166, -0.0034, -0.0260, -0.0149,  0.0356, -0.0130, -0.0074, -0.0436,\n",
      "        -0.0409,  0.0294, -0.0014,  0.0269,  0.0204, -0.0033,  0.0368,  0.0174,\n",
      "         0.0340, -0.0175, -0.0088, -0.0227,  0.0274, -0.0315,  0.0083,  0.0297,\n",
      "        -0.0310,  0.0032,  0.0007, -0.0110,  0.0281, -0.0381, -0.0011, -0.0299,\n",
      "         0.0401, -0.0240, -0.0118,  0.0299,  0.0397, -0.0350, -0.0425, -0.0357,\n",
      "         0.0016,  0.0230, -0.0390,  0.0095,  0.0231,  0.0213,  0.0425,  0.0108,\n",
      "         0.0438,  0.0248, -0.0378, -0.0338,  0.0430, -0.0289,  0.0415,  0.0309,\n",
      "         0.0113,  0.0031, -0.0123, -0.0150,  0.0240, -0.0074,  0.0388, -0.0148,\n",
      "        -0.0413,  0.0072,  0.0003, -0.0192, -0.0066,  0.0373,  0.0349,  0.0082,\n",
      "         0.0046, -0.0384, -0.0089,  0.0049, -0.0300,  0.0220, -0.0362,  0.0092,\n",
      "         0.0172,  0.0108, -0.0076,  0.0422,  0.0393, -0.0438, -0.0069,  0.0210,\n",
      "         0.0430,  0.0059, -0.0435,  0.0190, -0.0088,  0.0405, -0.0236, -0.0327,\n",
      "         0.0189, -0.0221, -0.0175,  0.0346,  0.0309, -0.0058, -0.0420,  0.0126,\n",
      "         0.0184, -0.0034, -0.0053, -0.0034, -0.0432, -0.0300,  0.0053,  0.0342,\n",
      "         0.0305, -0.0397, -0.0283, -0.0300, -0.0185,  0.0167, -0.0280, -0.0281,\n",
      "        -0.0350, -0.0081, -0.0243, -0.0165,  0.0094,  0.0204,  0.0438, -0.0257,\n",
      "         0.0208,  0.0422,  0.0283, -0.0246, -0.0415, -0.0421, -0.0161,  0.0438,\n",
      "         0.0125,  0.0348,  0.0014, -0.0260,  0.0268,  0.0349, -0.0327,  0.0327,\n",
      "        -0.0358,  0.0409, -0.0394,  0.0048,  0.0218, -0.0253,  0.0414, -0.0401,\n",
      "         0.0042, -0.0015, -0.0417, -0.0388,  0.0393,  0.0025, -0.0254,  0.0199,\n",
      "        -0.0238, -0.0238,  0.0357, -0.0109, -0.0379,  0.0325, -0.0015,  0.0402,\n",
      "        -0.0216, -0.0186,  0.0113,  0.0248,  0.0073,  0.0187, -0.0309, -0.0130],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 0.1905, -0.0159, -0.1426],\n",
      "          [-0.1550,  0.1501,  0.2590],\n",
      "          [ 0.2676, -0.1764,  0.1941]]],\n",
      "\n",
      "\n",
      "        [[[-0.1977,  0.2966, -0.2918],\n",
      "          [ 0.1316, -0.0747,  0.1881],\n",
      "          [-0.2593,  0.1369,  0.1823]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3058, -0.2617, -0.1811],\n",
      "          [ 0.0417,  0.1819,  0.0762],\n",
      "          [ 0.2396, -0.1388, -0.1073]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0403,  0.2611, -0.2113],\n",
      "          [-0.1021,  0.2111, -0.2966],\n",
      "          [ 0.0401,  0.3233, -0.0678]]],\n",
      "\n",
      "\n",
      "        [[[-0.0143,  0.1279,  0.0319],\n",
      "          [ 0.2148,  0.1295,  0.1376],\n",
      "          [ 0.1819,  0.0378, -0.0189]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1019, -0.2650,  0.1005],\n",
      "          [ 0.1474,  0.0344,  0.2946],\n",
      "          [ 0.1729,  0.3196, -0.3239]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 2.0556e-01, -4.4799e-02,  7.9710e-02,  2.3543e-02, -9.9588e-02,\n",
      "         1.2327e-01, -5.0297e-02, -1.2349e-01,  1.6229e-02,  2.7795e-01,\n",
      "         1.9918e-01,  2.2535e-01,  5.7951e-02, -1.6496e-01, -3.3753e-02,\n",
      "        -2.0502e-01,  3.4651e-02,  2.2733e-01,  2.4803e-01, -2.6421e-01,\n",
      "         3.1897e-02, -8.5335e-02, -1.1937e-01, -2.3446e-01,  9.8019e-02,\n",
      "         9.0839e-02,  3.0858e-01, -2.0326e-01,  3.1641e-01, -3.0146e-01,\n",
      "        -2.0182e-01, -6.3767e-02,  1.6136e-01,  9.0187e-03, -3.0645e-01,\n",
      "        -8.7164e-02,  7.8085e-02,  2.2033e-01,  2.8301e-01, -2.6136e-02,\n",
      "        -6.0924e-02, -2.3394e-01, -1.7787e-01, -1.2758e-01, -1.8527e-01,\n",
      "         2.4287e-01,  1.6561e-01, -6.3206e-03, -2.3973e-01, -2.4610e-02,\n",
      "        -1.8527e-01, -1.7651e-01,  3.6680e-03,  2.1018e-01, -1.6354e-02,\n",
      "        -9.3120e-03, -2.0174e-01,  1.0325e-01, -7.6244e-02, -3.1771e-01,\n",
      "        -1.3866e-01, -1.8498e-02,  2.7588e-01,  2.7654e-01,  1.9465e-01,\n",
      "         2.4224e-02, -3.0967e-01, -1.6079e-01, -2.1386e-01,  1.1618e-01,\n",
      "         3.1984e-01, -1.7918e-01,  3.1612e-01, -8.9672e-02,  1.3445e-01,\n",
      "        -2.6650e-01,  8.6796e-02,  3.2652e-01, -2.7048e-01,  2.5753e-01,\n",
      "        -2.2565e-02,  5.9541e-02, -2.0273e-01, -2.7219e-01,  1.7572e-01,\n",
      "        -1.6272e-01,  2.9166e-01, -2.4544e-01, -1.9587e-01, -4.5706e-02,\n",
      "        -2.5808e-01, -1.7699e-01, -2.3204e-01,  3.2512e-03,  5.5677e-02,\n",
      "        -1.2117e-02, -4.8791e-02, -1.7144e-01,  9.1317e-02, -1.2541e-01,\n",
      "         2.9117e-01,  1.8728e-01, -2.2753e-01,  9.4184e-02,  1.4333e-01,\n",
      "         6.5712e-02,  2.2207e-01,  1.0316e-01,  1.3456e-01, -1.2897e-01,\n",
      "        -7.3943e-02,  1.3814e-01,  7.1784e-02, -3.3297e-01,  2.2620e-01,\n",
      "         2.6207e-01, -5.1808e-02,  3.5896e-02,  2.2493e-01, -1.1820e-01,\n",
      "         1.5182e-01, -4.4587e-02,  1.8579e-01,  2.7102e-01,  3.0622e-01,\n",
      "         1.5684e-01,  5.4921e-02,  1.4897e-01,  1.4937e-01,  1.5938e-01,\n",
      "        -4.0607e-03,  2.9448e-01,  5.1780e-02, -1.9843e-02,  1.1331e-01,\n",
      "        -2.2410e-02, -8.8310e-03,  3.3301e-02, -2.6801e-01, -7.3252e-02,\n",
      "        -3.0482e-01, -1.2921e-01,  5.1797e-02, -1.8286e-01, -1.4232e-01,\n",
      "         2.1077e-01, -1.4878e-01, -5.8535e-02,  8.7853e-02, -1.3613e-01,\n",
      "         2.5347e-01,  1.7147e-01, -4.7012e-02,  2.2811e-01,  1.7423e-01,\n",
      "         5.3800e-02,  9.4825e-02, -8.5325e-02,  1.7448e-01, -8.8222e-02,\n",
      "        -2.8913e-01,  1.2085e-01,  2.8846e-01,  1.3311e-01, -4.6930e-02,\n",
      "         2.1825e-01, -2.1835e-01,  9.1663e-02, -2.9336e-01, -1.3505e-01,\n",
      "        -5.7879e-02,  4.2027e-02, -2.7479e-01, -1.5610e-01,  2.7836e-01,\n",
      "         3.1674e-01, -1.2730e-01,  8.0164e-02, -1.1969e-01, -3.1700e-01,\n",
      "         2.6007e-01, -1.3550e-02, -5.4143e-02,  2.4273e-01, -1.6586e-01,\n",
      "        -7.4459e-03,  1.7189e-01, -2.7782e-01, -2.6186e-01, -1.2019e-01,\n",
      "        -1.3396e-01,  1.1602e-01, -8.6765e-02,  1.1615e-01,  1.5361e-01,\n",
      "        -3.1158e-01, -1.9868e-01, -1.8037e-01,  1.3973e-01, -1.9701e-01,\n",
      "        -8.5928e-02, -1.9500e-01,  2.7342e-01,  1.6765e-01, -1.0878e-01,\n",
      "        -1.4914e-01, -7.9881e-04, -2.1811e-01,  5.8267e-03, -3.0622e-01,\n",
      "        -2.6297e-02,  1.0628e-01,  1.5700e-01, -2.8126e-01,  3.2127e-01,\n",
      "        -4.9809e-02,  3.2286e-01, -3.2559e-01,  2.0877e-01, -9.3574e-03,\n",
      "         2.9830e-02,  3.9209e-02,  7.5721e-02, -4.5225e-02, -2.0114e-01,\n",
      "        -2.6089e-01, -2.1315e-01, -1.1728e-02, -1.3601e-01, -2.9611e-01,\n",
      "        -9.4998e-02, -2.9987e-01,  3.0613e-01, -6.0369e-02,  2.0963e-01,\n",
      "        -1.0408e-01, -4.6616e-02,  6.9972e-02,  1.5513e-01, -1.0828e-01,\n",
      "        -2.0078e-03, -2.5997e-01,  3.1962e-01,  2.3015e-01,  1.0507e-01,\n",
      "        -1.8674e-01,  1.6754e-01, -1.7088e-02,  2.0148e-01,  2.5173e-01,\n",
      "         1.2592e-01, -9.4550e-02,  2.9771e-01,  2.9002e-01,  2.5910e-01,\n",
      "        -1.5658e-01,  1.1252e-01,  2.2495e-01,  4.1084e-02, -2.1618e-01,\n",
      "        -5.9132e-02, -1.3277e-02,  3.2749e-01, -1.1789e-01, -2.3241e-01,\n",
      "        -1.4602e-01, -3.1843e-01, -6.0494e-02,  1.4915e-01,  9.1580e-02,\n",
      "         2.3113e-01,  1.7970e-01,  8.8863e-02,  9.7667e-02, -1.2194e-01,\n",
      "         1.0504e-01,  1.9587e-01,  1.0882e-01, -1.7432e-01, -1.0964e-01,\n",
      "         1.8814e-01, -3.0040e-01, -9.2898e-02,  5.1567e-02, -2.3006e-01,\n",
      "        -2.1782e-01, -1.6143e-01,  2.0258e-01,  1.6319e-01, -2.3885e-02,\n",
      "        -1.4046e-02,  1.7629e-01,  6.6136e-02, -3.2703e-01, -1.9008e-01,\n",
      "         2.6598e-01,  2.0868e-01,  1.5358e-01, -3.2205e-02,  1.5769e-01,\n",
      "         1.6562e-01, -1.5939e-01, -1.8836e-01,  2.6366e-01,  4.6509e-04,\n",
      "        -7.5761e-02, -2.8579e-01, -3.1778e-01,  8.1961e-05,  5.0057e-02,\n",
      "        -1.9443e-01, -2.0967e-01,  1.4685e-01, -2.9332e-01,  1.8453e-02,\n",
      "         1.1806e-01,  5.1905e-02, -1.9166e-01, -1.2343e-01,  1.0609e-01,\n",
      "        -3.2625e-01,  6.3854e-02, -2.6517e-01,  2.7107e-01, -1.7837e-01,\n",
      "        -6.4964e-02, -1.8550e-02, -3.1291e-01,  2.7248e-01,  3.0185e-01,\n",
      "         3.1000e-01,  2.5228e-02,  4.4732e-02, -2.4873e-02, -1.3391e-01,\n",
      "        -2.7597e-01, -2.2677e-01,  2.7383e-02, -2.5139e-01,  2.1999e-01,\n",
      "         7.1170e-02,  3.2675e-01,  1.3854e-01,  2.8335e-01,  2.8709e-01,\n",
      "         3.2443e-01, -1.4137e-01, -4.0449e-02,  3.1615e-01,  2.3786e-01,\n",
      "         3.0486e-01, -1.5730e-01,  1.9688e-01,  1.3568e-01,  1.8691e-01,\n",
      "        -1.6012e-01, -5.6759e-02, -1.4605e-01, -7.3555e-02,  1.0186e-01,\n",
      "         3.0305e-01, -2.5700e-01, -2.1260e-01, -4.3083e-02, -2.0348e-01,\n",
      "        -1.0174e-01, -1.0069e-02, -2.7041e-01, -1.6710e-01, -3.1366e-01,\n",
      "         5.8029e-02,  2.7706e-01,  1.1191e-01, -2.6727e-01, -2.9024e-01,\n",
      "        -2.3926e-01,  1.2156e-01, -2.8444e-01, -2.8856e-01,  1.8773e-01,\n",
      "        -1.8220e-01,  5.4177e-03,  1.0777e-01, -1.1355e-01, -9.5613e-02,\n",
      "        -4.5579e-03, -9.7719e-02,  1.6688e-01,  2.6763e-01, -3.0703e-01,\n",
      "        -1.8575e-01,  1.1672e-01,  3.2223e-01,  2.3186e-01, -8.5838e-02,\n",
      "        -1.0869e-02, -4.0573e-02, -2.1563e-01,  2.8081e-02,  1.1129e-01,\n",
      "        -3.0540e-01,  1.0169e-01,  2.2653e-01,  1.1727e-01, -1.9491e-01,\n",
      "        -3.0223e-01, -1.1068e-01,  7.9714e-02, -1.3380e-01,  2.4765e-01,\n",
      "        -2.6430e-01, -1.9433e-01,  1.4724e-01,  2.8029e-01,  2.6775e-01,\n",
      "        -2.5688e-02, -1.9495e-01,  1.9650e-01, -2.5524e-01,  1.5215e-01,\n",
      "        -1.7401e-01, -2.3708e-01, -1.9487e-01,  1.6679e-01, -2.3804e-01,\n",
      "        -2.9950e-01, -1.4150e-01,  1.5263e-01,  2.9168e-01, -2.2816e-01,\n",
      "         2.8328e-01, -1.5523e-01, -4.8424e-03,  3.0915e-01, -1.4746e-01,\n",
      "         1.3387e-01, -2.5744e-02,  2.7880e-02, -8.8909e-02,  2.1213e-01,\n",
      "        -1.1921e-01,  2.0512e-01, -7.9203e-02, -4.6220e-02, -1.9037e-01,\n",
      "        -1.8730e-01, -5.0047e-03, -7.6551e-02, -2.3904e-01,  2.8715e-01,\n",
      "        -1.3277e-01, -5.5798e-02,  1.1392e-01,  3.2559e-01, -8.1915e-02,\n",
      "         2.6839e-01, -8.0312e-02, -2.2724e-01,  8.6271e-02,  1.4947e-01,\n",
      "        -1.6059e-01, -8.2986e-02, -3.0984e-01,  1.2809e-01, -2.4708e-02,\n",
      "         2.6800e-01, -3.2932e-01,  9.1121e-02, -1.4602e-01,  1.9804e-01,\n",
      "         8.9069e-02, -2.2545e-01, -2.8644e-02,  4.3501e-02, -1.5203e-01,\n",
      "         2.9146e-01,  1.4397e-01,  2.2546e-01, -1.3557e-01,  9.8415e-02,\n",
      "        -4.0255e-02,  2.9496e-01, -1.5650e-01, -2.9443e-01, -3.3124e-01,\n",
      "         3.3065e-02, -7.4042e-03,  1.3186e-01, -1.4585e-01,  2.9879e-01,\n",
      "         3.2990e-01, -5.5097e-02,  7.0722e-02,  1.7921e-01,  2.7171e-02,\n",
      "         2.2359e-01,  3.0025e-01, -6.7402e-02,  2.3323e-01, -1.2058e-01,\n",
      "         2.6878e-01, -3.1292e-01, -1.7404e-01,  2.4242e-01, -2.6878e-01,\n",
      "         1.4527e-01,  1.2557e-01,  7.1496e-02, -5.5710e-03,  2.4973e-01,\n",
      "         2.9172e-01,  1.1146e-01], requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 0.0197]],\n",
      "\n",
      "         [[ 0.0436]],\n",
      "\n",
      "         [[ 0.0191]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0078]],\n",
      "\n",
      "         [[-0.0123]],\n",
      "\n",
      "         [[-0.0079]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0258]],\n",
      "\n",
      "         [[ 0.0065]],\n",
      "\n",
      "         [[-0.0207]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0136]],\n",
      "\n",
      "         [[ 0.0380]],\n",
      "\n",
      "         [[-0.0323]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0126]],\n",
      "\n",
      "         [[ 0.0408]],\n",
      "\n",
      "         [[ 0.0345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0279]],\n",
      "\n",
      "         [[-0.0075]],\n",
      "\n",
      "         [[ 0.0276]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0011]],\n",
      "\n",
      "         [[-0.0284]],\n",
      "\n",
      "         [[ 0.0330]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0272]],\n",
      "\n",
      "         [[ 0.0370]],\n",
      "\n",
      "         [[-0.0414]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0087]],\n",
      "\n",
      "         [[ 0.0054]],\n",
      "\n",
      "         [[-0.0058]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0052]],\n",
      "\n",
      "         [[-0.0022]],\n",
      "\n",
      "         [[ 0.0187]]],\n",
      "\n",
      "\n",
      "        [[[-0.0057]],\n",
      "\n",
      "         [[-0.0210]],\n",
      "\n",
      "         [[-0.0383]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0388]],\n",
      "\n",
      "         [[-0.0378]],\n",
      "\n",
      "         [[ 0.0225]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 7.3474e-03,  1.9808e-02,  1.0007e-02, -6.3651e-03, -9.0678e-03,\n",
      "        -3.5159e-02, -3.8110e-02,  1.3350e-02, -3.1764e-02, -2.0890e-02,\n",
      "         2.3077e-02, -2.2993e-02, -5.6997e-03, -2.6570e-02,  2.1773e-02,\n",
      "         4.0044e-02,  2.8262e-02,  3.7158e-02, -6.1217e-03, -3.5718e-03,\n",
      "        -7.9083e-03, -2.3420e-03, -6.9441e-03,  3.3292e-02, -2.2591e-02,\n",
      "         4.9473e-03,  5.3709e-03, -8.3050e-03, -7.0531e-03,  4.3061e-02,\n",
      "        -1.5096e-02,  1.5894e-02,  5.6812e-04, -3.9210e-02, -1.0835e-02,\n",
      "        -1.3937e-02,  8.4178e-03,  8.9240e-03,  1.5928e-02, -1.8088e-02,\n",
      "        -3.3319e-02,  4.2442e-02, -2.7620e-02,  1.7390e-02,  1.9542e-03,\n",
      "        -3.6335e-02, -8.0485e-03,  2.2362e-02, -3.9629e-02, -1.0163e-02,\n",
      "        -4.3802e-02, -5.9814e-03, -9.9364e-03, -3.2388e-02,  3.4465e-02,\n",
      "         2.0490e-02,  2.6526e-02, -4.0787e-03, -2.2782e-03, -3.0346e-02,\n",
      "         2.6434e-02,  1.5077e-02,  2.9525e-02,  4.1931e-02,  9.6275e-03,\n",
      "         2.9302e-02, -4.3489e-02, -2.1180e-02,  3.9615e-02, -3.0363e-03,\n",
      "         3.2139e-02,  3.0362e-02,  3.9183e-02,  5.7558e-03,  4.2699e-02,\n",
      "        -2.9251e-02,  1.2383e-02, -4.3851e-02,  4.6840e-03,  3.1839e-02,\n",
      "         2.4733e-02, -2.5192e-02, -3.2732e-02,  4.0462e-02,  8.8029e-03,\n",
      "         2.6633e-02, -3.4401e-03,  1.2011e-02,  2.3082e-02, -5.8903e-03,\n",
      "         4.0066e-02, -2.4132e-02,  3.3565e-02, -4.1043e-03, -3.1893e-02,\n",
      "         3.3772e-02,  4.1248e-02,  3.0807e-02,  2.0192e-02,  2.9114e-02,\n",
      "        -2.0466e-03,  1.4335e-02, -3.6526e-03, -8.6176e-03, -3.5551e-02,\n",
      "         2.2849e-02,  2.3545e-03,  2.5943e-02,  3.3204e-02,  1.9062e-02,\n",
      "        -1.4069e-02,  3.4502e-02,  9.4906e-03, -1.2757e-03, -1.2095e-02,\n",
      "         2.7045e-03,  1.1032e-03,  2.7810e-02,  4.2735e-02, -3.1623e-02,\n",
      "        -3.7681e-02,  1.9598e-02,  3.8680e-02,  1.8075e-02, -1.7964e-02,\n",
      "        -9.2240e-03,  1.1827e-02,  1.9818e-02, -3.1485e-02, -3.4879e-02,\n",
      "        -3.9746e-02, -4.4192e-02, -3.6217e-02,  2.0417e-02, -3.2540e-02,\n",
      "         3.9223e-03, -8.7004e-03,  4.0337e-02,  1.7945e-02,  3.6838e-02,\n",
      "         5.5388e-03, -1.7362e-02,  1.2836e-02, -1.3506e-03, -1.6923e-02,\n",
      "        -3.8722e-02, -4.1259e-02,  4.1523e-02,  3.4163e-02, -1.3383e-02,\n",
      "         1.1056e-02, -2.7920e-02, -1.4213e-02,  3.1946e-03, -1.6897e-02,\n",
      "         2.8031e-02, -1.3422e-02, -3.4009e-02,  2.1488e-02, -1.4073e-02,\n",
      "         3.9722e-02,  2.2409e-02,  6.2910e-03,  8.9313e-04,  4.3127e-02,\n",
      "         3.6641e-02,  2.0257e-02, -3.4365e-02, -1.3868e-02, -9.2071e-03,\n",
      "         9.8794e-04, -3.4820e-02,  4.3589e-02,  3.5242e-02, -2.0348e-02,\n",
      "        -3.2448e-02, -2.4381e-02, -4.4109e-02,  8.5964e-03,  3.2447e-02,\n",
      "         1.9008e-02,  2.5664e-02, -3.7871e-02, -1.3557e-03, -3.5099e-02,\n",
      "        -2.0903e-02,  3.5272e-02, -1.3689e-02,  1.7514e-02, -3.4577e-02,\n",
      "         4.0749e-03,  3.6184e-02,  3.6634e-02, -1.2944e-02, -2.8668e-03,\n",
      "        -3.9388e-02,  2.4509e-02,  4.1830e-02,  6.6285e-03,  1.0260e-02,\n",
      "         1.5503e-03,  2.9414e-02,  2.7944e-02,  1.3777e-02,  2.1120e-02,\n",
      "        -1.7197e-02, -1.0694e-02, -3.0061e-02,  9.5123e-03,  3.0113e-02,\n",
      "         1.7199e-02, -8.8154e-03, -4.9800e-03,  2.3925e-02, -2.9815e-02,\n",
      "        -4.3373e-02, -1.8733e-02, -1.4558e-02, -1.1265e-02, -1.9351e-02,\n",
      "         8.4638e-03, -2.7950e-02, -5.0832e-04,  3.5528e-02,  8.9375e-04,\n",
      "         6.5996e-03, -2.3244e-02, -2.2295e-02, -3.8451e-02,  1.8342e-02,\n",
      "         3.3594e-02, -3.6957e-02,  3.5339e-02, -4.6856e-03, -1.8357e-02,\n",
      "         1.4200e-02, -3.8798e-02,  2.4633e-02, -7.0806e-03, -2.2346e-02,\n",
      "        -1.3495e-02,  2.5021e-02,  2.4598e-02, -3.6364e-02, -1.1933e-02,\n",
      "         1.6487e-02, -3.8496e-02,  3.8096e-02, -4.2834e-02,  3.7352e-02,\n",
      "        -3.6774e-02,  2.3654e-02,  4.0349e-03, -1.6684e-02,  3.2502e-02,\n",
      "         1.6141e-02, -2.1172e-02, -4.3254e-02,  1.9067e-02,  2.0045e-02,\n",
      "         1.3460e-02,  3.4223e-03, -1.1890e-02,  7.4623e-03,  1.1582e-02,\n",
      "        -5.4179e-03, -1.6837e-02,  4.0038e-02, -2.9166e-03,  1.5250e-03,\n",
      "         2.2020e-02, -2.2978e-02, -3.5654e-02,  1.9056e-02,  3.2972e-02,\n",
      "        -4.7534e-03,  8.9628e-03,  5.6370e-04,  2.2898e-02,  3.5420e-02,\n",
      "         4.0378e-04,  2.1080e-02, -4.2370e-02, -1.0487e-02, -4.4239e-03,\n",
      "         2.8639e-02,  5.0236e-03, -3.4368e-02, -3.5337e-02,  2.1430e-02,\n",
      "        -3.1115e-02, -4.2525e-02, -1.3542e-02, -2.2043e-02, -1.0723e-03,\n",
      "         3.3131e-02, -1.0705e-02,  1.9230e-06,  1.2752e-02, -4.3762e-02,\n",
      "        -1.2878e-02, -1.2606e-02,  1.3278e-02, -1.9487e-02, -2.8144e-03,\n",
      "        -1.8190e-02, -4.9096e-03, -3.4354e-02,  6.5180e-03,  2.6454e-02,\n",
      "        -9.4605e-03,  3.8513e-02, -2.9205e-02,  1.2114e-02, -2.0195e-02,\n",
      "        -4.1340e-02,  1.1612e-03, -1.1205e-02,  3.6940e-02,  3.3779e-02,\n",
      "         3.1234e-02, -3.3650e-02, -3.1980e-02,  1.3172e-02,  3.1535e-02,\n",
      "        -4.2364e-02,  1.4733e-02,  2.1290e-02,  9.9767e-03,  3.1206e-02,\n",
      "         6.8811e-03, -4.4068e-02, -2.5521e-02, -2.5642e-02,  1.6656e-03,\n",
      "        -1.4283e-03,  1.0867e-02, -5.5417e-03, -1.1924e-02,  3.2973e-02,\n",
      "         6.0532e-03,  2.2193e-02,  4.7552e-03, -2.5461e-02,  1.1422e-02,\n",
      "         4.7664e-03, -4.2082e-02,  2.5817e-02, -4.2514e-03,  9.0495e-03,\n",
      "        -3.4030e-02, -3.0660e-02,  4.2925e-02, -1.2981e-02,  4.5410e-03,\n",
      "         3.7467e-02, -2.9662e-02, -2.0129e-02,  3.7166e-03, -1.8640e-03,\n",
      "         2.5396e-02, -3.4927e-03, -1.9409e-02,  1.9498e-03,  1.0245e-03,\n",
      "        -3.1389e-02,  7.7679e-03, -2.1793e-03, -1.8864e-02, -3.7926e-03,\n",
      "         3.2174e-02,  8.1167e-03,  7.0084e-03,  3.8347e-02,  3.3243e-02,\n",
      "        -1.8992e-02,  1.3520e-02, -2.5413e-02,  4.3974e-02, -1.1750e-02,\n",
      "        -1.1010e-03, -3.1841e-02, -8.6039e-03,  2.9704e-02,  3.5825e-02,\n",
      "         9.5657e-03,  1.7020e-02, -3.9647e-02,  3.5333e-02,  1.3342e-02,\n",
      "        -6.3016e-04,  2.3951e-02, -1.9835e-02,  7.9492e-03, -8.1777e-03,\n",
      "        -5.5823e-03, -1.4083e-02, -4.2183e-02,  3.6344e-02, -4.0254e-02,\n",
      "         2.5482e-02, -4.2047e-02,  6.5701e-03, -2.3919e-03,  4.0649e-02,\n",
      "        -1.6464e-02, -2.2572e-02,  2.8827e-02,  3.9627e-02, -1.8525e-02,\n",
      "         1.4218e-02,  1.7549e-02,  2.2476e-02, -2.0020e-02,  3.7717e-02,\n",
      "        -1.5761e-02, -1.3629e-02, -2.0730e-02,  2.9341e-02, -3.1749e-02,\n",
      "        -2.4385e-02, -3.4106e-02, -1.9262e-02,  1.6526e-02, -2.1930e-02,\n",
      "         2.3789e-02,  3.6847e-02,  3.5493e-02, -3.2946e-03,  1.0976e-02,\n",
      "        -3.3811e-02, -2.6942e-02,  2.4834e-02,  8.4123e-03, -4.2285e-02,\n",
      "        -9.7582e-03, -1.5347e-02, -3.1988e-02,  8.9755e-03, -4.3017e-02,\n",
      "        -3.9509e-02,  2.8309e-02, -2.4867e-02, -3.9868e-02,  1.5266e-03,\n",
      "        -1.5267e-02,  1.1557e-02,  5.8053e-03,  3.4743e-02,  3.9250e-02,\n",
      "         3.6536e-02,  6.5730e-03, -3.2033e-02,  2.7186e-02, -4.2996e-02,\n",
      "        -2.2053e-02, -2.4412e-02, -3.0966e-02,  2.9226e-02,  2.7958e-02,\n",
      "        -2.0574e-03, -3.1884e-03,  2.6633e-02, -3.0415e-02, -3.6737e-02,\n",
      "        -2.5761e-02, -1.2998e-02,  7.9794e-03, -4.0128e-02,  3.8262e-02,\n",
      "         4.2872e-02,  2.1568e-02, -3.9103e-02, -2.7742e-02,  3.3227e-02,\n",
      "        -2.2004e-02, -2.3148e-02,  2.9852e-02,  2.6429e-02,  2.0981e-02,\n",
      "        -3.2955e-02, -3.9296e-02,  2.9208e-02, -2.9057e-02,  2.1911e-02,\n",
      "         1.5805e-02,  3.6058e-02, -1.5801e-02, -3.6393e-02,  7.9763e-03,\n",
      "        -2.4651e-02, -3.4649e-02, -1.1062e-02,  1.3082e-02, -1.8960e-03,\n",
      "         5.5367e-03,  3.3075e-02, -1.6209e-02, -4.1204e-02, -9.1152e-03,\n",
      "        -1.7838e-02, -6.8776e-03, -1.4733e-02, -3.1031e-02, -2.2945e-02,\n",
      "        -3.7120e-02,  5.2551e-04,  3.1855e-02, -7.3441e-03,  6.9274e-03,\n",
      "        -3.6874e-02,  2.1741e-02], requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 0.0032,  0.0339,  0.2840],\n",
      "          [-0.0828, -0.2472,  0.1559],\n",
      "          [-0.1101, -0.0473, -0.2314]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2920,  0.0994,  0.0146],\n",
      "          [ 0.2169,  0.1076, -0.3138],\n",
      "          [-0.1210, -0.1028, -0.1158]]],\n",
      "\n",
      "\n",
      "        [[[-0.3008, -0.0582,  0.2966],\n",
      "          [-0.1440,  0.2056,  0.1787],\n",
      "          [-0.3304,  0.3178, -0.2961]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2746, -0.2329, -0.1305],\n",
      "          [ 0.1489,  0.1521, -0.0110],\n",
      "          [ 0.1041, -0.1818,  0.2134]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2815, -0.0311,  0.2861],\n",
      "          [-0.2951, -0.2662, -0.1179],\n",
      "          [-0.2738, -0.1394, -0.2832]]],\n",
      "\n",
      "\n",
      "        [[[-0.1390, -0.0208, -0.3256],\n",
      "          [-0.0562, -0.1318, -0.2951],\n",
      "          [-0.2768, -0.0563, -0.2884]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 1.2396e-01, -3.2528e-01,  1.5376e-01, -1.1361e-01,  1.4604e-01,\n",
      "        -4.6598e-02,  2.9277e-01,  2.9609e-01,  4.5287e-02,  1.1435e-01,\n",
      "         4.2948e-02,  1.2756e-01, -1.6566e-01, -7.9017e-02,  1.6576e-01,\n",
      "        -3.0920e-01, -1.7871e-01,  2.1846e-01,  5.4705e-02,  1.5189e-01,\n",
      "         1.1929e-01, -3.0227e-01,  2.5344e-01, -1.4449e-01,  1.3578e-01,\n",
      "        -2.5044e-01,  1.2401e-01, -1.0566e-01, -3.0364e-01,  1.5848e-01,\n",
      "         1.5741e-01,  5.7299e-02, -1.2419e-01, -7.8966e-02,  1.6106e-01,\n",
      "         4.0008e-02, -1.4717e-01,  2.1690e-01,  5.3348e-02,  2.5488e-01,\n",
      "         7.2169e-02,  3.1644e-01,  2.6486e-01,  1.1162e-01,  8.4688e-02,\n",
      "        -1.9556e-01, -1.4813e-02, -1.1735e-01,  3.0595e-01, -7.4641e-02,\n",
      "        -2.0676e-01, -2.3885e-01,  2.1782e-01,  2.1109e-01,  3.8635e-02,\n",
      "        -1.4004e-01,  8.9141e-02, -2.6366e-01, -3.2094e-01, -1.9805e-01,\n",
      "        -2.3580e-01,  1.5580e-01,  9.4383e-03, -1.5321e-01, -1.7125e-01,\n",
      "         1.3565e-01, -4.3069e-02,  6.5083e-02,  2.5173e-01,  1.7651e-01,\n",
      "         2.3180e-01, -1.6581e-01,  1.4797e-01, -1.1610e-01, -5.2413e-02,\n",
      "         1.9966e-01,  2.2337e-01, -1.0797e-01,  1.9223e-01,  1.0993e-02,\n",
      "        -2.5532e-01, -5.6924e-02,  2.1218e-01,  1.9716e-01, -1.6245e-02,\n",
      "        -6.3373e-02,  2.5424e-02,  2.7222e-02,  2.2384e-01,  1.1795e-01,\n",
      "         9.1310e-02,  5.0768e-02,  1.4758e-01,  5.5660e-02,  6.4160e-02,\n",
      "        -5.8905e-02,  1.1026e-01,  1.4214e-01,  1.5867e-01, -3.2891e-01,\n",
      "        -2.2938e-01, -2.0186e-01,  1.3620e-01, -3.2836e-01, -2.3784e-01,\n",
      "         2.7376e-01,  6.7579e-02, -1.9192e-01, -7.8919e-02, -3.3298e-01,\n",
      "        -1.2352e-01,  8.4849e-02,  4.9169e-02, -8.3047e-03, -2.0505e-01,\n",
      "         2.8067e-01, -5.1693e-02,  1.2848e-01, -3.2108e-01,  2.5569e-01,\n",
      "        -1.2396e-01, -1.3254e-02, -1.2621e-02,  2.7418e-01, -1.4574e-01,\n",
      "         1.0756e-01, -1.1596e-01, -8.1321e-02,  1.5264e-01,  5.1374e-02,\n",
      "         1.2219e-01,  2.4901e-01, -3.2245e-01, -1.9045e-01, -2.4977e-01,\n",
      "         1.9989e-01, -6.3726e-02,  1.0534e-01,  1.7192e-01, -1.1845e-02,\n",
      "         2.8846e-01,  1.3052e-03, -1.7888e-01,  2.7187e-01,  1.3124e-01,\n",
      "         3.1782e-01,  2.8611e-01, -4.6619e-02,  2.2221e-01,  2.4236e-01,\n",
      "        -1.2475e-01,  2.4891e-01, -2.0973e-01, -2.2271e-01,  8.8077e-02,\n",
      "        -2.4638e-01, -2.4502e-01, -2.6497e-02,  1.0536e-01,  3.2353e-01,\n",
      "        -1.4019e-01, -2.5895e-01,  2.4051e-01,  2.8332e-01,  9.5573e-02,\n",
      "         9.5621e-02,  3.8697e-02, -2.4496e-01,  9.4741e-02,  2.7155e-01,\n",
      "        -1.4648e-01, -2.2528e-02, -6.1123e-02,  5.2438e-02,  1.0659e-01,\n",
      "        -9.1360e-02, -1.6078e-02, -1.7931e-01, -1.0761e-01,  2.8896e-01,\n",
      "        -7.5275e-02, -4.2628e-02, -2.9778e-01, -6.1604e-02, -1.6871e-01,\n",
      "         2.3516e-01, -3.0074e-01, -3.2597e-04,  1.4810e-01, -3.9827e-02,\n",
      "        -1.0472e-01,  1.4031e-02,  2.8382e-01,  2.9556e-01, -3.8360e-02,\n",
      "        -1.0960e-01, -1.8403e-01,  1.7675e-01,  2.8130e-01, -3.0524e-01,\n",
      "         1.5851e-03,  1.4623e-01,  5.9096e-02, -2.8103e-01, -3.3036e-01,\n",
      "         5.1495e-02, -1.6306e-01, -3.2649e-01, -2.0949e-01,  3.8995e-02,\n",
      "         3.0702e-01, -5.7665e-02,  2.8086e-01,  8.5231e-02, -5.3839e-02,\n",
      "        -1.2778e-01,  6.5561e-02, -3.0058e-01,  6.2130e-02,  2.1578e-01,\n",
      "         1.1380e-02, -3.2294e-01,  1.9954e-01, -1.1111e-01, -1.2596e-01,\n",
      "        -1.0271e-01,  2.5988e-01,  4.5286e-02, -1.1405e-01,  1.8682e-01,\n",
      "        -2.5828e-01,  2.3057e-01,  2.5494e-01, -3.1923e-01,  9.3952e-02,\n",
      "         3.1945e-02,  2.6688e-01,  4.7221e-02, -5.4995e-02, -7.9812e-02,\n",
      "        -3.1107e-01, -3.1093e-01, -5.5297e-02, -2.1844e-01, -1.3923e-01,\n",
      "         6.0342e-02,  2.3102e-01, -1.6393e-01, -1.1939e-01,  2.4365e-01,\n",
      "        -3.0539e-01,  4.6354e-02, -1.5299e-01,  2.5220e-01, -2.3070e-02,\n",
      "        -4.6143e-02,  7.0445e-02,  5.1475e-02, -3.0620e-01,  1.5299e-01,\n",
      "        -1.2924e-01,  2.2171e-01,  2.4002e-01, -7.0242e-02,  1.2537e-02,\n",
      "        -2.0380e-01,  9.8431e-02, -1.7861e-01,  5.6026e-02,  9.1593e-02,\n",
      "        -1.5938e-01, -1.9904e-01,  1.7746e-01,  3.2192e-01,  1.8415e-01,\n",
      "        -2.6399e-01,  1.6556e-01, -7.6798e-02, -2.0372e-01,  5.1258e-02,\n",
      "         2.0193e-01, -1.3580e-01, -3.0453e-01,  1.2530e-01, -8.1475e-02,\n",
      "        -7.5445e-02, -2.2881e-01,  3.1347e-01, -2.1306e-02,  2.6992e-01,\n",
      "         1.7437e-02,  2.2185e-01, -3.1349e-01,  3.2914e-01, -1.2797e-01,\n",
      "         2.0193e-01,  1.5652e-01, -7.5810e-02, -3.0034e-01, -2.6232e-01,\n",
      "        -2.8506e-01,  4.8632e-02, -3.0055e-01, -7.4774e-02, -7.1837e-02,\n",
      "        -3.2441e-01, -2.3962e-01, -7.0809e-02,  1.8445e-01, -1.2090e-01,\n",
      "         4.7424e-02,  3.3101e-01, -1.7442e-01, -8.7843e-02,  4.7590e-02,\n",
      "         1.4014e-01, -2.1634e-02, -1.7176e-01,  3.2896e-01,  3.2464e-02,\n",
      "        -1.0188e-01,  2.0971e-01, -1.6322e-01,  2.8757e-01, -2.4401e-01,\n",
      "        -3.1794e-01, -1.4821e-01, -2.0673e-01,  2.9803e-01,  1.4213e-01,\n",
      "         1.8455e-01, -2.7280e-01, -9.7917e-02,  1.6588e-01, -2.2943e-01,\n",
      "         2.4640e-01,  3.1737e-01, -2.4955e-01, -2.4746e-01, -9.4194e-02,\n",
      "         2.4267e-01, -2.8858e-01,  1.5325e-02, -7.7216e-02, -2.8586e-01,\n",
      "         1.1068e-01, -2.7874e-01, -2.0891e-01, -2.9379e-01, -4.8365e-02,\n",
      "         3.3118e-01,  1.3938e-02,  1.1054e-01,  2.3652e-01, -1.4866e-01,\n",
      "        -6.3215e-03,  1.1338e-01,  2.8668e-01, -9.1439e-02, -1.0586e-01,\n",
      "         2.4020e-01,  3.9561e-02,  8.6265e-02, -1.3903e-01, -1.6608e-01,\n",
      "        -1.6894e-01,  2.3135e-01, -1.1964e-01, -5.1516e-02, -8.0192e-02,\n",
      "        -2.4735e-02,  9.6919e-02, -1.0868e-01,  1.8964e-01, -2.0860e-01,\n",
      "        -1.7330e-01, -2.7510e-01, -1.2040e-01,  1.1094e-01, -2.9821e-01,\n",
      "         2.0911e-02, -2.6853e-01, -4.9820e-02,  2.7428e-01, -1.6273e-01,\n",
      "        -1.2373e-01,  1.6417e-01, -1.2373e-01, -3.1607e-01, -5.2479e-02,\n",
      "         1.3281e-01,  1.7284e-01,  2.2981e-01, -1.9368e-01, -1.2299e-01,\n",
      "         1.7921e-02, -2.0425e-01,  1.8982e-01, -2.5616e-01,  3.2526e-02,\n",
      "         1.5533e-01, -2.5519e-01, -7.7669e-02, -2.2933e-01, -6.3208e-02,\n",
      "        -2.4625e-01, -4.2717e-02,  2.6255e-01, -8.9944e-02,  8.2038e-02,\n",
      "        -1.5874e-01,  1.8157e-02, -7.5261e-02, -2.7233e-01, -2.2446e-01,\n",
      "         2.7732e-01,  1.1861e-02, -1.1898e-01, -1.6700e-01,  2.5999e-02,\n",
      "         6.4882e-02,  1.2088e-01, -1.2999e-01,  3.0111e-01, -2.2282e-01,\n",
      "         3.0064e-01, -2.8325e-01, -2.1581e-01,  2.7701e-01, -2.3916e-01,\n",
      "         1.6589e-01, -1.6103e-01, -3.1445e-01,  1.5859e-01, -2.2333e-02,\n",
      "        -1.7165e-01, -1.8574e-01, -3.1763e-01,  1.2630e-01,  1.0750e-01,\n",
      "         3.6354e-02,  5.9165e-03,  7.5464e-02, -3.2802e-01, -8.6240e-02,\n",
      "         1.7456e-02,  2.8288e-01,  1.7763e-01, -1.6776e-01,  1.2337e-02,\n",
      "        -3.9783e-02,  1.0606e-01, -2.3537e-01, -5.2440e-02,  2.1894e-01,\n",
      "         9.2615e-02, -2.7877e-01,  1.2139e-01,  2.9384e-02,  2.9243e-01,\n",
      "        -7.5175e-02, -2.4524e-01, -2.3366e-02, -1.9639e-01, -2.9864e-01,\n",
      "        -3.0927e-01,  2.9074e-01, -2.2846e-01,  2.6375e-01,  1.3718e-01,\n",
      "        -3.3087e-01,  2.9619e-01, -1.7617e-01, -1.3242e-01,  2.9433e-01,\n",
      "         7.5462e-02, -2.4728e-01,  3.0239e-01,  6.0278e-02,  3.7066e-02,\n",
      "        -1.8750e-01, -1.5723e-01, -2.9631e-01,  2.8207e-01, -2.2797e-01,\n",
      "         2.2848e-01,  2.5014e-02, -1.4664e-01,  2.5178e-01, -4.7796e-02,\n",
      "         3.1017e-01, -8.1294e-02,  2.0773e-01, -3.0717e-01,  6.1879e-02,\n",
      "        -2.3863e-01, -2.3261e-01,  2.6656e-01,  3.0255e-02,  2.4138e-01,\n",
      "        -1.0528e-01, -1.5931e-01, -4.7207e-02,  2.3442e-01,  4.2108e-02,\n",
      "         5.5565e-02, -2.7263e-01,  1.3162e-01, -1.9950e-01,  1.5493e-01,\n",
      "         1.6124e-01,  1.7728e-01], requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.0121]],\n",
      "\n",
      "         [[ 0.0372]],\n",
      "\n",
      "         [[ 0.0140]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0249]],\n",
      "\n",
      "         [[ 0.0404]],\n",
      "\n",
      "         [[-0.0282]]],\n",
      "\n",
      "\n",
      "        [[[-0.0024]],\n",
      "\n",
      "         [[-0.0107]],\n",
      "\n",
      "         [[-0.0261]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0344]],\n",
      "\n",
      "         [[-0.0276]],\n",
      "\n",
      "         [[ 0.0365]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0059]],\n",
      "\n",
      "         [[ 0.0229]],\n",
      "\n",
      "         [[-0.0012]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0196]],\n",
      "\n",
      "         [[-0.0074]],\n",
      "\n",
      "         [[ 0.0151]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0129]],\n",
      "\n",
      "         [[-0.0288]],\n",
      "\n",
      "         [[ 0.0325]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0342]],\n",
      "\n",
      "         [[ 0.0389]],\n",
      "\n",
      "         [[-0.0373]]],\n",
      "\n",
      "\n",
      "        [[[-0.0248]],\n",
      "\n",
      "         [[-0.0429]],\n",
      "\n",
      "         [[-0.0378]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0064]],\n",
      "\n",
      "         [[-0.0103]],\n",
      "\n",
      "         [[ 0.0259]]],\n",
      "\n",
      "\n",
      "        [[[-0.0220]],\n",
      "\n",
      "         [[ 0.0023]],\n",
      "\n",
      "         [[ 0.0055]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0362]],\n",
      "\n",
      "         [[ 0.0076]],\n",
      "\n",
      "         [[ 0.0310]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0358,  0.0225,  0.0202,  0.0375, -0.0346,  0.0244, -0.0406, -0.0130,\n",
      "        -0.0111,  0.0388,  0.0242,  0.0245,  0.0030,  0.0139,  0.0434, -0.0065,\n",
      "         0.0433, -0.0097,  0.0322,  0.0416,  0.0441, -0.0348, -0.0101, -0.0146,\n",
      "        -0.0300,  0.0415,  0.0170,  0.0087,  0.0313, -0.0344,  0.0125, -0.0332,\n",
      "         0.0016, -0.0379,  0.0162, -0.0194, -0.0390,  0.0141,  0.0275,  0.0285,\n",
      "        -0.0424, -0.0162, -0.0334, -0.0200,  0.0273,  0.0414, -0.0059, -0.0171,\n",
      "         0.0136,  0.0298, -0.0297,  0.0254,  0.0296,  0.0330, -0.0361,  0.0168,\n",
      "         0.0350,  0.0276,  0.0357, -0.0217, -0.0221,  0.0099, -0.0059,  0.0258,\n",
      "        -0.0029, -0.0263,  0.0224,  0.0131, -0.0099,  0.0144, -0.0179,  0.0321,\n",
      "        -0.0321,  0.0215,  0.0145, -0.0271, -0.0212,  0.0302, -0.0353, -0.0266,\n",
      "        -0.0436,  0.0093, -0.0096, -0.0306, -0.0049,  0.0038,  0.0039,  0.0209,\n",
      "        -0.0056,  0.0028, -0.0019, -0.0313, -0.0126, -0.0270, -0.0259, -0.0129,\n",
      "        -0.0322,  0.0134, -0.0354,  0.0120, -0.0314, -0.0382, -0.0336,  0.0187,\n",
      "        -0.0419,  0.0205,  0.0071,  0.0086,  0.0145,  0.0058, -0.0300,  0.0081,\n",
      "        -0.0016,  0.0283, -0.0148, -0.0252, -0.0235, -0.0202,  0.0229, -0.0196,\n",
      "        -0.0019,  0.0281, -0.0100,  0.0301,  0.0296,  0.0312, -0.0341, -0.0165,\n",
      "        -0.0229,  0.0099,  0.0033,  0.0113,  0.0064,  0.0289, -0.0432, -0.0002,\n",
      "         0.0035, -0.0048,  0.0298,  0.0182, -0.0062,  0.0199,  0.0426,  0.0255,\n",
      "         0.0244, -0.0425,  0.0343,  0.0115, -0.0123, -0.0329,  0.0338,  0.0232,\n",
      "        -0.0326, -0.0104, -0.0351, -0.0332, -0.0308,  0.0120, -0.0301,  0.0129,\n",
      "        -0.0013,  0.0304, -0.0224,  0.0008,  0.0090,  0.0310,  0.0339, -0.0246,\n",
      "        -0.0147,  0.0344,  0.0384,  0.0146,  0.0100, -0.0243,  0.0095, -0.0427,\n",
      "        -0.0202, -0.0376, -0.0354, -0.0369, -0.0304,  0.0082, -0.0360, -0.0439,\n",
      "         0.0403, -0.0349, -0.0011, -0.0297,  0.0204, -0.0161, -0.0098,  0.0325,\n",
      "        -0.0281, -0.0036,  0.0266,  0.0305, -0.0144, -0.0343,  0.0157, -0.0014,\n",
      "        -0.0403, -0.0196,  0.0312,  0.0293, -0.0201,  0.0017,  0.0066, -0.0295,\n",
      "        -0.0137, -0.0099, -0.0273,  0.0401,  0.0048, -0.0236, -0.0276,  0.0419,\n",
      "        -0.0254, -0.0074, -0.0299, -0.0035, -0.0417,  0.0025,  0.0143,  0.0188,\n",
      "         0.0391,  0.0115, -0.0042, -0.0008,  0.0339, -0.0044,  0.0428, -0.0154,\n",
      "        -0.0441,  0.0254,  0.0051, -0.0357, -0.0020,  0.0270,  0.0341, -0.0428,\n",
      "         0.0156,  0.0086, -0.0087, -0.0374, -0.0130,  0.0263, -0.0103, -0.0049,\n",
      "        -0.0016, -0.0088, -0.0202,  0.0028, -0.0304, -0.0298,  0.0278,  0.0307,\n",
      "         0.0098,  0.0423, -0.0340, -0.0200,  0.0287,  0.0063, -0.0211,  0.0404,\n",
      "        -0.0417, -0.0283, -0.0145, -0.0165,  0.0275,  0.0052, -0.0123,  0.0429,\n",
      "        -0.0203, -0.0054,  0.0372,  0.0437,  0.0006,  0.0251, -0.0198,  0.0178,\n",
      "         0.0090, -0.0248, -0.0115, -0.0162, -0.0317, -0.0392,  0.0424, -0.0346,\n",
      "        -0.0106,  0.0184,  0.0368,  0.0331,  0.0282, -0.0162,  0.0049, -0.0348,\n",
      "        -0.0010, -0.0253, -0.0275,  0.0049, -0.0404,  0.0414,  0.0278, -0.0019,\n",
      "        -0.0113,  0.0305,  0.0152, -0.0054, -0.0311, -0.0322,  0.0277,  0.0189,\n",
      "        -0.0375, -0.0060,  0.0319,  0.0273,  0.0190, -0.0372, -0.0021,  0.0193,\n",
      "        -0.0254,  0.0354, -0.0042, -0.0288, -0.0158,  0.0243,  0.0353,  0.0094,\n",
      "         0.0294,  0.0398, -0.0224, -0.0250, -0.0431,  0.0129,  0.0408, -0.0258,\n",
      "         0.0332,  0.0076, -0.0333, -0.0007,  0.0311, -0.0289,  0.0223,  0.0034,\n",
      "         0.0130, -0.0084, -0.0425,  0.0142,  0.0168,  0.0340,  0.0077,  0.0122,\n",
      "         0.0264,  0.0345, -0.0106, -0.0237,  0.0376,  0.0324, -0.0196,  0.0073,\n",
      "        -0.0337,  0.0281,  0.0067,  0.0169,  0.0356, -0.0153,  0.0408,  0.0067,\n",
      "         0.0094,  0.0259, -0.0360,  0.0121, -0.0278,  0.0272, -0.0441,  0.0158,\n",
      "         0.0217, -0.0414,  0.0351, -0.0291, -0.0212, -0.0227, -0.0416, -0.0434,\n",
      "        -0.0003, -0.0352, -0.0167,  0.0268,  0.0435,  0.0225,  0.0263, -0.0110,\n",
      "        -0.0015,  0.0426,  0.0159, -0.0020, -0.0188,  0.0422, -0.0304,  0.0075,\n",
      "         0.0407,  0.0168, -0.0022, -0.0206,  0.0347, -0.0436, -0.0166,  0.0186,\n",
      "         0.0261, -0.0103,  0.0209, -0.0395,  0.0138,  0.0257, -0.0036,  0.0325,\n",
      "         0.0433, -0.0436,  0.0219, -0.0075, -0.0010, -0.0165, -0.0129,  0.0143,\n",
      "         0.0214, -0.0355,  0.0424, -0.0062, -0.0159, -0.0408, -0.0202, -0.0181,\n",
      "        -0.0087, -0.0287,  0.0242, -0.0027, -0.0435,  0.0224, -0.0428,  0.0358,\n",
      "        -0.0011, -0.0112,  0.0075,  0.0275, -0.0023,  0.0165, -0.0236, -0.0222,\n",
      "         0.0057, -0.0059,  0.0218, -0.0282,  0.0042, -0.0086,  0.0252,  0.0178,\n",
      "         0.0356,  0.0230, -0.0334, -0.0238,  0.0250,  0.0249, -0.0186,  0.0216,\n",
      "         0.0360,  0.0380,  0.0016,  0.0434,  0.0223,  0.0124,  0.0393,  0.0297,\n",
      "         0.0257,  0.0429, -0.0084,  0.0330,  0.0125, -0.0375, -0.0212, -0.0429,\n",
      "        -0.0373, -0.0223, -0.0205, -0.0029,  0.0436, -0.0115, -0.0006, -0.0427,\n",
      "        -0.0389, -0.0087, -0.0390, -0.0387, -0.0164, -0.0263,  0.0237, -0.0412,\n",
      "         0.0320, -0.0358,  0.0359,  0.0340,  0.0225,  0.0080, -0.0189, -0.0422,\n",
      "         0.0139,  0.0169, -0.0054, -0.0258, -0.0289,  0.0265,  0.0287,  0.0435],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
      "tensor([[ 2.0932e-02,  2.4047e-02,  2.7167e-02, -4.2758e-03, -7.2011e-03,\n",
      "         -5.7856e-03, -1.5648e-02, -3.2120e-02, -2.5855e-02, -2.1405e-02,\n",
      "          2.6138e-02, -1.6642e-02, -2.2251e-02,  3.1593e-02,  1.9341e-02,\n",
      "         -2.3246e-02, -2.5581e-02,  4.0281e-02,  1.2002e-02, -2.8655e-03,\n",
      "         -2.1856e-02,  3.6362e-02,  1.5221e-02, -1.3831e-02, -3.3525e-02,\n",
      "         -3.8187e-03, -1.9261e-02,  1.8095e-02,  5.6152e-03, -1.4772e-02,\n",
      "          2.8123e-02, -3.0483e-02,  1.9857e-02,  4.4157e-02, -2.2124e-02,\n",
      "         -2.1554e-02, -3.1976e-02, -3.6427e-02, -3.8189e-02,  2.4435e-02,\n",
      "         -4.6312e-03, -2.4348e-02,  1.3058e-03,  4.6590e-03, -3.7453e-02,\n",
      "          2.3985e-03, -2.0751e-02,  2.3110e-02,  1.3490e-02,  4.4338e-03,\n",
      "          2.8176e-02,  1.2995e-02, -1.5231e-02,  2.9692e-03, -4.1505e-03,\n",
      "          3.2813e-02, -3.6956e-02,  3.7994e-02,  8.7349e-03,  1.8353e-02,\n",
      "          1.9501e-02,  1.4508e-02, -2.1687e-02, -3.5329e-03,  2.7125e-02,\n",
      "         -1.8079e-02, -3.5152e-02,  2.8391e-02,  3.3712e-02, -1.1989e-02,\n",
      "         -4.0216e-02,  2.8398e-02,  8.6239e-03,  7.8482e-03,  3.6879e-02,\n",
      "         -4.0699e-02, -1.4986e-02,  3.8451e-02, -1.7430e-02, -1.9896e-02,\n",
      "          1.5889e-02,  2.0003e-02,  2.8869e-02,  3.7072e-02, -2.2851e-02,\n",
      "          4.2851e-02, -1.6129e-03, -4.8784e-03,  2.2714e-02, -1.8378e-02,\n",
      "         -9.1537e-03, -1.7457e-02,  4.1866e-02, -9.3165e-03,  2.3627e-02,\n",
      "         -4.0854e-03, -2.7301e-02, -2.8053e-02,  3.3003e-02, -2.2897e-02,\n",
      "         -2.8696e-02,  2.6577e-02, -2.7358e-02,  1.4166e-02, -6.7056e-03,\n",
      "          4.1692e-02,  1.0683e-02,  3.3617e-02, -1.0112e-02,  6.3346e-03,\n",
      "         -3.4743e-02, -2.7988e-02, -1.8913e-02, -1.7002e-02, -7.5981e-03,\n",
      "          1.0624e-02, -3.7964e-02, -1.7198e-02, -3.7968e-02, -1.8569e-02,\n",
      "          3.9086e-02,  4.9122e-03, -4.1990e-02,  1.2198e-02, -4.3134e-02,\n",
      "          2.7989e-02,  3.3142e-02, -3.3721e-02,  3.0618e-02,  2.4216e-02,\n",
      "          2.1291e-02,  2.6947e-02,  3.4645e-02,  1.3680e-02,  2.6504e-02,\n",
      "          2.6339e-02, -8.6369e-03,  2.9479e-02,  9.8317e-03,  2.8417e-02,\n",
      "          2.3087e-02,  6.6392e-03,  2.9575e-02, -1.9689e-02,  2.1866e-02,\n",
      "          3.1020e-02,  2.7261e-02, -1.7874e-02,  1.8436e-02,  3.2063e-02,\n",
      "          8.3247e-03,  4.0082e-02,  4.2738e-03,  2.4013e-02, -2.5468e-03,\n",
      "         -2.7046e-02,  2.2627e-02,  6.8459e-03,  2.9024e-02, -1.2244e-02,\n",
      "          1.5095e-03,  5.7676e-03,  5.7110e-03,  6.2333e-03, -1.3492e-02,\n",
      "          6.0110e-03, -1.7494e-02, -3.0434e-02, -8.5091e-03,  4.3694e-02,\n",
      "          5.1025e-03, -2.4628e-02, -2.8125e-02,  2.1790e-02,  9.4526e-04,\n",
      "         -4.6468e-03, -3.6673e-02,  1.5695e-02, -2.5104e-02,  9.9008e-03,\n",
      "         -1.0057e-03, -1.1085e-02,  1.8518e-02, -2.3802e-02,  1.6685e-02,\n",
      "          3.2382e-02,  7.7924e-03,  3.9028e-03, -3.3310e-02,  3.2352e-02,\n",
      "          1.6649e-02, -3.8816e-02,  1.9988e-02, -1.3981e-02, -9.3405e-03,\n",
      "         -9.4025e-03,  3.8628e-02, -4.7555e-04, -3.6038e-02, -4.1566e-02,\n",
      "          1.1521e-02, -2.4351e-02, -1.2347e-02,  1.9064e-02,  2.3616e-02,\n",
      "          4.1533e-02, -1.2200e-02, -1.6178e-02, -2.9651e-02,  2.9534e-02,\n",
      "          4.1648e-02, -2.8967e-02,  3.1766e-03,  1.9516e-02,  1.8747e-02,\n",
      "         -6.7410e-03, -4.1122e-02, -4.0126e-02, -2.0770e-02, -3.3382e-02,\n",
      "         -4.9773e-03, -2.0098e-02, -2.8112e-02,  2.2826e-02, -1.8037e-02,\n",
      "         -2.2025e-02, -3.1170e-02,  3.1080e-02,  5.7692e-03, -1.9919e-02,\n",
      "         -1.2963e-02,  2.2217e-02,  3.4210e-02, -3.0846e-02,  6.9115e-03,\n",
      "          1.3100e-02,  3.0894e-02, -3.5609e-02,  2.3250e-02,  1.6963e-02,\n",
      "          1.9369e-02, -4.3877e-02,  2.5834e-02, -2.2999e-02,  2.1211e-02,\n",
      "         -2.9134e-02, -2.8113e-02, -1.2838e-03,  2.1956e-02, -4.3521e-02,\n",
      "          1.9674e-02, -1.3086e-02,  2.7000e-02,  2.6711e-02,  1.2516e-02,\n",
      "          5.2280e-04, -3.9850e-02, -8.9977e-03,  1.7476e-02, -3.5733e-03,\n",
      "          4.1205e-02,  4.0402e-02,  3.2010e-02, -2.0620e-02,  1.9553e-02,\n",
      "          2.2912e-02,  4.1813e-02,  3.0054e-02,  3.2937e-02,  2.5261e-02,\n",
      "         -1.7904e-02, -9.7281e-03,  2.5965e-02,  2.7031e-02, -4.3240e-02,\n",
      "          3.6415e-02, -5.5870e-03, -1.8001e-02,  3.1979e-02, -3.3304e-02,\n",
      "         -2.8871e-02, -2.6339e-02, -5.3180e-03, -7.5169e-04,  4.0786e-02,\n",
      "          3.4088e-02, -4.3442e-02,  3.7324e-02,  1.4180e-02,  2.0384e-02,\n",
      "         -4.6991e-03, -1.8774e-02, -1.9660e-02,  7.3323e-03,  3.6230e-02,\n",
      "         -1.3146e-02,  1.6816e-02, -7.6797e-04, -3.8839e-02, -4.2810e-02,\n",
      "         -9.7276e-03,  2.1952e-02,  3.8853e-02, -1.4069e-02,  3.9052e-04,\n",
      "         -4.0789e-02,  3.8332e-02, -2.2734e-02,  1.8762e-02, -1.1339e-02,\n",
      "          3.3576e-02, -2.4233e-03,  2.4932e-02, -1.7326e-02,  9.3467e-05,\n",
      "         -3.6479e-02,  4.2700e-02, -8.6817e-03,  7.0028e-03, -1.5740e-02,\n",
      "          8.6085e-03,  1.7792e-03, -4.2084e-02, -2.2050e-02, -3.4640e-02,\n",
      "          2.1575e-02, -1.4728e-02,  2.1364e-02,  3.4536e-02,  2.2304e-02,\n",
      "          3.2645e-02,  2.6610e-02, -6.1698e-03, -6.8868e-03,  5.5692e-03,\n",
      "          1.2489e-02,  1.9566e-02, -3.3663e-02,  1.4487e-02,  1.7650e-02,\n",
      "         -3.0679e-02, -3.0835e-02,  2.9654e-02,  9.4008e-03,  3.2297e-02,\n",
      "         -2.6759e-02,  4.2731e-02,  9.9862e-04, -5.9832e-04,  1.3623e-02,\n",
      "         -2.0368e-02, -2.8283e-02,  2.1512e-02,  4.2814e-02, -2.6185e-02,\n",
      "          2.3024e-02, -2.6499e-02, -3.6170e-02, -1.3522e-02, -1.0930e-03,\n",
      "         -2.6052e-03,  1.1620e-02, -3.0789e-02,  4.0113e-03,  1.5130e-02,\n",
      "          3.6646e-02,  1.9238e-03, -4.6595e-03,  4.0825e-02,  2.5856e-02,\n",
      "         -2.6422e-02,  1.9677e-03, -2.0318e-02,  2.7615e-02,  4.0888e-02,\n",
      "          3.6842e-02, -2.1114e-02, -7.5847e-04,  3.3206e-02, -4.1089e-02,\n",
      "         -2.5372e-03,  1.7912e-02,  1.8848e-02,  1.3151e-02, -1.1073e-03,\n",
      "         -3.5352e-02, -2.9477e-02,  9.3619e-03, -1.3420e-02, -4.0719e-02,\n",
      "         -3.7213e-02, -8.9541e-03,  2.3246e-03,  1.3390e-02,  3.7742e-02,\n",
      "         -5.2788e-03,  3.9073e-02,  3.2537e-02, -3.6936e-02, -4.1344e-02,\n",
      "          3.6986e-02, -3.3897e-02, -3.1470e-02,  2.1803e-02, -3.6214e-02,\n",
      "         -3.3618e-02, -4.0498e-02, -3.4145e-02, -4.1136e-02, -2.1961e-02,\n",
      "         -3.0707e-02,  4.2212e-02, -1.6413e-02, -2.3074e-02, -3.5936e-02,\n",
      "          5.0826e-03, -3.8471e-02,  1.0983e-02,  2.4465e-02, -3.2321e-02,\n",
      "         -3.0036e-02, -1.4387e-04, -2.5894e-02,  6.4801e-03, -6.3409e-03,\n",
      "         -3.5499e-02,  4.7459e-03,  5.1874e-03,  1.6771e-02, -3.0817e-02,\n",
      "          1.5104e-02, -1.1830e-02, -3.7821e-02, -1.1971e-02, -3.8061e-03,\n",
      "          9.0466e-03,  1.5926e-02, -3.1968e-02, -2.8281e-03, -1.9679e-02,\n",
      "         -2.4536e-02, -3.1442e-02,  7.8226e-03,  3.7222e-02,  1.3538e-02,\n",
      "          7.3568e-03,  1.9924e-02,  4.3694e-03,  1.2969e-02,  3.9003e-02,\n",
      "         -1.0408e-02,  1.9501e-02,  3.5621e-02, -3.3025e-02,  1.1501e-02,\n",
      "          1.1563e-02, -2.4336e-02, -2.9986e-02,  1.5337e-02, -8.9301e-03,\n",
      "          3.5358e-02, -1.5130e-02,  1.2029e-02,  2.9056e-02, -2.0834e-02,\n",
      "          3.5208e-02, -1.7848e-02,  2.9353e-02,  7.4382e-03,  4.0992e-02,\n",
      "          2.6793e-02, -3.8602e-02, -3.1922e-02, -1.8438e-02,  3.9244e-02,\n",
      "         -4.8975e-03, -1.6982e-02,  1.9181e-02,  3.9672e-02,  5.9982e-03,\n",
      "         -3.3779e-02, -3.8424e-02, -3.0625e-02, -1.7806e-02, -3.6221e-02,\n",
      "         -1.2186e-02,  1.5949e-03,  1.0271e-02,  2.5914e-02, -1.2882e-02,\n",
      "         -2.7278e-02,  4.3235e-02, -1.8652e-02, -2.6476e-02,  4.2144e-02,\n",
      "          1.1689e-02,  2.9991e-02, -4.2604e-02, -4.0745e-02, -3.7237e-02,\n",
      "         -1.1288e-03,  3.0044e-03, -1.1456e-02,  4.2649e-02, -3.4014e-02,\n",
      "         -3.3655e-02,  1.6896e-02,  7.9300e-03,  2.4111e-02, -3.2294e-02,\n",
      "         -3.3296e-02,  1.8365e-02]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0099], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(tree_model.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4795f794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>\n",
       "\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0  </span> layers                   Sequential          1.8 M \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1  </span> layers.0                 MyEntryLayer        174 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2  </span> layers.0.proj_out        Conv2d              6.7 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3  </span> layers.0.entry_blocks    ModuleList          168 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4  </span> layers.1                 MySepConvLayer      268 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5  </span> layers.1.proj_out        Identity                0 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6  </span> layers.1.sep_conv_block  Sequential          268 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7  </span> layers.2                 MySepConvLayer      268 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8  </span> layers.2.proj_out        Identity                0 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9  </span> layers.2.sep_conv_block  Sequential          268 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10 </span> layers.3                 MySepConvLayer      268 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 11 </span> layers.3.proj_out        Identity                0 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 12 </span> layers.3.sep_conv_block  Sequential          268 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 13 </span> layers.4                 MySepConvLayer      268 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 14 </span> layers.4.proj_out        Identity                0 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 15 </span> layers.4.sep_conv_block  Sequential          268 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 16 </span> layers.5                 MySepConvLayer      268 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 17 </span> layers.5.proj_out        Identity                0 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 18 </span> layers.5.sep_conv_block  Sequential          268 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 19 </span> layers.6                 MySepConvLayer      268 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 20 </span> layers.6.proj_out        Identity                0 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 21 </span> layers.6.sep_conv_block  Sequential          268 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 22 </span> layers.7                 AdaptiveMaxPool2d       0 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 23 </span> layers.8                 Flatten                 0 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 24 </span> layers.9                 Linear                513 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35m \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mName                   \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m\n",
       "\n",
       "\u001b[2m \u001b[0m\u001b[2m0 \u001b[0m\u001b[2m \u001b[0m layers                   Sequential          1.8 M \n",
       "\u001b[2m \u001b[0m\u001b[2m1 \u001b[0m\u001b[2m \u001b[0m layers.0                 MyEntryLayer        174 K \n",
       "\u001b[2m \u001b[0m\u001b[2m2 \u001b[0m\u001b[2m \u001b[0m layers.0.proj_out        Conv2d              6.7 K \n",
       "\u001b[2m \u001b[0m\u001b[2m3 \u001b[0m\u001b[2m \u001b[0m layers.0.entry_blocks    ModuleList          168 K \n",
       "\u001b[2m \u001b[0m\u001b[2m4 \u001b[0m\u001b[2m \u001b[0m layers.1                 MySepConvLayer      268 K \n",
       "\u001b[2m \u001b[0m\u001b[2m5 \u001b[0m\u001b[2m \u001b[0m layers.1.proj_out        Identity                0 \n",
       "\u001b[2m \u001b[0m\u001b[2m6 \u001b[0m\u001b[2m \u001b[0m layers.1.sep_conv_block  Sequential          268 K \n",
       "\u001b[2m \u001b[0m\u001b[2m7 \u001b[0m\u001b[2m \u001b[0m layers.2                 MySepConvLayer      268 K \n",
       "\u001b[2m \u001b[0m\u001b[2m8 \u001b[0m\u001b[2m \u001b[0m layers.2.proj_out        Identity                0 \n",
       "\u001b[2m \u001b[0m\u001b[2m9 \u001b[0m\u001b[2m \u001b[0m layers.2.sep_conv_block  Sequential          268 K \n",
       "\u001b[2m \u001b[0m\u001b[2m10\u001b[0m\u001b[2m \u001b[0m layers.3                 MySepConvLayer      268 K \n",
       "\u001b[2m \u001b[0m\u001b[2m11\u001b[0m\u001b[2m \u001b[0m layers.3.proj_out        Identity                0 \n",
       "\u001b[2m \u001b[0m\u001b[2m12\u001b[0m\u001b[2m \u001b[0m layers.3.sep_conv_block  Sequential          268 K \n",
       "\u001b[2m \u001b[0m\u001b[2m13\u001b[0m\u001b[2m \u001b[0m layers.4                 MySepConvLayer      268 K \n",
       "\u001b[2m \u001b[0m\u001b[2m14\u001b[0m\u001b[2m \u001b[0m layers.4.proj_out        Identity                0 \n",
       "\u001b[2m \u001b[0m\u001b[2m15\u001b[0m\u001b[2m \u001b[0m layers.4.sep_conv_block  Sequential          268 K \n",
       "\u001b[2m \u001b[0m\u001b[2m16\u001b[0m\u001b[2m \u001b[0m layers.5                 MySepConvLayer      268 K \n",
       "\u001b[2m \u001b[0m\u001b[2m17\u001b[0m\u001b[2m \u001b[0m layers.5.proj_out        Identity                0 \n",
       "\u001b[2m \u001b[0m\u001b[2m18\u001b[0m\u001b[2m \u001b[0m layers.5.sep_conv_block  Sequential          268 K \n",
       "\u001b[2m \u001b[0m\u001b[2m19\u001b[0m\u001b[2m \u001b[0m layers.6                 MySepConvLayer      268 K \n",
       "\u001b[2m \u001b[0m\u001b[2m20\u001b[0m\u001b[2m \u001b[0m layers.6.proj_out        Identity                0 \n",
       "\u001b[2m \u001b[0m\u001b[2m21\u001b[0m\u001b[2m \u001b[0m layers.6.sep_conv_block  Sequential          268 K \n",
       "\u001b[2m \u001b[0m\u001b[2m22\u001b[0m\u001b[2m \u001b[0m layers.7                 AdaptiveMaxPool2d       0 \n",
       "\u001b[2m \u001b[0m\u001b[2m23\u001b[0m\u001b[2m \u001b[0m layers.8                 Flatten                 0 \n",
       "\u001b[2m \u001b[0m\u001b[2m24\u001b[0m\u001b[2m \u001b[0m layers.9                 Linear                513 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.8 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 1.8 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 7                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.8 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 1.8 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 7                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1688476cb85c4bd9be6eeed52c39518a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [95]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:531\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    529\u001b[0m model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 531\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:42\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     45\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:570\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[0;32m    561\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[0;32m    562\u001b[0m )\n\u001b[0;32m    564\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    566\u001b[0m     ckpt_path,\n\u001b[0;32m    567\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    568\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    569\u001b[0m )\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:975\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    980\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1016\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1016\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1045\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1042\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1045\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1047\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:177\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop_run(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:115\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m     previous_dataloader_idx \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:375\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[0;32m    374\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 375\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[0;32m    379\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_test_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:287\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 287\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    290\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:379\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, ValidationStep)\n\u001b[1;32m--> 379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\double.py:48\u001b[0m, in \u001b[0;36mLightningDoublePrecisionModule.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mvalidation_step(\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;241m*\u001b[39mLightningDoublePrecisionModule\u001b[38;5;241m.\u001b[39m_move_float_tensors_to_double(args),\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mLightningDoublePrecisionModule\u001b[38;5;241m.\u001b[39m_move_float_tensors_to_double(kwargs),\n\u001b[0;32m     51\u001b[0m     )\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36mMyCNNModel.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx): \u001b[38;5;66;03m# New!\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 30\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36mMyCNNModel.training_step\u001b[1;34m(self, batch, batch_idx, log_prefix)\u001b[0m\n\u001b[0;32m     22\u001b[0m X, y \u001b[38;5;241m=\u001b[39m batch \u001b[38;5;66;03m# Tuple with (X,y) in our case\u001b[39;00m\n\u001b[0;32m     23\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(X)\n\u001b[1;32m---> 24\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMSELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem(), on_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, on_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, prog_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:533\u001b[0m, in \u001b[0;36mMSELoss.__init__\u001b[1;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, size_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMSELoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:23\u001b[0m, in \u001b[0;36m_Loss.__init__\u001b[1;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28msuper\u001b[39m(_Loss, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacy_get_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction \u001b[38;5;241m=\u001b[39m reduction\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:35\u001b[0m, in \u001b[0;36mlegacy_get_string\u001b[1;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     reduce \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mand\u001b[39;00m reduce:\n\u001b[0;32m     36\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m reduce:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "trainer1.fit(tree_model, trainloader, validloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5900cc27",
   "metadata": {},
   "source": [
    "## Now, we can apply it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e5f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,10, figsize=(12, 12))\n",
    "for i in range(10):\n",
    "    X,y = testset[i]\n",
    "    y_hat = tree_model.predict(X.unsqueeze(0))[0]\n",
    "    X,y = X.transpose(0,-1).transpose(0,1) * 0.5 + 0.5, testset.classes[y]\n",
    "    axarr[i].imshow(X)\n",
    "    axarr[i].axis('off')\n",
    "    axarr[i].set_title(f'{y} - {y_hat}', fontsize='small')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
